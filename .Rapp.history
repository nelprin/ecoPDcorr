points(1:10,rep(3,10),pch=19,cex=8,col=color.scale(1:10,c(1,0,0),c(0.9,0,0),c(0.8,0,0),color.spec="rgb"))
plot(1:10,rep(1:3,length.out=10),axes=FALSE,type="n",xlim=c(0,11),ylim=c(0,4),main="Test of RGB, HSV and HCL",xlab="",ylab="Color specification")axis(2,at=1:3,labels=c("HCL","HSV","RGB"))points(1:10,rep(1,10),pch=19,cex=8,col=color.scale(1:10,c(0,300),35,85,color.spec="hcl"))points(1:10,rep(2,10),pch=19,cex=8,col=color.scale(1:10,c(0,1),0.8,1,color.spec="hsv"))
points(1:10,rep(3,10),pch=19,cex=8,col=color.scale(c(1,0,0),c(0.9,0,0),c(0.8,0,0),color.spec="rgb"))
plot(0:1, type="n", axes=FALSE)#
#
##define a gradient from blue to cyan to green to yellow to red. the more slices the smoother#
#
gradient.colors <- color.gradient(c(0,0,0,1,1),c(0,1,1,1,0),c(1,1,0,0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
plot(0:1, type="n", axes=FALSE)#
#
##define a gradient from blue to cyan to green to yellow to red. the more slices the smoother#
#
gradient.colors <- color.gradient(c(0,0,0,0,0),c(0,0,0,0,0),c(0,0,0,0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
plot(0:1, type="n", axes=FALSE)#
#
##define a gradient from blue to cyan to green to yellow to red. the more slices the smoother#
#
gradient.colors <- color.gradient(c(1,0.9,0.8,0.7,0.6),c(0,0,0,0,0),c(0,0,0,0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
plot(0:1, type="n", axes=FALSE)#
#
##define a gradient from blue to cyan to green to yellow to red. the more slices the smoother#
#
gradient.colors <- color.gradient(c(1,0.8,0.6,0.4,0.2),c(0,0,0,0,0),c(0,0,0,0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
plot(0:1, type="n", axes=FALSE)#
#
##define a gradient from blue to cyan to green to yellow to red. the more slices the smoother#
#
gradient.colors <- color.gradient(c(1,0.8,0.6,0.4,0.2,0),c(0,0,0,0,0,0),c(0,0,0,0,0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
gradient.colors <- color.gradient(c(1,1,0,0,0,1),c(0,1,1,1,0,0),c(0,0,0,1,1,1), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
gradient.colors <- color.gradient(c(1,0),c(0,1),c(0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
gradient.colors <- color.gradient(c(1,1,0),c(0,1,1),c(0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
gradient.colors <- color.gradient(c(1,0),c(0,1),c(0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
quartz()
gradient.colors <- color.gradient(c(1,0),c(0,1),c(0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
gradient.colors <- color.gradient(c(1,1,0),c(0,1,1),c(0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
plot(0:1, type="n", axes=FALSE)#
#
##define a gradient from blue to cyan to green to yellow to red. the more slices the smoother#
#
gradient.colors <- color.gradient(c(1,1,0),c(0,1,1),c(0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
quartz()
gradient.colors <- color.gradient(c(1,1,0),c(0,1,1),c(0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
plot(0:1, type="n", axes=FALSE)#
#
##define a gradient from blue to cyan to green to yellow to red. the more slices the smoother#
#
gradient.colors <- color.gradient(c(1,0),c(0,1),c(0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
plot(0:1, type="n", axes=FALSE)#
#
##define a gradient from blue to cyan to green to yellow to red. the more slices the smoother#
#
gradient.colors <- color.gradient(c(1,1,0),c(0,1,1),c(0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
plot(0:1, type="n", axes=FALSE)#
#
##define a gradient from blue to cyan to green to yellow to red. the more slices the smoother#
#
gradient.colors <- color.gradient(c(1,1,0),c(0,1,0.9),c(0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
plot(0:1, type="n", axes=FALSE)#
#
##define a gradient from blue to cyan to green to yellow to red. the more slices the smoother#
#
gradient.colors <- color.gradient(c(1,0),c(0,0.9),c(0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
plot(0:1, type="n", axes=FALSE)#
#
##define a gradient from blue to cyan to green to yellow to red. the more slices the smoother#
#
gradient.colors <- color.gradient(c(1,0),c(0,0.5),c(0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
plot(0:1, type="n", axes=FALSE)#
#
##define a gradient from blue to cyan to green to yellow to red. the more slices the smoother#
#
gradient.colors <- color.gradient(c(1,0),c(0,0.6),c(0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
library(plotrix)#
#
##call an empty plot that will make it easy to define the rectangle#
#
plot(0:1, type="n", axes=FALSE)#
#
##define a gradient from blue to cyan to green to yellow to red. the more slices the smoother#
#
gradient.colors <- color.gradient(c(0,0,0,1,1),c(0,1,1,1,0),c(1,1,0,0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
plot(0:1, type="n", axes=FALSE)#
#
gradient.colors <- color.gradient(c(0,0,1,1),c(1,1,0.5,0),c(1,1,0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
pdf("plot.pdf")
plot(0:1, type="n", axes=FALSE)#
#
gradient.colors <- color.gradient(c(0,0,1,1),c(1,1,0.5,0),c(1,1,0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
dev.off()
pdf("plot.pdf")
gradient.colors <- color.gradient(c(0,0,0,1,1),c(0,1,1,1,0),c(1,1,0,0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
plot(0:1, type="n", axes=FALSE)#
#
gradient.colors <- color.gradient(c(0,0,0,1,1),c(0,1,1,1,0),c(1,1,0,0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
dev.off()
pdf("plot.pdf")
plot(0:1, type="n", axes=FALSE)#
#
gradient.colors <- color.gradient(c(1,1,0),c(0,1,1),c(0,0), nslices=1000)#
#
gradient.rect(0,0,1.1,1, col=gradient.colors, border=NA, gradient="y")
dev.off()
100 x 6
100/6
library(plyr)
libary(picante)
library(picante)
here are a set of functions to derive null expectations as done in our#
##forthingcoming paper, "Niche conservatism constrains Australian honeyeater assemblages #
##in stressful environments".#
#
##call your libraries#
#
library(plyr)#
library(picante)#
#
##i used to simulate the null expectations by random draws from the entire phylogeny. the #
##code for how to properly deal with the resulting data is in previous versions of this file#
##here, i will randomize the input matrix with various null models, then save the results #
##as a data frame with first column equal to richness, second column equal to MPD#
#
##first define a function that will be used to find the species richness of each row (i.e. community)#
#
lengthNonZeros <- function(input.vector)#
{#
	nonZeros <- input.vector[input.vector != 0]#
	return(length(nonZeros))#
}#
#
##then define a function that will use this function and the modified.mpd function to generate one block (iteration) of the desired data frame#
#
oneIteration <- function(orig.matrix, phy.dists, abundance.method)#
{#
	oneBlock <- matrix(nrow = dim(orig.matrix)[1], ncol = 2)#
	oneBlock[,1] <- apply(orig.matrix, 1, lengthNonZeros)#
	oneBlock[,2] <- modified.mpd(orig.matrix, phy.dists, abundance.method)#
	return(oneBlock)#
}#
#
##define a function that uses the function oneIteration and the picante function randomizeMatrix to generate null expectations after randomization#
#
null.exp <- function(orig.matrix, null.method, phy.dists, abundance.method)#
{#
	randomMatrix <- matrix(nrow = dim(orig.matrix)[1], ncol = 2)#
	randomMatrix <- randomizeMatrix(orig.matrix, null.method)#
	results <- oneIteration(randomMatrix, phy.dists, abundance.method)#
	return(results)#
}#
#
##put all of these functions into an iterator function#
#
iterator <- function(orig.matrix, null.method, phy.dists, abundance.method, iterations)#
{#
	final.results <- matrix(nrow = iterations * dim(orig.matrix)[1], ncol = 2)#
	for (i in 1:iterations)#
	{	#
		final.results[(i * dim(orig.matrix)[1] - dim(orig.matrix)[1] + 1):(i * dim(orig.matrix)[1]), ] <- null.exp(orig.matrix, null.method, phy.dists, abundance.method)#
	}#
	final.results <- as.data.frame(final.results)#
	names(final.results) <- c("richness","metric")#
	return(final.results)#
}#
#
##discovered that the iterator function bogs down the memory very quickly (e.g. at > 1000 iterations)#
##want to write a function that will write the results to a csv file outside of R at each iteration, then clear the memory#
#
null.csv <- function(orig.matrix, null.method, phy.dists, abundance.method, iterations, file.name)#
{#
	for (i in 1:iterations)#
	{#
		temp.results <- null.exp(orig.matrix, null.method, phy.dists, abundance.method)#
		if(i == 1)#
		{#
			write.table(temp.results, file=file.name, append=FALSE, row.names=FALSE, sep=",")#
		}#
		else if(i/iterations == 0.2)#
		{#
			print("20% complete")#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
		else if(i/iterations == 0.5)#
		{#
			print("50% complete")#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
		else#
		{#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
	}#
	print("File saved to working directory")#
}#
#
##also, in case you need to run more iterations at a given richness, e.g. a low richness that isn't being sampled well with the frequency null, write a function that will subset each randomized matrix to only those richnesses you want#
#
null.exp.selected <- function(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses)#
{#
	randomMatrix <- matrix(nrow = dim(orig.matrix)[1], ncol = 2)#
	randomMatrix <- randomizeMatrix(orig.matrix, null.method)#
	results <- oneIteration(randomMatrix, phy.dists, abundance.method)#
	results <- matrix(results[results[,1] %in% accepted.richnesses, ], ncol=2)#
	return(results)#
}#
#
##and the iterator version of that. can't define the matrix beforehand because you don't know how often the pertinent richnesses will appear#
#
iterator.selected <- function(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses, iterations)#
{#
	final.results <- c()#
	for (i in 1:iterations)#
	{	#
		final.results <- rbind(final.results, null.exp.selected(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses))#
	}#
	final.results <- as.data.frame(final.results)#
	names(final.results) <- c("richness","metric")#
	return(final.results)#
}#
#
##make a version that will write straight to csv#
#
null.csv.selected <- function(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses, iterations, file.name)#
{#
	for (i in 1:iterations)#
	{#
		temp.results <- null.exp.selected(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses)#
		if(i == 1)#
		{#
			write.table(temp.results, file=file.name, append=FALSE, row.names=FALSE, sep=",")#
		}#
		else if(i/iterations == 0.2)#
		{#
			print("20% complete")#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
		else if(i/iterations == 0.5)#
		{#
			print("50% complete")#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
		else#
		{#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
	}#
	print("File saved to working directory")#
}#
#
specific.csv <- function(orig.matrix, null.method, phy.dists, abundance.method, desired.iterations, max.iterations, file.name)#
{#
	temp <- oneIteration(orig.matrix, phy.dists, abundance.method)#
	max.rich <- max(temp[,1])#
	min.rich <- min(temp[,1])#
	rich.seq <- min.rich:max.rich#
	details.table <- matrix(nrow=length(rich.seq), ncol=1, dimnames=list(rich.seq))#
	details.table[,1] <- 0#
	temp.results <- null.exp.selected(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses=rich.seq)#
	write.table(temp.results, file=file.name, append=FALSE, row.names=FALSE, col.names=c("richness","metric"), sep=",")#
	details.table[,1][row.names(details.table) %in% count(temp.results[,1])$x] <- count(temp.results[,1])$freq#
	for (i in 1:max.iterations)#
	{#
		rich.seq <- row.names(details.table)[details.table[,1] < desired.iterations]#
		temp.results <- null.exp.selected(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses=rich.seq)#
		write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		details.table[,1][row.names(details.table) %in% count(temp.results[,1])$x] <- details.table[,1][row.names(details.table) %in% count(temp.results[,1])$x] + count(temp.results[,1])$freq#
		if(length(rich.seq) == 0)#
		{#
			break()#
		}#
	}#
	print("File saved to working directory")#
	return(details.table)#
}#
#
##you need to call either iterator(), null.csv(), or specific.csv here to generate your nulls (or any of the selected versions of those) or load in a file (e.g. richness_sim.csv)#
#
##define a function to calculate the mean and 95% confidence intervals of the results from the iterator function#
#
con.intervals <- function(null.output)#
{#
	confidence <- ddply(null.output, "richness", summarise, iterations=length(metric), average=mean(metric), upper=quantile(metric, 0.975, na.rm=TRUE), lower=quantile(metric, 0.025, na.rm=TRUE))#
	return(confidence)#
}#
#
##in the end I ran about 100,000 iterations of the null.csv for each of the four options (non-abundance weighted frequency and richness and interspecific abundance-weighted frequency and richness), then ran 1,000,000 million iterations of the specific.csv for the frequency of both, trying to find 100 samples for every richness. also bound in a few additional searches i did with the null.csv.selected for these higher and lower richnesses for both frequency nulls.#
##then ran the function con.intervals on the concatenated results (note i used some sqldf commands to load these huge files in, see file titled something to do with large table load)#
##load in the for confidence intervals
gc()
library(vegan)
citation("vegan")
gc()
DEFINE A FUNCTION OF ATTRACTION REPULSION ACCORDING TO GD AND SPATIAL DISTANCE (1-ATTRACTION)#
#
library(ape)#
library(colorRamps)#
library(geiger)#
#
require(doMC)#
require(foreach)#
registerDoMC(8)#
repulsing <- TRUE#
#
if (repulsing) {#
	max_dist <- 30 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 3 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
} else {#
	min_dist <- 30#
	max_dist <- 50#
	nl <- 2 #non-linearity#
	max_travel <- 8#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 5  ## moves left or right in reverse direction#
#
}#
#
## HOW MANY RUNS BEFORE TAKING QUADRAT#
n_rounds <- 100#
####  ARENA IS x_max x y_max#
x_min <- 0#
x_max <- 300#
y_min <- 0#
y_max <- 300#
#### CREATE PHYLO TREE WITH INDIVIDUALS#
#
n_default_inds <- 2150#
#
n_species <- 50#
#
results <- foreach (j = 1) %dopar% {#
#
	output <- list()#
#
	####  RUN FROM HERE - NOTHING MORE TO DO#
#
	#tree<-rcoal(n_species) # make tree with n_species#
	tree<-sim.bdtree(b=0.1,d=0,stop="taxa",n=n_species)#
	output[[1]] <- tree#
	rstree<-transform(tree,"depth",1) # rescale tree to have root to tip distance of 1.#
#
	# Assign abundances to species in tree#
	ab<-rlnorm(n_species,2,1)#
	# rescale abundances to be out of n_inds individuals in total#
	abpercent<-ab/sum(ab)*100#
	abdata<-round(abpercent/100*n_default_inds)#
	# replace species that have zero abundance with 1.#
	zeroes<-which(abdata==0)#
	abdata[zeroes]<-1#
#
	regional.community<-data.frame(species=tree$tip.label,abundance=abdata)#
	output[[2]] <- regional.community#
	# branch lengths between pairs of species#
	phydistmatrix<-sqrt(cophenetic(rstree)/2)#
	#### RANDOMLY PLACE INDS IN THE ARENA#
#
	n_inds <- sum(regional.community[,2])#
#
	inds <- data.frame(SPECIES=rep("",n_inds),X=rep(0,n_inds),Y=rep(0,n_inds))#
	inds$SPECIES <- rep(regional.community[,1],regional.community[,2])#
	if (repulsing) {#
		# Initial area of the arena occupied by the individuals under phylogenetic repulsion.#
		# change the first term in the first multiplication to zero and the first term in the second multiplication to 1 if I want    	the individuals to occupy the entire arena from the start.#
		inds$X <- sample(c((0*x_max):(1*x_max)),n_inds, replace=T)#
		inds$Y <- sample(c((0*y_max):(1*y_max)),n_inds, replace=T)#
	} else {#
		inds$X <- sample(c((x_max):(x_max)),n_inds, replace=T)#
		inds$Y <- sample(c((y_max):(y_max)),n_inds, replace=T)#
	}#
	inds$X2 <- inds$X#
	inds$Y2 <- inds$Y#
	inds$REPULSE <- 0#
	inds$SPECIES_NUM <- rep(c(1:nrow(phydistmatrix)),regional.community[,2])#
	cols <- blue2green2red(nrow(phydistmatrix))#
#
	#### FUNCTION TO DEFINE ANGLE AND DISTANCE#
#
	dir_dist <- function(xy2,xy1) {#
		distance <- sqrt((xy1[1]-xy2[1])^2 + (xy1[2]-xy2[2])^2)#
#
		angle <- atan2((c(xy1[2]-xy2[2])),(c(xy1[1]-xy2[1]))) * 180 / pi#
		if (angle <0) angle <- 360+angle#
		angle <- angle-180#
		if (angle <0) angle <- 360+angle#
		return(c(distance,angle))#
	}#
#
	#### FUNCTION TO CALCULATE REPULSION / ATTRACTION#
#
	repulse <- function(gd, distance, max_dist, nl, steepness) {#
		repulsion <- max_travel*(1-(steepness/(steepness+exp(-distance-offset+((1-gd)^nl*max_dist)+1))))#
		return(repulsion)#
	}#
#
	attract <- function(gd, distance, max_dist, min_dist, nl, steepness) {#
		attraction <- max_travel*((steepness/(steepness+exp(-distance-offset+(gd^nl*(max_dist-min_dist))+1))))#
		return(attraction)#
	}#
#
	#### FUNCTION TO CALCULATE NEWX AND NEWY#
#
	travel <- function(inputs) {  # inputs <- x, y, angle, repulsion#
		xy <- inputs[c(1,2)]#
		angle <- inputs[3]#
		repulsion <- inputs[4]#
		if (angle < 180) {#
			angle <- angle * pi / 180#
			newx <- xy[1]-repulsion*cos(angle)#
			newy <- xy[2]-repulsion*sin(angle)#
		} else {#
			angle <- angle - 180#
			angle <- angle * pi / 180#
			newx <- xy[1]+repulsion*cos(angle)#
			newy <- xy[2]+repulsion*sin(angle)#
		}#
		return(c(newx,newy))#
#
	}	#
#
	#### FUNCTION TO ROUND TO +- MAX TRAVEL#
#
	round_travel <- function(distance) {#
		if (distance < 0) #
			return(max(distance,-max_travel))#
		else#
			return(min(distance,max_travel))#
	}#
#
	#### GIVE EACH INDIVIDUAL A CHANCE TO RELOCATE#
	#plot(inds$X,inds$Y,pch=20,cex=0.5, xlim=c(0,x_max),ylim=c(0,y_max), col=cols[inds$SPECIES_NUM])#
	for (zz in c(1:n_rounds)) {#
#
		for (yy in sample(c(1:nrow(inds)),nrow(inds),replace=FALSE)) {#
			xy2 <- as.matrix(inds[yy,c(2,3)])#
			# Put point in center of arena to avoid boundary issues#
			xy <- xy2#
			xy[1] <- xy2[1]+(0.5*x_max-xy2[1])#
			xy[2] <- xy2[2]+(0.5*y_max-xy2[2])#
			inds$X2 <- inds$X+(0.5*x_max-xy2[1])#
			inds$Y2 <- inds$Y+(0.5*y_max-xy2[2])#
			inds$X2[inds$X2 > x_max] <- inds$X2[inds$X2 > x_max]-x_max#
			inds$Y2[inds$Y2 > y_max] <- inds$Y2[inds$Y2 > y_max]-y_max#
			inds$X2[inds$X2 < 0] <- inds$X2[inds$X2 < 0]+x_max#
			inds$Y2[inds$Y2 < 0] <- inds$Y2[inds$Y2 < 0]+y_max#
			# identify individuals within 15m#
			distances <- sqrt((inds$X2[yy]-inds$X2[-yy])^2 + (inds$Y2[yy]-inds$Y2[-yy])^2)#
			if (repulsing) {#
				locals <- inds[-yy,][distances < max_dist ,]#
			} else {#
				locals <- inds[-yy,][distances > min_dist & distances < max_dist ,]#
			}#
			if (nrow(locals) > 0) {#
				# calculate angles, distances and repulsions#
				distances <- t(apply(as.matrix(locals[,c(4,5)]),1,dir_dist,xy))#
				if (repulsing) {#
					repulsions <- repulse(phydistmatrix[inds$SPECIES_NUM[yy],locals$SPECIES_NUM],distances[,1],rep(max_dist,nrow(locals)),rep(nl,nrow(locals)),rep(steepness,nrow(locals)))#
				} else {#
					repulsions <- -attract(phydistmatrix[inds$SPECIES_NUM[yy],locals$SPECIES_NUM],distances[,1],rep(max_dist,nrow(locals)),rep(min_dist,nrow(locals)),rep(nl,nrow(locals)),rep(steepness,nrow(locals)))#
				}#
				# calculate new xs and ys#
				inputs <- cbind(rep(xy[1],nrow(locals)),rep(xy[2],nrow(locals)),distances[,2],repulsions)#
				travels <- t(apply(inputs,1,travel))#
				x_travel <- round_travel(sum(travels[,1] - (0.5*x_max)))#
				y_travel <- round_travel(sum(travels[,2] - (0.5*y_max)))#
				inds$X[yy] <- inds$X[yy] + x_travel#
				inds$Y[yy] <- inds$Y[yy] + y_travel#
				inds$X2[yy] <- inds$X2[yy] + x_travel#
				inds$Y2[yy] <- inds$Y2[yy] + y_travel#
				if (inds$X[yy] < 0) #
					inds$X[yy] <- x_max+(x_travel)-xy2[1]#
				if (inds$X[yy] > x_max)#
					inds$X[yy] <- inds$X[yy]-x_max#
				if (inds$Y[yy] < 0) #
					inds$Y[yy] <- y_max+(y_travel)-xy2[2]#
				if (inds$Y[yy] > y_max)#
					inds$Y[yy] <- inds$Y[yy]-y_max#
			} #
		}#
		#plot(inds$X,inds$Y,pch=20,cex=0.5, xlim=c(0,x_max),ylim=c(0,y_max), col=cols[inds$SPECIES_NUM])#
	}#
	output[[3]] <- inds#
	return(output)#
}
repulsing <- FALSE # Change this to FALSE for clustering#
#
if (repulsing) {#
	max_dist <- 30 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 3 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*(1-(steepness/(steepness+exp(-x-offset+((gd)^nl*max_dist)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl*max_dist)-offset,0.5*max_travel,gd,srt=-74)#
	}#
} else {#
	min_dist <- 100#
	max_dist <- 150#
	nl <- 0.01 #non-linearity#
	max_travel <- 5#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 0  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Attraction",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*((steepness/(steepness+exp(-x-offset+min_dist+(gd^nl*(max_dist-min_dist))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl*(max_dist-min_dist))-offset+min_dist,0.5*max_travel,gd,srt=-74)#
	}#
}
repulsing <- FALSE # Change this to FALSE for clustering#
#
if (repulsing) {#
	max_dist <- 30 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 3 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*(1-(steepness/(steepness+exp(-x-offset+((gd)^nl*max_dist)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl*max_dist)-offset,0.5*max_travel,gd,srt=-74)#
	}#
}
repulsing <- FALSE # Change this to FALSE for clustering#
#
if (repulsing) {#
	max_dist <- 30 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 3 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*(1-(steepness/(steepness+exp(-x-offset+((gd)^nl*max_dist)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl*max_dist)-offset,0.5*max_travel,gd,srt=-74)#
	}#
} else {#
	min_dist <- 100#
	max_dist <- 150#
	nl <- 0.01 #non-linearity#
	max_travel <- 5#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 0  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Attraction",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*((steepness/(steepness+exp(-x-offset+min_dist+(gd^nl*(max_dist-min_dist))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl*(max_dist-min_dist))-offset+min_dist,0.5*max_travel,gd,srt=-74)#
	}#
}
repulsing
repulsing <- TRUE
repulsing <- FALSE # Change this to FALSE for clustering#
#
if (repulsing) {#
	max_dist <- 30 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 3 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*(1-(steepness/(steepness+exp(-x-offset+((gd)^nl*max_dist)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl*max_dist)-offset,0.5*max_travel,gd,srt=-74)#
	}#
} else {#
	min_dist <- 100#
	max_dist <- 150#
	nl <- 0.01 #non-linearity#
	max_travel <- 5#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 0  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Attraction",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*((steepness/(steepness+exp(-x-offset+min_dist+(gd^nl*(max_dist-min_dist))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl*(max_dist-min_dist))-offset+min_dist,0.5*max_travel,gd,srt=-74)#
	}#
}
repulsing
repulsing <- FALSE # Change this to FALSE for clustering#
#
if (repulsing) {#
	max_dist <- 30 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 3 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*(1-(steepness/(steepness+exp(-x-offset+((gd)^nl*max_dist)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl*max_dist)-offset,0.5*max_travel,gd,srt=-74)#
	}#
} else {#
	min_dist <- 100#
	max_dist <- 150#
	nl <- 0.01 #non-linearity#
	max_travel <- 5#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 0  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Attraction",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*((steepness/(steepness+exp(-x-offset+min_dist+(gd^nl*(max_dist-min_dist))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl*(max_dist-min_dist))-offset+min_dist,0.5*max_travel,gd,srt=-74)#
	}#
}
repulsing <- TRUE # Change this to FALSE for clustering#
#
if (repulsing) {#
	max_dist <- 30 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 3 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*(1-(steepness/(steepness+exp(-x-offset+((gd)^nl*max_dist)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl*max_dist)-offset,0.5*max_travel,gd,srt=-74)#
	}#
} else {#
	min_dist <- 100#
	max_dist <- 150#
	nl <- 0.01 #non-linearity#
	max_travel <- 5#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 0  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Attraction",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*((steepness/(steepness+exp(-x-offset+min_dist+(gd^nl*(max_dist-min_dist))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl*(max_dist-min_dist))-offset+min_dist,0.5*max_travel,gd,srt=-74)#
	}#
}
repulsing <- FALSE # Change this to FALSE for clustering#
#
if (repulsing) {#
	max_dist <- 30 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 3 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*(1-(steepness/(steepness+exp(-x-offset+((gd)^nl*max_dist)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl*max_dist)-offset,0.5*max_travel,gd,srt=-74)#
	}#
} else {#
	min_dist <- 100#
	max_dist <- 150#
	nl <- 0.01 #non-linearity#
	max_travel <- 5#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 0  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Attraction",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*((steepness/(steepness+exp(-x-offset+min_dist+(gd^nl*(max_dist-min_dist))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl*(max_dist-min_dist))-offset+min_dist,0.5*max_travel,gd,srt=-74)#
	}#
}
if (repulsing) {#
	max_dist <- 1 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 3 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*(1-(steepness/(steepness+exp(-x-offset+((gd)^nl*max_dist)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl*max_dist)-offset,0.5*max_travel,gd,srt=-74)#
	}#
} else {#
	min_dist <- 100#
	max_dist <- 150#
	nl <- 0.01 #non-linearity#
	max_travel <- 5#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 0  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Attraction",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*((steepness/(steepness+exp(-x-offset+min_dist+(gd^nl*(max_dist-min_dist))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl*(max_dist-min_dist))-offset+min_dist,0.5*max_travel,gd,srt=-74)#
	}#
}
if (repulsing) {#
	max_dist <- 30 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 0 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*(1-(steepness/(steepness+exp(-x-offset+((gd)^nl*max_dist)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl*max_dist)-offset,0.5*max_travel,gd,srt=-74)#
	}#
} else {#
	min_dist <- 100#
	max_dist <- 150#
	nl <- 0.01 #non-linearity#
	max_travel <- 5#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 0  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Attraction",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*((steepness/(steepness+exp(-x-offset+min_dist+(gd^nl*(max_dist-min_dist))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl*(max_dist-min_dist))-offset+min_dist,0.5*max_travel,gd,srt=-74)#
	}#
}
repulsing <- FALSE # Change this to FALSE for clustering#
#
if (repulsing) {#
	max_dist <- 30 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 3 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*(1-(steepness/(steepness+exp(-x-offset+((gd)^nl*max_dist)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl*max_dist)-offset,0.5*max_travel,gd,srt=-74)#
	}#
} else {#
	min_dist <- 1#
	max_dist <- 150#
	nl <- 0.01 #non-linearity#
	max_travel <- 5#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 0  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Attraction",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*((steepness/(steepness+exp(-x-offset+min_dist+(gd^nl*(max_dist-min_dist))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl*(max_dist-min_dist))-offset+min_dist,0.5*max_travel,gd,srt=-74)#
	}#
}
if (repulsing) {#
	max_dist <- 30 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 3 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*(1-(steepness/(steepness+exp(-x-offset+((gd)^nl*max_dist)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl*max_dist)-offset,0.5*max_travel,gd,srt=-74)#
	}#
} else {#
	min_dist <- 10#
	max_dist <- 30#
	nl <- 0.01 #non-linearity#
	max_travel <- 5#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 0  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Attraction",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*((steepness/(steepness+exp(-x-offset+min_dist+(gd^nl*(max_dist-min_dist))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl*(max_dist-min_dist))-offset+min_dist,0.5*max_travel,gd,srt=-74)#
	}#
}
if (repulsing) {#
	max_dist <- 30 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 3 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*(1-(steepness/(steepness+exp(-x-offset+((gd)^nl*max_dist)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl*max_dist)-offset,0.5*max_travel,gd,srt=-74)#
	}#
} else {#
	min_dist <- 10#
	max_dist <- 30#
	nl <- 1 #non-linearity#
	max_travel <- 5#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 0  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Attraction",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*((steepness/(steepness+exp(-x-offset+min_dist+(gd^nl*(max_dist-min_dist))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl*(max_dist-min_dist))-offset+min_dist,0.5*max_travel,gd,srt=-74)#
	}#
}
100*35
3500/60
repulsing <- FALSE # Change this to FALSE for clustering#
#
if (repulsing) {#
	max_dist <- 30 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 3 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*(1-(steepness/(steepness+exp(-x-offset+((gd)^nl*max_dist)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl*max_dist)-offset,0.5*max_travel,gd,srt=-74)#
	}#
} else {#
	min_dist <- 2#
	max_dist <- 30#
	nl <- 3 #non-linearity#
	max_travel <- 5#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 0  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Attraction",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*((steepness/(steepness+exp(-x-offset+min_dist+(gd^nl*(max_dist-min_dist))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl*(max_dist-min_dist))-offset+min_dist,0.5*max_travel,gd,srt=-74)#
	}#
}
repulsing <- FALSE # Change this to FALSE for clustering#
#
if (repulsing) {#
	max_dist <- 30 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 3 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*(1-(steepness/(steepness+exp(-x-offset+((gd)^nl*max_dist)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl*max_dist)-offset,0.5*max_travel,gd,srt=-74)#
	}#
} else {#
	min_dist <- 2#
	max_dist <- 30#
	nl <- 3 #non-linearity#
	max_travel <- 5#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 0  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Attraction",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*((steepness/(steepness+exp(-x-offset+min_dist+(gd^nl*(max_dist-min_dist))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl*(max_dist-min_dist))-offset+min_dist,0.5*max_travel,gd,srt=-74)#
	}#
}#
#
## HOW MANY RUNS BEFORE TAKING QUADRAT#
n_rounds <- 1#
#
n_quadrats <- 15#
quadrat_size <-50#
####  ARENA IS x_max x y_max#
x_min <- 0#
x_max <- 300#
y_min <- 0#
y_max <- 300#
#### CREATE PHYLO TREE WITH INDIVIDUALS#
#
n_default_inds <- 4000#
#
n_species <- 50#
####  RUN FROM HERE - NOTHING MORE TO DO#
#
library(ape)#
library(geiger)#
#
#tree<-rcoal(n_species) # make tree with n_species#
#
tree<-sim.bdtree(b=0.1,d=0,stop="taxa",n=n_species)#
#
rstree<-transform(tree,"depth",1) # rescale tree to have root to tip distance of 1.#
#
# Assign abundances to species in tree#
ab<-rlnorm(n_species,2,1)#
# rescale abundances to be out of n_inds individuals in total#
abpercent<-ab/sum(ab)*100#
abdata<-round(abpercent/100*n_default_inds)#
# replace species that have zero abundance with 1.#
zeroes<-which(abdata==0)#
abdata[zeroes]<-1#
#
regional.community<-data.frame(species=tree$tip.label,abundance=abdata)#
#
# branch lengths between pairs of species#
phydistmatrix<-cophenetic(rstree)#
#### RANDOMLY PLACE INDS IN THE ARENA#
#
n_inds <- sum(regional.community[,2])#
#
inds <- data.frame(SPECIES=rep("",n_inds),X=rep(0,n_inds),Y=rep(0,n_inds))#
inds$SPECIES <- rep(regional.community[,1],regional.community[,2])#
if (repulsing) {#
	# Initial area of the arena occupied by the individuals under phylogenetic repulsion.#
	# change the first term in the first multiplication to zero and the first term in the second multiplication to 1 if I want    	the individuals to occupy the entire arena from the start.#
	inds$X <- sample(c((0*x_max):(1*x_max)),n_inds, replace=T)#
	inds$Y <- sample(c((0*y_max):(1*y_max)),n_inds, replace=T)#
} else {#
	inds$X <- sample(c((x_max):(x_max)),n_inds, replace=T)#
	inds$Y <- sample(c((y_max):(y_max)),n_inds, replace=T)#
}#
inds$X2 <- inds$X#
inds$Y2 <- inds$Y#
inds$REPULSE <- 0#
inds$SPECIES_NUM <- rep(c(1:nrow(phydistmatrix)),regional.community[,2])#
library(colorRamps)#
cols <- blue2green2red(nrow(phydistmatrix))#
#
#### FUNCTION TO DEFINE ANGLE AND DISTANCE#
#
dir_dist <- function(xy2,xy1) {#
	distance <- sqrt((xy1[1]-xy2[1])^2 + (xy1[2]-xy2[2])^2)#
#
	angle <- atan2((c(xy1[2]-xy2[2])),(c(xy1[1]-xy2[1]))) * 180 / pi#
	if (angle <0) angle <- 360+angle#
	angle <- angle-180#
	if (angle <0) angle <- 360+angle#
	return(c(distance,angle))#
}#
#
#### FUNCTION TO CALCULATE REPULSION / ATTRACTION#
#
repulse <- function(gd, distance, max_dist, nl, steepness) {#
	repulsion <- max_travel*(1-(steepness/(steepness+exp(-distance-offset+((1-gd)^nl*max_dist)+1))))#
	return(repulsion)#
}#
#
attract <- function(gd, distance, max_dist, min_dist, nl, steepness) {#
	attraction <- max_travel*((steepness/(steepness+exp(-distance-offset+(gd^nl*(max_dist-min_dist))+1))))#
	return(attraction)#
}#
#
#### FUNCTION TO CALCULATE NEWX AND NEWY#
#
travel <- function(inputs) {  # inputs <- x, y, angle, repulsion#
	xy <- inputs[c(1,2)]#
	angle <- inputs[3]#
	repulsion <- inputs[4]#
	if (angle < 180) {#
		angle <- angle * pi / 180#
		newx <- xy[1]-repulsion*cos(angle)#
		newy <- xy[2]-repulsion*sin(angle)#
	} else {#
		angle <- angle - 180#
		angle <- angle * pi / 180#
		newx <- xy[1]+repulsion*cos(angle)#
		newy <- xy[2]+repulsion*sin(angle)#
	}#
	return(c(newx,newy))#
#
}	#
#
#### FUNCTION TO ROUND TO +- MAX TRAVEL#
#
round_travel <- function(distance) {#
	if (distance < 0) #
		return(max(distance,-max_travel))#
	else#
		return(min(distance,max_travel))#
}#
#
#### GIVE EACH INDIVIDUAL A CHANCE TO RELOCATE#
plot(inds$X,inds$Y,pch=20,cex=0.5, xlim=c(0,x_max),ylim=c(0,y_max), col=cols[inds$SPECIES_NUM])#
for (zz in c(1:n_rounds)) {#
#
	for (yy in sample(c(1:nrow(inds)),nrow(inds),replace=FALSE)) {#
		xy2 <- as.matrix(inds[yy,c(2,3)])#
		# Put point in center of arena to avoid boundary issues#
		xy <- xy2#
		xy[1] <- xy2[1]+(0.5*x_max-xy2[1])#
		xy[2] <- xy2[2]+(0.5*y_max-xy2[2])#
		inds$X2 <- inds$X+(0.5*x_max-xy2[1])#
		inds$Y2 <- inds$Y+(0.5*y_max-xy2[2])#
		inds$X2[inds$X2 > x_max] <- inds$X2[inds$X2 > x_max]-x_max#
		inds$Y2[inds$Y2 > y_max] <- inds$Y2[inds$Y2 > y_max]-y_max#
		inds$X2[inds$X2 < 0] <- inds$X2[inds$X2 < 0]+x_max#
		inds$Y2[inds$Y2 < 0] <- inds$Y2[inds$Y2 < 0]+y_max#
		# identify individuals within 15m#
		distances <- sqrt((inds$X2[yy]-inds$X2[-yy])^2 + (inds$Y2[yy]-inds$Y2[-yy])^2)#
		if (repulsing) {#
			locals <- inds[-yy,][distances < max_dist ,]#
		} else {#
			locals <- inds[-yy,][distances > min_dist & distances < max_dist ,]#
		}#
		if (nrow(locals) > 0) {#
			# calculate angles, distances and repulsions#
			distances <- t(apply(as.matrix(locals[,c(4,5)]),1,dir_dist,xy))#
			if (repulsing) {#
				repulsions <- repulse(phydistmatrix[inds$SPECIES_NUM[yy],locals$SPECIES_NUM],distances[,1],rep(max_dist,nrow(locals)),rep(nl,nrow(locals)),rep(steepness,nrow(locals)))#
			} else {#
				repulsions <- -attract(phydistmatrix[inds$SPECIES_NUM[yy],locals$SPECIES_NUM],distances[,1],rep(max_dist,nrow(locals)),rep(min_dist,nrow(locals)),rep(nl,nrow(locals)),rep(steepness,nrow(locals)))#
			}#
			# calculate new xs and ys#
			inputs <- cbind(rep(xy[1],nrow(locals)),rep(xy[2],nrow(locals)),distances[,2],repulsions)#
			travels <- t(apply(inputs,1,travel))#
			x_travel <- round_travel(sum(travels[,1] - (0.5*x_max)))#
			y_travel <- round_travel(sum(travels[,2] - (0.5*y_max)))#
			inds$X[yy] <- inds$X[yy] + x_travel#
			inds$Y[yy] <- inds$Y[yy] + y_travel#
			inds$X2[yy] <- inds$X2[yy] + x_travel#
			inds$Y2[yy] <- inds$Y2[yy] + y_travel#
			if (inds$X[yy] < 0) #
				inds$X[yy] <- x_max+(x_travel)-xy2[1]#
			if (inds$X[yy] > x_max)#
				inds$X[yy] <- inds$X[yy]-x_max#
			if (inds$Y[yy] < 0) #
				inds$Y[yy] <- y_max+(y_travel)-xy2[2]#
			if (inds$Y[yy] > y_max)#
				inds$Y[yy] <- inds$Y[yy]-y_max#
			distances <- t(apply(as.matrix(locals[,c(4,5)]),1,dir_dist,as.matrix(inds[yy,c(4,5)])))#
			inds$REPULSE[yy] <- sum(phydistmatrix[inds$SPECIES_NUM[yy],locals$SPECIES_NUM],distances[,1],max_dist,nl,steepness)#
		} else {#
			inds$REPULSE[yy] <- 0#
		}#
	}#
	plot(inds$X,inds$Y,pch=20,cex=0.5, xlim=c(0,x_max),ylim=c(0,y_max), col=cols[inds$SPECIES_NUM])#
	if (proportion_replaced > 0) {#
	if (zz < (n_rounds-(0.1*n_rounds))) {#
		for (i in c(1:(proportion_replaced*n_inds))) {#
			inds[which.max(inds$REPULSE),]$X <- sample(c(1:x_max),1)#
			inds[which.max(inds$REPULSE),]$Y <- sample(c(1:y_max),1)#
			inds[which.max(inds$REPULSE),]$REPULSE <- 0#
		}	#
	}#
	}#
	print(zz)#
}#
#####  TAKE QUADRATS#
#
plot(inds$X,inds$Y,pch=20,cex=0.5, xlim=c(0,x_max),ylim=c(0,y_max), col=cols[inds$SPECIES_NUM])#
#
quadrat_bounds <- matrix(0,nrow=n_quadrats,ncol=4)#
colnames(quadrat_bounds) <- c("X1","X2","Y1","Y2")#
#
for (i in c(1:n_quadrats)) {#
#
	repeat {#
	OK <- TRUE#
	quadrat_bounds[i,1] <- sample(c(0:(x_max-quadrat_size)),1)#
	quadrat_bounds[i,2] <- quadrat_bounds[i,1] + quadrat_size#
	quadrat_bounds[i,3] <- sample(c(0:(y_max-quadrat_size)),1)#
	quadrat_bounds[i,4] <- quadrat_bounds[i,3] + quadrat_size#
	if (i > 1) {#
	for (j in c(1:(i-1))) {#
		if (any(#
			quadrat_bounds[i,1] %in% c(quadrat_bounds[j,1]:quadrat_bounds[j,2]) & quadrat_bounds[i,3] %in% c(quadrat_bounds[j,3]:quadrat_bounds[j,4]),#
			quadrat_bounds[i,2] %in% c(quadrat_bounds[j,1]:quadrat_bounds[j,2]) & quadrat_bounds[i,3] %in% c(quadrat_bounds[j,3]:quadrat_bounds[j,4]),#
			quadrat_bounds[i,1] %in% c(quadrat_bounds[j,1]:quadrat_bounds[j,2]) & quadrat_bounds[i,4] %in% c(quadrat_bounds[j,3]:quadrat_bounds[j,4]),#
			quadrat_bounds[i,2] %in% c(quadrat_bounds[j,1]:quadrat_bounds[j,2]) & quadrat_bounds[i,4] %in% c(quadrat_bounds[j,3]:quadrat_bounds[j,4])#
			)) {#
			OK <- FALSE#
		}#
	}#
	}#
	if (OK == TRUE) {#
		break;#
	}#
	}#
	polygon(c(quadrat_bounds[i,1],quadrat_bounds[i,2],quadrat_bounds[i,2],quadrat_bounds[i,1]),c(quadrat_bounds[i,3],quadrat_bounds[i,3],quadrat_bounds[i,4],quadrat_bounds[i,4]))#
#
}#
#####  RECORD WHATS IN QUADRATS, RETURNING A DATA FRAME#
#
species <- unique(inds$SPECIES)#
results <- matrix(0, ncol=n_quadrats, nrow=length(species))#
rownames(results) <- species#
#
for (i in c(1:n_quadrats)) {#
#
	in_quadrat <- inds$SPECIES[inds$X >= quadrat_bounds[i,1] & inds$X <= quadrat_bounds[i,2] & inds$Y >= quadrat_bounds[i,3] & inds$Y <= quadrat_bounds[i,4]]#
#
	for (j in c(1:length(species))) {#
		results[j,i] <- sum(in_quadrat == species[j])#
	}#
#
}
results
test <- rlnorm(1000)
hist(test)
test <- rnorm(1000)
hist(test)
test2 <- rnorm(1000)
test2 <- sqrt(test2)
hist(test2)
DEFINE A FUNCTION OF ATTRACTION REPULSION ACCORDING TO GD AND SPATIAL DISTANCE (1-ATTRACTION)#
#
repulsing <- FALSE # Change this to FALSE for clustering#
#
if (repulsing) {#
	max_dist <- 30 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 3 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*(1-(steepness/(steepness+exp(-x-offset+((gd)^nl*max_dist)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl*max_dist)-offset,0.5*max_travel,gd,srt=-74)#
	}#
} else {#
	min_dist <- 2#
	max_dist <- 30#
	nl <- 3 #non-linearity#
	max_travel <- 5#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 0  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Attraction",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*((steepness/(steepness+exp(-x-offset+min_dist+(gd^nl*(max_dist-min_dist))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl*(max_dist-min_dist))-offset+min_dist,0.5*max_travel,gd,srt=-74)#
	}#
}#
#
## HOW MANY RUNS BEFORE TAKING QUADRAT#
n_rounds <- 100#
#
n_quadrats <- 15#
quadrat_size <-50#
####  ARENA IS x_max x y_max#
x_min <- 0#
x_max <- 300#
y_min <- 0#
y_max <- 300#
#### CREATE PHYLO TREE WITH INDIVIDUALS#
#
n_default_inds <- 4000#
#
n_species <- 50#
####  RUN FROM HERE - NOTHING MORE TO DO#
#
library(ape)#
library(geiger)#
#
#tree<-rcoal(n_species) # make tree with n_species#
#
tree<-sim.bdtree(b=0.1,d=0,stop="taxa",n=n_species)#
#
rstree<-transform(tree,"depth",1) # rescale tree to have root to tip distance of 1.#
#
# Assign abundances to species in tree#
ab<-rlnorm(n_species,2,1)#
# rescale abundances to be out of n_inds individuals in total#
abpercent<-ab/sum(ab)*100#
abdata<-round(abpercent/100*n_default_inds)#
# replace species that have zero abundance with 1.#
zeroes<-which(abdata==0)#
abdata[zeroes]<-1#
#
regional.community<-data.frame(species=tree$tip.label,abundance=abdata)#
#
# branch lengths between pairs of species#
phydistmatrix<-cophenetic(rstree)
rstree$edge.length
max(rstree$edge.length)
0.001:1 -> test
test
1:5
seq(from=0.001, to=1, by=0.1)
seq(from=0.001, to=1, by=0.1)->test
sqrt(test)
repulsing <- FALSE # Change this to FALSE for clustering#
#
if (repulsing) {#
	max_dist <- 30 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 3 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*(1-(steepness/(steepness+exp(-x-offset+((gd)^nl*max_dist)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl*max_dist)-offset,0.5*max_travel,gd,srt=-74)#
	}#
} else {#
	min_dist <- 0#
	max_dist <- 30#
	nl <- 3 #non-linearity#
	max_travel <- 5#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 0  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Attraction",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*((steepness/(steepness+exp(-x-offset+min_dist+(gd^nl*(max_dist-min_dist))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl*(max_dist-min_dist))-offset+min_dist,0.5*max_travel,gd,srt=-74)#
	}#
}
repulsing <- FALSE # Change this to FALSE for clustering#
#
if (repulsing) {#
	max_dist <- 30 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 3 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*(1-(steepness/(steepness+exp(-x-offset+((gd)^nl*max_dist)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl*max_dist)-offset,0.5*max_travel,gd,srt=-74)#
	}#
} else {#
	min_dist <- 0#
	max_dist <- 30#
	nl <- 0.01 #non-linearity#
	max_travel <- 5#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 0  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Attraction",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*((steepness/(steepness+exp(-x-offset+min_dist+(gd^nl*(max_dist-min_dist))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl*(max_dist-min_dist))-offset+min_dist,0.5*max_travel,gd,srt=-74)#
	}#
}
repulsing <- FALSE # Change this to FALSE for clustering#
#
if (repulsing) {#
	max_dist <- 30 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 3 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*(1-(steepness/(steepness+exp(-x-offset+((gd)^nl*max_dist)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl*max_dist)-offset,0.5*max_travel,gd,srt=-74)#
	}#
} else {#
	min_dist <- 0#
	max_dist <- 30#
	nl <- 1 #non-linearity#
	max_travel <- 5#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 0  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Attraction",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*((steepness/(steepness+exp(-x-offset+min_dist+(gd^nl*(max_dist-min_dist))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl*(max_dist-min_dist))-offset+min_dist,0.5*max_travel,gd,srt=-74)#
	}#
}
repulsing <- FALSE # Change this to FALSE for clustering#
#
if (repulsing) {#
	max_dist <- 30 # maximum distance at which an individual is affected by neighbouring individuals.#
	nl <- 3 #non-linearity#
	max_travel <- 5 # maximum distance an individual will move in a single iteration of the model. This is what is called repulsion and reported for the y-axis of the plot. Change this to a smaller value if I want the individuals to make smaller distance moves in each run, and so be more influenced by the composition of their neighbourhodd through time. With a high number an individual can make a large distance move, and when doing this it does not take into consideration the neighbourhood where it will end up. The only decision in this model is how far and in what direction to move away from the individual's current neighbourhood, i.e. only consider current and not potential neighbours.#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*(1-(steepness/(steepness+exp(-x-offset+((gd)^nl*max_dist)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl*max_dist)-offset,0.5*max_travel,gd,srt=-74)#
	}#
} else {#
	min_dist <- 0#
	max_dist <- 30#
	nl <- 10 #non-linearity#
	max_travel <- 5#
	steepness <- 1#
	proportion_replaced <- 0#
	offset <- 0  ## moves left or right in reverse direction#
#
	x <- seq(0,max_dist,0.2)#
	plot(NULL,ylim=c(0,max_travel),xlim=c(0,max_dist),xlab="Distance",ylab="Attraction",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel*((steepness/(steepness+exp(-x-offset+min_dist+(gd^nl*(max_dist-min_dist))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl*(max_dist-min_dist))-offset+min_dist,0.5*max_travel,gd,srt=-74)#
	}#
}
this is the code to run all final analyses for the Meliphagid manuscript for phylo#
##community structure across australia with the phylogeny of uncorrected molecular#
##divergences, provided to us#
##by arpi, and then modified by me to include some species (for which we made up#
##branch lengths according to code in another text file in this same folder) and to #
##include the topology of the Melithreptus per Toon et al. note that there have been many#
##previous versions of this script. this is the version that will be used to generate#
##the final revision, to Ecology Letters. a major change from previous versions#
##is that I am now using Atlas of Living Australia data. have tried to generalize many#
##functions, etc., so that can deal with different datasets an situations, but still a lot#
##of unique, situation-specific fiddling of data tables in here. THIS SCRIPT IS POLISHED,#
##in that it should run cleanly from front to back, with no simulations within it (loading#
##summary results of nulls, etc), and nicely annotated.#
###########################################################################################
####################SECTIONS ARE BROKEN BY HEADERS LIKE THIS###############################
###########################################################################################
#
##set your working directory manually#
#
library(hdrcde)#
library(plyr)#
library(phytools)#
library(picante)#
library(plotrix)#
library(vegan)#
library(fitContinuousMCMC)#
#
###########################################################################################
####################LOAD TREE###############################
###########################################################################################
#
meliphagidae_initial <- read.tree("meli3.tre")#
#
###########################################################################################
####################LOAD RAW DATA AND PROCESS INTO MATRICES###############################
###########################################################################################
#
##bring in the taxonomically and spatially cleaned meliphagidae database, with #
##associated notes. i could use the hashed out read.csv() below, but it loads more slowly #
##than read.table(). however, note that this argument will need to be carefully modified #
##if you ever change the raw data input. your date is coming in as a factor, you'll have #
##to coerce it to POSIXlt if you ever want to use it#
#
raw.coll <- read.table("meli_final_output.txt", header=TRUE, sep=",", nrows=2266013, colClasses=c("integer", rep("factor", 7), rep("numeric", 2), rep("factor", 3), "numeric", rep("factor", 7), rep("numeric", 3)), comment.char="")#
#
##raw.coll <- read.csv("meli_final_output.txt")#
#
##rename the columns to reflect which grid cell they came from (they were output with weird names from GIS). note that after this step i usually refer to and perform functions on 50 before 200.#
#
names(raw.coll)[22] = "ID_100"#
names(raw.coll)[23] = "ID_200"#
names(raw.coll)[24] = "ID_50"#
#
##create community data matrices (CDMs). start by simply summarizing the raw collections into grid cell occurrences. note that there will be two forms of this, one where occurrences are simply number of points per grid cell, and another where "occurrences" are sum of counts per grid cell#
##the idata.frame command seems to speed the hell up out of this (about a 3 fold difference when i tested it last). #
##however, it stopped working with a recent R update, so i had to hash those out. that made it run unbearably slow, so i am minimizing the database before running these#
#
##the second argument of the ddply function (the c("grid","species")), splits it first by grid, then by species. works great, did a test run with a smaller dataset#
#
raw.coll2 <- data.frame(raw.coll$Species_Cleaned, raw.coll$Count_, raw.coll$ID_100, raw.coll$ID_200, raw.coll$ID_50)#
#
names(raw.coll2) <- c("Species_Cleaned", "Count_", "ID_100", "ID_200", "ID_50")#
#
rm(raw.coll)#
#
##this clears the memory (at least somewhat)#
#
gc()#
#
##cdm.onehund.ini <- ddply(idata.frame(raw.coll), c("ID_100","Species_Cleaned"), summarise, occurrences=length(Count_), count=sum(Count_))#
##cdm.fifty.ini <- ddply(idata.frame(raw.coll), c("ID_50","Species_Cleaned"), summarise, occurrences=length(Count_), count=sum(Count_))#
##cdm.twohund.ini <- ddply(idata.frame(raw.coll), c("ID_200","Species_Cleaned"), summarise, occurrences=length(Count_), count=sum(Count_))#
#
cdm.onehund.ini <- ddply(raw.coll2, c("ID_100","Species_Cleaned"), summarise, occurrences=length(Count_), count=sum(Count_))#
cdm.fifty.ini <- ddply(raw.coll2, c("ID_50","Species_Cleaned"), summarise, occurrences=length(Count_), count=sum(Count_))#
cdm.twohund.ini <- ddply(raw.coll2, c("ID_200","Species_Cleaned"), summarise, occurrences=length(Count_), count=sum(Count_))#
#
##the following two commands, which I will normally keep hashed out, will generate and save pdfs of the abundance curves for all species#
##before any cuts for effort or land area#
#
#taxa <- unique(cdm.fifty.ini$Species_Cleaned)#
#
#for(i in 1:75)#
##{#
##	filename <- paste(as.character(taxa[i]), "pdf", sep=".")#
##	pdf(file = filename)#
##	hist(log10(cdm.fifty.ini$count[cdm.fifty.ini$Species_Cleaned==taxa[i]]), main = "Log10 of total counts per 50x50 km grid", xlab=taxa[i])#
##	dev.off()#
##}#
#
##continue processing your CDMs. start with just the occurrences#
#
cdm.occ.onehund <- data.frame(cdm.onehund.ini$ID_100, cdm.onehund.ini$occurrences, cdm.onehund.ini$Species_Cleaned)#
cdm.occ.fifty <- data.frame(cdm.fifty.ini$ID_50, cdm.fifty.ini$occurrences, cdm.fifty.ini$Species_Cleaned)#
cdm.occ.twohund <- data.frame(cdm.twohund.ini$ID_200, cdm.twohund.ini$occurrences, cdm.twohund.ini$Species_Cleaned)#
#
##simplify the names of the columns#
#
names(cdm.occ.onehund) <- c("V1","V2","V3")#
names(cdm.occ.fifty) <- c("V1","V2","V3")#
names(cdm.occ.twohund) <- c("V1","V2","V3")#
#
##repeat for the actual counts#
#
cdm.count.onehund <- data.frame(cdm.onehund.ini$ID_100, cdm.onehund.ini$count, cdm.onehund.ini$Species_Cleaned)#
cdm.count.fifty <- data.frame(cdm.fifty.ini$ID_50, cdm.fifty.ini$count, cdm.fifty.ini$Species_Cleaned)#
cdm.count.twohund <- data.frame(cdm.twohund.ini$ID_200, cdm.twohund.ini$count, cdm.twohund.ini$Species_Cleaned)#
#
##simplify the names of the columns#
#
names(cdm.count.onehund) <- c("V1","V2","V3")#
names(cdm.count.fifty) <- c("V1","V2","V3")#
names(cdm.count.twohund) <- c("V1","V2","V3")#
#
##make a table of the number of observations made in each grid. start with just occurrences#
#
coll.occ.onehund <- ddply(cdm.onehund.ini, "ID_100", summarise, observations=sum(occurrences))#
coll.occ.fifty <- ddply(cdm.fifty.ini, "ID_50", summarise, observations=sum(occurrences))#
coll.occ.twohund <- ddply(cdm.twohund.ini, "ID_200", summarise, observations=sum(occurrences))#
#
##repeat for the actual counts#
#
coll.count.onehund <- ddply(cdm.onehund.ini, "ID_100", summarise, observations=sum(count))#
coll.count.fifty <- ddply(cdm.fifty.ini, "ID_50", summarise, observations=sum(count))#
coll.count.twohund <- ddply(cdm.twohund.ini, "ID_200", summarise, observations=sum(count))#
#
##and a table of the number of species in each grid#
#
rich.onehund <- ddply(cdm.onehund.ini, "ID_100", summarise, richness=length(occurrences))#
rich.fifty <- ddply(cdm.fifty.ini, "ID_50", summarise, richness=length(occurrences))#
rich.twohund <- ddply(cdm.twohund.ini, "ID_200", summarise, richness=length(occurrences))#
#
###########################################################################################
####################RAREFACTION, RICHNESS, and CONTINUE PROCESSING CDMS####################
###########################################################################################
#
##use the vegan function estimateR to extrapolate the expected species richness for each site based on the abundances at that site. this function takes a standard CDM, so convert to that format using picante's sample2matrix function. begin with just the occurrences#
#
est.occ.onehund <- estimateR(sample2matrix(cdm.occ.onehund))#
est.occ.fifty <- estimateR(sample2matrix(cdm.occ.fifty))#
est.occ.twohund <- estimateR(sample2matrix(cdm.occ.twohund))#
#
##move on to counts.#
#
est.count.onehund <- estimateR(sample2matrix(cdm.count.onehund))#
est.count.fifty <- estimateR(sample2matrix(cdm.count.fifty))#
est.count.twohund <- estimateR(sample2matrix(cdm.count.twohund))#
#
##the piece we are most interested in from these estimated species richnesses is the second row of the matrix, the S.chao1. for whatever reason, the ACE estimate of species richness spits a lot of NAs, so we won't use that one.#
##another thing of note here is that grid cells with a single count of a single bird seem to be interpreted as having only one species. so we'll need to find some minimum number of counts necessary independent of the rarefaction (e.g. >5 counts)#
##generate a vector of the percentage observed of the expected species. begin with occurrences#
#
percent.occ.onehund <- est.occ.onehund[1,]/est.occ.onehund[2,]#
percent.occ.fifty <- est.occ.fifty[1,]/est.occ.fifty[2,]#
percent.occ.twohund <- est.occ.twohund[1,]/est.occ.twohund[2,]#
#
##move on to actual counts#
#
percent.count.onehund <- est.count.onehund[1,]/est.count.onehund[2,]#
percent.count.fifty <- est.count.fifty[1,]/est.count.fifty[2,]#
percent.count.twohund <- est.count.twohund[1,]/est.count.twohund[2,]#
#
##determined maximum species richness per grid cell#
#
##subset the collections to only those grids with at least 34 collections for 100, 33 for fifty, and 37 for twohund. use  these numbers are arbitrary, but can make a decent verbal argument as to the reasons why I chose them (would never be able to count the maximum number of species in a grid cell without at least the number of observations as that many species)#
##more importantly, do need to cut it above 1, at bare minimum, due to problem noted above in rarefaction section. in practice, making these small cuts would only remove--after the counts we'll be making anyhow for rarefaction--an additional ~4% of the remaining cells at 100km, 17% at 50km, and 2% at 200km.#
#
min_collections.onehund <- subset(coll.occ.onehund, observations > 33)#
min_collections.fifty <- subset(coll.occ.fifty, observations > 32)#
min_collections.twohund <- subset(coll.occ.twohund, observations > 36)#
#
##doing this goes from 100 km cells: 890 -> 852#
##50 km cells: 3238 -> 2435#
##200 km cells: 253 -> 247#
#
##make a vector of the grid ids that meet this requirement#
#
grdid.onehund <- min_collections.onehund$ID_100#
grdid.fifty <- min_collections.fifty$ID_50#
grdid.twohund <- min_collections.twohund$ID_200#
#
##the following is very neat code. what it does is subset the cdm to all cases where#
##the left operand (cdm_initial$V1) matches the vector grdid#
#
cdm.occ.onehund <- subset(cdm.occ.onehund, cdm.occ.onehund$V1 %in% grdid.onehund)#
cdm.occ.fifty <- subset(cdm.occ.fifty, cdm.occ.fifty$V1 %in% grdid.fifty)#
cdm.occ.twohund <- subset(cdm.occ.twohund, cdm.occ.twohund$V1 %in% grdid.twohund)#
#
cdm.count.onehund <- subset(cdm.count.onehund, cdm.count.onehund$V1 %in% grdid.onehund)#
cdm.count.fifty <- subset(cdm.count.fifty, cdm.count.fifty$V1 %in% grdid.fifty)#
cdm.count.twohund <- subset(cdm.count.twohund, cdm.count.twohund$V1 %in% grdid.twohund)#
#
##now make the cuts based on the rarefaction analysis. 90% seems like a very believable number and it doesn't lose an ungodly number of cells. HOWEVER! cell 607 in the 100km grid cell size is estimated to have 84% of species sampled. this is the only cell with Lichenostomus_hindwoodi in it. tried first running the analysis with 84%, but it let quite a bit of slop in. instead, add grid cell 607 in manually. begin with occurrences#
#
cdm.occ.onehund <- cdm.occ.onehund[cdm.occ.onehund$V1 %in% c(names(percent.occ.onehund[percent.occ.onehund > 0.9]), 607), ]#
cdm.occ.fifty <- cdm.occ.fifty[cdm.occ.fifty$V1 %in% names(percent.occ.fifty[percent.occ.fifty > 0.9]), ]#
cdm.occ.twohund <- cdm.occ.twohund[cdm.occ.twohund$V1 %in% names(percent.occ.twohund[percent.occ.twohund > 0.9]), ]#
#
##now move on to counts#
#
cdm.count.onehund <- cdm.count.onehund[cdm.count.onehund$V1 %in% names(percent.count.onehund[percent.count.onehund > 0.9]), ]#
cdm.count.fifty <- cdm.count.fifty[cdm.count.fifty$V1 %in% names(percent.count.fifty[percent.count.fifty > 0.9]), ]#
cdm.count.twohund <- cdm.count.twohund[cdm.count.twohund$V1 %in% names(percent.count.twohund[percent.count.twohund > 0.9]), ]#
#
##pull out the final gridids you will use. begin with occurrences#
#
grdid.occ.onehund <- unique(cdm.occ.onehund$V1)#
grdid.occ.fifty <- unique(cdm.occ.fifty$V1)#
grdid.occ.twohund <- unique(cdm.occ.twohund$V1)#
#
##move on to counts#
#
grdid.count.onehund <- unique(cdm.count.onehund$V1)#
grdid.count.fifty <- unique(cdm.count.fifty$V1)#
grdid.count.twohund <- unique(cdm.count.twohund$V1)#
#
##calculate Shannon diversity indices for all the different grid cells so that you can calculate Pielou's evenness index. begin with occurrences#
#
H.occ.onehund <- diversity(sample2matrix(cdm.occ.onehund))#
H.occ.fifty <- diversity(sample2matrix(cdm.occ.fifty))#
H.occ.twohund <- diversity(sample2matrix(cdm.occ.twohund))#
#
##move on to counts#
#
H.count.onehund <- diversity(sample2matrix(cdm.count.onehund))#
H.count.fifty <- diversity(sample2matrix(cdm.count.fifty))#
H.count.twohund <- diversity(sample2matrix(cdm.count.twohund))#
#
##I NO LONGER CARE TO MAKE CUTS BASED ON PERCENT LAND AFTER THE RAREFACTION ANALYSIS, so that section of the code has been removed. see old archived files for this code if necessary#
#
###########################################################################################
####################BRING IN THE BIOMEANS FOR ALL THREE GRID CELLS#########################
###########################################################################################
#
biomeans.onehund <- read.csv("biomeans_onehund.csv", header=TRUE, sep=",")#
biomeans.fifty <- read.csv("biomeans_fifty.csv", header=TRUE, sep=",")#
biomeans.twohund <- read.csv("biomeans_twohund.csv", header=TRUE, sep=",")#
#
###########################################################################################
####################CONVERT BETWEEN CDM FORMATS AND CONTINUE PROCESSING CDMS###############
###########################################################################################
#
##use picante's sample2matrix function to convert the phylocom style matrix#
##into a picante matrix#
#
cdm.occ.onehund <- sample2matrix(cdm.occ.onehund)#
cdm.occ.fifty <- sample2matrix(cdm.occ.fifty)#
cdm.occ.twohund <- sample2matrix(cdm.occ.twohund)#
#
cdm.count.onehund <- sample2matrix(cdm.count.onehund)#
cdm.count.fifty <- sample2matrix(cdm.count.fifty)#
cdm.count.twohund <- sample2matrix(cdm.count.twohund)#
#
##FYI this function isn't actually doing anything, since it's pruning according to#
##the column names in the cdm, and there is a column in there for all taxa, includ-#
##ing any that were cut in the above processes#
#
meliphagidae <- prune.sample(cdm.occ.onehund,meliphagidae_initial)#
#
###########################################################################################
####################CALCULATE PAIRWISE DISTANCES AMONG TAXA & CONTINUE PROCESSING CDMS#####
###########################################################################################
#
dists <- cophenetic(meliphagidae)#
#
##now subset the biomeans to only those grd cells we will analyze (based on cuts#
##above). begin with occurrences (remember that these are slightly dissimilar sets of grdids so need to keep separate the whole way)#
##importantly, for reasons i can't quite figure out, all the biomeans files are missing between 1 and 3 rows worth of environmental data as compared to the grid cells i want to analyze. lose a very small proportion here of samples, for reasons i can't figure out #
#
biomeans.occ.onehund <- subset(biomeans.onehund, biomeans.onehund$id %in% grdid.occ.onehund)#
biomeans.occ.fifty <- subset(biomeans.fifty, biomeans.fifty$gridcell %in% grdid.occ.fifty)#
biomeans.occ.twohund <- subset(biomeans.twohund, biomeans.twohund$gridcell %in% grdid.occ.twohund)#
#
##move on to counts.#
#
biomeans.count.onehund <- subset(biomeans.onehund, biomeans.onehund$id %in% grdid.count.onehund)#
biomeans.count.fifty <- subset(biomeans.fifty, biomeans.fifty$gridcell %in% grdid.count.fifty)#
biomeans.count.twohund <- subset(biomeans.twohund, biomeans.twohund$gridcell %in% grdid.count.twohund)#
#
###########################################################################################
####################DEFINE THE MODIFIED MPD FUNCTION###############################
###########################################################################################
#
modified.mpd <- function (samp, dis, abundance.weighted = FALSE) #
{#
    N <- dim(samp)[1]#
    mpd <- numeric(N)#
    for (i in 1:N) {#
        sppInSample <- names(samp[i, samp[i, ] > 0])#
        if (length(sppInSample) > 1) {#
            sample.dis <- dis[sppInSample, sppInSample]#
            if (abundance.weighted == "interspecific") {#
                sample.weights <- t(as.matrix(samp[i, sppInSample, #
                  drop = FALSE])) %*% as.matrix(samp[i, sppInSample, #
                  drop = FALSE])#
	            diag(sample.weights) <- 0#
                mpd[i] <- weighted.mean(sample.dis, sample.weights)#
            }#
            else if (abundance.weighted == "intraspecific") {#
                sample.weights <- t(as.matrix(samp[i, sppInSample, #
                  drop = FALSE])) %*% as.matrix(samp[i, sppInSample, #
                  drop = FALSE])#
	            diag(sample.weights) <- diag(sample.weights) - sqrt(diag(sample.weights))#
                mpd[i] <- weighted.mean(sample.dis, sample.weights)#
            }#
            else if (abundance.weighted == "complete") {#
                sample.weights <- t(as.matrix(samp[i, sppInSample, #
                  drop = FALSE])) %*% as.matrix(samp[i, sppInSample, #
                  drop = FALSE])#
                mpd[i] <- weighted.mean(sample.dis, sample.weights)#
            }#
            else {#
                mpd[i] <- mean(sample.dis[lower.tri(sample.dis)])#
            }#
        }#
        else {#
            mpd[i] <- NA#
        }#
    }#
    mpd#
}#
#
###########################################################################################
####################USE THE MPD FUNCTION ON THE PROCESSED CDMS#############################
###########################################################################################
#
##calculate non-abundance-weighted mean pairwise distance for these grid cells. note that you could use either cdm.occ or cdm.count here IF they were the same grid cells that you'll bind back to later. But because they are different, have to re-run it for both#
#
noabund.MPD.occ.onehund <- modified.mpd(cdm.occ.onehund, dists, abundance.weighted=FALSE)#
noabund.MPD.occ.fifty <- modified.mpd(cdm.occ.fifty, dists, abundance.weighted=FALSE)#
noabund.MPD.occ.twohund <- modified.mpd(cdm.occ.twohund, dists, abundance.weighted=FALSE)#
#
##re-run it for counts#
#
noabund.MPD.count.onehund <- modified.mpd(cdm.count.onehund, dists, abundance.weighted=FALSE)#
noabund.MPD.count.fifty <- modified.mpd(cdm.count.fifty, dists, abundance.weighted=FALSE)#
noabund.MPD.count.twohund <- modified.mpd(cdm.count.twohund, dists, abundance.weighted=FALSE)#
#
##calculate interspecific-abundance-weighted MPD on the occurrence cdms#
#
inter.MPD.occ.onehund <- modified.mpd(cdm.occ.onehund, dists, abundance.weighted="interspecific")#
inter.MPD.occ.fifty <- modified.mpd(cdm.occ.fifty, dists, abundance.weighted="interspecific")#
inter.MPD.occ.twohund <- modified.mpd(cdm.occ.twohund, dists, abundance.weighted="interspecific")#
#
##calculate interspecific-abundance-weighted MPD on the count cdms. #
#
inter.MPD.count.onehund <- modified.mpd(cdm.count.onehund, dists, abundance.weighted="interspecific")#
inter.MPD.count.fifty <- modified.mpd(cdm.count.fifty, dists, abundance.weighted="interspecific")#
inter.MPD.count.twohund <- modified.mpd(cdm.count.twohund, dists, abundance.weighted="interspecific")#
#
##calculate intraspecific-abundance-weighted MPD on the occurrence cdms#
#
intra.MPD.occ.onehund <- modified.mpd(cdm.occ.onehund, dists, abundance.weighted="intraspecific")#
intra.MPD.occ.fifty <- modified.mpd(cdm.occ.fifty, dists, abundance.weighted="intraspecific")#
intra.MPD.occ.twohund <- modified.mpd(cdm.occ.twohund, dists, abundance.weighted="intraspecific")#
#
##calculate intraspecific-abundance-weighted MPD on the count cdms. #
#
intra.MPD.count.onehund <- modified.mpd(cdm.count.onehund, dists, abundance.weighted="intraspecific")#
intra.MPD.count.fifty <- modified.mpd(cdm.count.fifty, dists, abundance.weighted="intraspecific")#
intra.MPD.count.twohund <- modified.mpd(cdm.count.twohund, dists, abundance.weighted="intraspecific")#
#
##calculate complete-abundance-weighted MPD on the occurrence cdms#
#
complete.MPD.occ.onehund <- modified.mpd(cdm.occ.onehund, dists, abundance.weighted="complete")#
complete.MPD.occ.fifty <- modified.mpd(cdm.occ.fifty, dists, abundance.weighted="complete")#
complete.MPD.occ.twohund <- modified.mpd(cdm.occ.twohund, dists, abundance.weighted="complete")#
#
##calculate complete-abundance-weighted MPD on the count cdms#
#
complete.MPD.count.onehund <- modified.mpd(cdm.count.onehund, dists, abundance.weighted="complete")#
complete.MPD.count.fifty <- modified.mpd(cdm.count.fifty, dists, abundance.weighted="complete")#
complete.MPD.count.twohund <- modified.mpd(cdm.count.twohund, dists, abundance.weighted="complete")#
#
###########################################################################################
####################CONCATENATE RESULTS INTO USEFUL TABLES###############################
###########################################################################################
#
##pull out only those richnesses that went into the analysis. begin with occurrences#
#
rich.occ.onehund <- subset(rich.onehund, rich.onehund$ID_100 %in% grdid.occ.onehund)#
rich.occ.fifty <- subset(rich.fifty, rich.fifty$ID_50 %in% grdid.occ.fifty)#
rich.occ.twohund <- subset(rich.twohund, rich.twohund$ID_200 %in% grdid.occ.twohund)#
#
##move on to counts#
#
rich.count.onehund <- subset(rich.onehund, rich.onehund$ID_100 %in% grdid.count.onehund)#
rich.count.fifty <- subset(rich.fifty, rich.fifty$ID_50 %in% grdid.count.fifty)#
rich.count.twohund <- subset(rich.twohund, rich.twohund$ID_200 %in% grdid.count.twohund)#
#
##make some temporary results files. begin with occurrences#
##because of the problem where some biomeans are missing, you'll need to chop the results to those later, so can't bind biomeans in yet#
##NOTICE ALSO THAT WE CALCULATE the EVENNESS INDEX IN THE LAST COLUMN AS THE SHANNON INDEX DIVIDED BY THE LOG OF SPECIES RICHNESS#
#
temp.results.occ.onehund <- data.frame(grdid.occ.onehund, noabund.MPD.occ.onehund, inter.MPD.occ.onehund, intra.MPD.occ.onehund, complete.MPD.occ.onehund, rich.occ.onehund$richness, H.occ.onehund, H.occ.onehund/log(rich.occ.onehund$richness))#
temp.results.occ.fifty <- data.frame(grdid.occ.fifty, noabund.MPD.occ.fifty, inter.MPD.occ.fifty, intra.MPD.occ.fifty, complete.MPD.occ.fifty, rich.occ.fifty$richness, H.occ.fifty, H.occ.fifty/log(rich.occ.fifty$richness))#
temp.results.occ.twohund <- data.frame(grdid.occ.twohund, noabund.MPD.occ.twohund, inter.MPD.occ.twohund, intra.MPD.occ.twohund, complete.MPD.occ.twohund, rich.occ.twohund$richness, H.occ.twohund, H.occ.twohund/log(rich.occ.twohund$richness))#
#
##move on to counts#
#
temp.results.count.onehund <- data.frame(grdid.count.onehund, noabund.MPD.count.onehund, inter.MPD.count.onehund, intra.MPD.count.onehund, complete.MPD.count.onehund, rich.count.onehund$richness, H.count.onehund, H.count.onehund/log(rich.count.onehund$richness))#
temp.results.count.fifty <- data.frame(grdid.count.fifty, noabund.MPD.count.fifty, inter.MPD.count.fifty, intra.MPD.count.fifty, complete.MPD.count.fifty, rich.count.fifty$richness, H.count.fifty, H.count.fifty/log(rich.count.fifty$richness))#
temp.results.count.twohund <- data.frame(grdid.count.twohund, noabund.MPD.count.twohund, inter.MPD.count.twohund, intra.MPD.count.twohund, complete.MPD.count.twohund, rich.count.twohund$richness, H.count.twohund, H.count.twohund/log(rich.count.twohund$richness))#
#
##now cut them to the biomeans you actually have. begin with occurrences#
#
results.occ.onehund <- subset(temp.results.occ.onehund, temp.results.occ.onehund$grdid.occ.onehund %in% biomeans.occ.onehund$id)#
results.occ.fifty <- subset(temp.results.occ.fifty, temp.results.occ.fifty$grdid.occ.fifty %in% biomeans.occ.fifty$gridcell)#
results.occ.twohund <- subset(temp.results.occ.twohund, temp.results.occ.twohund$grdid.occ.twohund %in% biomeans.occ.twohund$gridcell)#
#
##move on to counts#
#
results.count.onehund <- subset(temp.results.count.onehund, temp.results.count.onehund$grdid.count.onehund %in% biomeans.count.onehund$id)#
results.count.fifty <- subset(temp.results.count.fifty, temp.results.count.fifty$grdid.count.fifty %in% biomeans.count.fifty$gridcell)#
results.count.twohund <- subset(temp.results.count.twohund, temp.results.count.twohund$grdid.count.twohund %in% biomeans.count.twohund$gridcell)#
#
##bind the biomeans in. first occurrences#
#
results.occ.onehund <- cbind(biomeans.occ.onehund, results.occ.onehund)#
results.occ.fifty <- cbind(biomeans.occ.fifty, results.occ.fifty)#
results.occ.twohund <- cbind(biomeans.occ.twohund, results.occ.twohund)#
#
##then counts#
#
results.count.onehund <- cbind(biomeans.count.onehund, results.count.onehund)#
results.count.fifty <- cbind(biomeans.count.fifty, results.count.fifty)#
results.count.twohund <- cbind(biomeans.count.twohund, results.count.twohund)#
#
##delete the duplicate grdid columns and fix the names up nice for all results files#
#
results.occ.onehund[,21] <- NULL#
results.occ.fifty[,60] <- NULL#
results.occ.twohund[,60] <- NULL#
#
results.count.onehund[,21] <- NULL#
results.count.fifty[,60] <- NULL#
results.count.twohund[,60] <- NULL#
#
names(results.occ.onehund)[21:27] <- c("noabund.MPD", "inter.MPD", "intra.MPD", "complete.MPD", "richness", "shannon", "evenness")#
names(results.occ.fifty)[60:66] <- c("noabund.MPD", "inter.MPD", "intra.MPD", "complete.MPD", "richness", "shannon", "evenness")#
names(results.occ.twohund)[60:66] <- c("noabund.MPD", "inter.MPD", "intra.MPD", "complete.MPD", "richness", "shannon", "evenness")#
#
names(results.count.onehund)[21:27] <- c("noabund.MPD", "inter.MPD", "intra.MPD", "complete.MPD", "richness", "shannon", "evenness")#
names(results.count.fifty)[60:66] <- c("noabund.MPD", "inter.MPD", "intra.MPD", "complete.MPD", "richness", "shannon", "evenness")#
names(results.count.twohund)[60:66] <- c("noabund.MPD", "inter.MPD", "intra.MPD", "complete.MPD", "richness", "shannon", "evenness")#
#
##at this point i've decided to stop using the real counts, as the effort per point isn't comparable between collecting, observations where people counted individuals, and observations where they just noted presence absence. will instead just use occurrences from here out#
#
##take the cdm files, turn them back into phylocom style cdms instead of current#
##state, and change the col name so that we have a column to merge#
##it with and with biomeans files#
#
cdm.onehund.ini <- matrix2sample(cdm.occ.onehund)#
cdm.fifty.ini <- matrix2sample(cdm.occ.fifty)#
cdm.twohund.ini <- matrix2sample(cdm.occ.twohund)#
#
names(cdm.onehund.ini) = c("id","abund","species")#
names(cdm.fifty.ini) = c("id","abund","species")#
names(cdm.twohund.ini) = c("id","abund","species")#
#
##cut down to only those cells you have climatic data for#
#
cdm.onehund.ini <- subset(cdm.onehund.ini, cdm.onehund.ini$id %in% biomeans.occ.onehund$id)#
cdm.fifty.ini <- subset(cdm.fifty.ini, cdm.fifty.ini$id %in% biomeans.occ.fifty$gridcell)#
cdm.twohund.ini <- subset(cdm.twohund.ini, cdm.twohund.ini$id %in% biomeans.occ.twohund$gridcell)#
#
##now get the names of the biomeans files into order as well#
#
names(biomeans.occ.fifty)[1] = "id"#
names(biomeans.occ.twohund)[1] = "id"#
#
###########################################################################################
####################MERGE THE RESULTS AND CLIMATIC DATA FILES##############################
###########################################################################################
#
combo.onehund <- merge(cdm.onehund.ini, biomeans.occ.onehund, by="id")#
combo.fifty <- merge(cdm.fifty.ini, biomeans.occ.fifty, by="id")#
combo.twohund <- merge(cdm.twohund.ini, biomeans.occ.twohund, by="id")#
#
##order it by species. from here on proceeding as if running analysis only#
##with 100 km grids#
#
combo.onehund <- combo.onehund[order(combo.onehund$species), ]#
#
##the following is a bit of a cheap fix, but since i know that bio1 will be a#
##variable we are interested in, and since i know that it needs to be divided #
##by 10 (others do as well but not interested), will do here#
#
combo.onehund$bio1mean <- combo.onehund$bio1mean/10#
#
##derive both the species' level averages and the species' minima for all bioclim#
#
bio1niche <- ddply(combo.onehund, "species", summarise, niche=mean(bio1mean))#
bio1STDniche <- ddply(combo.onehund, "species", summarise, niche=sd(bio1mean))#
bio2niche <- ddply(combo.onehund, "species", summarise, niche=mean(bio2mean))#
bio3niche <- ddply(combo.onehund, "species", summarise, niche=mean(bio3mean))#
bio4niche <- ddply(combo.onehund, "species", summarise, niche=mean(bio4mean))#
bio5niche <- ddply(combo.onehund, "species", summarise, niche=mean(bio5mean))#
bio6niche <- ddply(combo.onehund, "species", summarise, niche=mean(bio6mean))#
bio7niche <- ddply(combo.onehund, "species", summarise, niche=mean(bio7mean))#
bio8niche <- ddply(combo.onehund, "species", summarise, niche=mean(bio8mean))#
bio9niche <- ddply(combo.onehund, "species", summarise, niche=mean(bio9mean))#
bio10niche <- ddply(combo.onehund, "species", summarise, niche=mean(bio10mean))#
bio11niche <- ddply(combo.onehund, "species", summarise, niche=mean(bio11mean))#
bio12niche <- ddply(combo.onehund, "species", summarise, niche=mean(bio12mean))#
bio12STDniche <- ddply(combo.onehund, "species", summarise, niche=sd(log10(bio12mean)))#
bio13niche <- ddply(combo.onehund, "species", summarise, niche=mean(bio13mean))#
bio14niche <- ddply(combo.onehund, "species", summarise, niche=mean(bio14mean))#
bio15niche <- ddply(combo.onehund, "species", summarise, niche=mean(bio15mean))#
bio16niche <- ddply(combo.onehund, "species", summarise, niche=mean(bio16mean))#
bio17niche <- ddply(combo.onehund, "species", summarise, niche=mean(bio17mean))#
bio18niche <- ddply(combo.onehund, "species", summarise, niche=mean(bio18mean))#
bio19niche <- ddply(combo.onehund, "species", summarise, niche=mean(bio19mean))#
#
bio1min <- ddply(combo.onehund, "species", summarise, min=min(bio1mean))#
bio2min <- ddply(combo.onehund, "species", summarise, min=min(bio2mean))#
bio3min <- ddply(combo.onehund, "species", summarise, min=min(bio3mean))#
bio4min <- ddply(combo.onehund, "species", summarise, min=min(bio4mean))#
bio5min <- ddply(combo.onehund, "species", summarise, min=min(bio5mean))#
bio6min <- ddply(combo.onehund, "species", summarise, min=min(bio6mean))#
bio7min <- ddply(combo.onehund, "species", summarise, min=min(bio7mean))#
bio8min <- ddply(combo.onehund, "species", summarise, min=min(bio8mean))#
bio9min <- ddply(combo.onehund, "species", summarise, min=min(bio9mean))#
bio10min <- ddply(combo.onehund, "species", summarise, min=min(bio10mean))#
bio11min <- ddply(combo.onehund, "species", summarise, min=min(bio11mean))#
bio12min <- ddply(combo.onehund, "species", summarise, min=min(bio12mean))#
bio13min <- ddply(combo.onehund, "species", summarise, min=min(bio13mean))#
bio14min <- ddply(combo.onehund, "species", summarise, min=min(bio14mean))#
bio15min <- ddply(combo.onehund, "species", summarise, min=min(bio15mean))#
bio16min <- ddply(combo.onehund, "species", summarise, min=min(bio16mean))#
bio17min <- ddply(combo.onehund, "species", summarise, min=min(bio17mean))#
bio18min <- ddply(combo.onehund, "species", summarise, min=min(bio18mean))#
bio19min <- ddply(combo.onehund, "species", summarise, min=min(bio19mean))#
#
##there was here a huge section of functioning, useful code involving bringing in the #
##HANZAB morphological data, and running PICs of climate and body size, and of checking #
##the phylogenetic signal, the trait community structure, and mean root distance, that #
##I've deleted. Remains in previous versions of this script file#
#
###########################################################################################
####################RUN THE ANCESTRAL STATE RECONSTRUCTION###############################
###########################################################################################
#
##per suggestions on http://www.r-phylo.org/wiki/HowTo/Ancestral_State_Reconstruction , #
##will pull out trait data, then associate the row names with it#
#
name.vector <- bio1niche$species#
#
bio1niche <- bio1niche$niche#
names(bio1niche) <- name.vector#
#
bio1STDniche <- bio1STDniche$niche#
names(bio1STDniche) <- name.vector#
#
##take the log base 10 of mean annual precipitation here too, since the following code assumes we're using logged values#
#
bio12niche <- log10(bio12niche$niche)#
names(bio12niche) <- name.vector#
#
##already logged bio12STD above#
#
bio12STDniche <- bio12STDniche$niche#
names(bio12STDniche) <- name.vector#
#
##VERY IMPORTANT TO SORT THESE BY THE ORDER OF THE PHYLOGENY#
#
bio1niche <- bio1niche[meliphagidae$tip.label]#
#
bio1STDniche <- bio1STDniche[meliphagidae$tip.label]#
#
bio12niche <- bio12niche[meliphagidae$tip.label]#
#
bio12STDniche <- bio12STDniche[meliphagidae$tip.label]#
#
##replace Lichenostomus hindwoodi variation with arbitrary small numbers#
#
bio1STDniche[names(bio1STDniche)=="Lichenostomus_hindwoodi"] <- min(bio1STDniche,na.rm=T)#
#
bio12STDniche[names(bio12STDniche)=="Lichenostomus_hindwoodi"] <- min(bio12STDniche,na.rm=T)#
#
##when I first developed this code, I used method=ML. However, since then, REML has#
##been introduced to the ace code. The ace manual recommends this method. Run both#
##and compare results. NOTE THAT THE BIO1 model has a negative log likelihood score#
#
ML.bio1 <- ace(bio1niche, meliphagidae, type="continuous", method="ML")#
ML.bio12 <- ace(bio12niche, meliphagidae, type="continuous", method="ML")#
#
##extrapolate the logged precip results into real precip. call the root#
#
root.ML.bio12 <- 10^ML.bio12$ace[1]#
#
##run the REML. note that results are very similar#
#
REML.bio1 <- ace(bio1niche, meliphagidae, type="continuous", method="REML")#
REML.bio12 <- ace(bio12niche, meliphagidae, type="continuous", method="REML")#
#
root.REML.bio12 <- 10^REML.bio12$ace[1]#
#
###########################################################################################
####################USE fitContinuousMCMC TO PUT A PRIOR ON THE ROOT#######################
####################AND RECONSTRUCT USING A TREND MODEL OF EVOLUTION#######################
###########################################################################################
#
##the mean is the log10 of the midpoint of D. Greenwood's estimate, the sd was chosen such#
##that 2 sd out from the mean described the range given by Greenwood#
##most of the actual calls here are hashed out so that things don't run#
#
##FIRST make the tree ultrametric to faciliate visualization and to allow various analyses to run the way they are supposed to#
#
meliphagidae2 <- chronopl(meliphagidae, lambda = 0.1)#
#
##set the working directory to the desktop. this is where the output files will be saved to#
#
#setwd("~/Desktop")#
#
##fit the different models of evolution.#
#
##create a data frame for a mean/sd style root prior. #
#
root.prior <- data.frame(mean=log10(1250), sd=0.079, priortype="normal")#
#
##Graham Slater said that I want acceptance rates of 0.25-0.7. Going through his code, #
##it appears that these are what are printing to the screen, though I'm not sure what the #
##range of values printing are (I can see that all except "trend" should print 3 values, #
##while that should print 4). Nevertheless, running with the default propwidth #
##(which is rep(0.1, 5)), the acceptance rates are generally higher than they should be. #
##The first value in the numeric vector 5-long refers to the root state proposal width, #
##which is the one we're most concerned about. So, try modifying that...in the end I used#
##trial and error. The fourth term in the numeric vector doesn't matter (it relates to OU #
##model and is not yet implemented)#
#
propwidth <- c(0.15, 0.5, 0.4, 0.1, 0.4)#
#
##i then used this propwidth to fit various iterations of the models. ACDC linear was #
##always best supported, but i had trouble fitting the beta parameters--a very large value#
##was always supported, but there was also a huge spread of good values. #
##this was true whether i used the aboved propwidth, or propwidth <- c(0.1, 0.5, 0.4, 0.1, 0.4)#
##which kept the acceptance rates for the ACDC models closer to the sweet spot.#
##in the end, I only used BM and trend. if you want to use ACDC, remember these propwidths #
##here. and remember to fit limits to the acdc parameter. from the equation #
##end rate = sigma sq + beta * T where T is the length of your tree#
##Graham has a function to do this, but it's hidden. to access it#
#
#acdc.lin.priors = fitContinuousMCMC:::ACDC.prior(meliphagidae2, "ACDC.lin", decrease.max = -1, increase.max = 3)#
#
##for the exp priors, have to be careful. Harmon et al. observed values as small as -0.15. to generate that call the decrease.max as below. call the increase.max so it ends up being 3. #
#
#acdc.exp.priors = fitContinuousMCMC:::ACDC.prior(meliphagidae2, "ACDC.exp", decrease.max = 0.8, increase.max = 10)#
#
##SSP is currently broken in this package. Graham needs to fix it still#
#
#fitContinuousMCMC(meliphagidae2, bio12niche, model="BM", Ngens=1e7, sampleFreq=100, printFreq=100, propwidth=propwidth, root.prior=root.prior, outputName="precip_BM3")#
#
#fitContinuousMCMC(meliphagidae2, bio12niche, model="Trend", Ngens=1e7, sampleFreq=100, printFreq=100, propwidth=propwidth, root.prior=root.prior, outputName="precip_trend3")#
#
##also tried running it over different temperature models. again, ACDC linear was best. #
##but again, hard to fit the parameters right. again, just go with BM and trend#
#
##the mean comes from Greenwood et al 2003 (16-22 deg C), and the sd such that 2sd out from 20 deg C is 16 & 22#
#
root.prior <- data.frame(mean=19, sd=1.5, priortype="normal")#
#
propwidth <- c(3, 0.5, 4, 4, 4)#
#
#fitContinuousMCMC(meliphagidae2, bio1niche, model="Trend", Ngens=1e7, sampleFreq=100, printFreq=100, propwidth=propwidth, root.prior=root.prior, outputName="temp_trend3")#
#
#fitContinuousMCMC(meliphagidae2, bio1niche, model="BM", Ngens=1e7, sampleFreq=100, printFreq=100, propwidth=propwidth, root.prior=root.prior, outputName="temp_BM3")#
#
##load in the different results files of interest. i manually copied them into the main #
##meliphagidae working folder. can set working directory back there if you changed it to desktop above#
#
bm.precip.res <- read.table("precip_BM3_model_params.txt", header= TRUE)#
#
head(bm.precip.res)#
#
trend.precip.res <- read.table("precip_trend3_model_params.txt", header= TRUE)#
#
head(trend.precip.res)#
#
##load in the precipitation node state files as well! use only the trend node states for now#
#
trend.precip.nodes.ini <- read.table("precip_trend3_nodestates.txt", header= TRUE)#
#
##plot the likelihood results#
#
plot(bm.precip.res$generation, bm.precip.res$logLk, type = "l", xlab="Generation", ylab="LogLk", main="Precipitation", ylim = c(min(c(bm.precip.res$logLk,trend.precip.res$logLk)),max(c(bm.precip.res$logLk,trend.precip.res$logLk))))#
lines(trend.precip.res$generation, trend.precip.res$logLk, col = "red")#
legend("bottomleft", c("bm", "trend"), lwd = 3, col = c("black", "red"))#
#
## perform model selection using AICM#
## First remove burn-in (the first 100 sampled generations seems like a good estimate)#
#
bm.precip.res.burned <- bm.precip.res[-(1:100), ]#
trend.precip.res.burned <- trend.precip.res[-(1:100), ]#
#
aicm.bm.precip <- AICM(bm.precip.res.burned$logLk)#
aicm.trend.precip <- AICM(trend.precip.res.burned$logLk)#
#
aicm.precip <- c(aicm.bm.precip, aicm.trend.precip)#
names(aicm.precip) <- c("bm", "trend")#
#
AkaikeWeights(aicm.precip)#
#
##move on to load the temperature files#
#
bm.temp.res <- read.table("temp_BM3_model_params.txt", header= TRUE)#
#
head(bm.temp.res)#
#
trend.temp.res <- read.table("temp_trend3_model_params.txt", header= TRUE)#
#
head(trend.temp.res)#
#
##load in the temperature node state files as well! use only the trend node states for now#
#
trend.temp.nodes.ini <- read.table("temp_trend3_nodestates.txt", header= TRUE)#
#
plot(bm.temp.res$generation, bm.temp.res$logLk, type = "l", xlab="Generation", ylab="LogLk", main="temperature", ylim = c(min(c(bm.temp.res$logLk,trend.temp.res$logLk)),max(c(bm.temp.res$logLk,trend.temp.res$logLk))))#
lines(trend.temp.res$generation, trend.temp.res$logLk, col = "red")#
legend("bottomleft", c("bm", "trend"), lwd = 3, col = c("black", "red"))#
#
## perform model selection using AICM#
## First remove burn-in (the first 100 sampled generations seems like a good estimate)#
#
bm.temp.res.burned <- bm.temp.res[-(1:100), ]#
trend.temp.res.burned <- trend.temp.res[-(1:100), ]#
#
aicm.bm.temp <- AICM(bm.temp.res.burned$logLk)#
aicm.trend.temp <- AICM(trend.temp.res.burned$logLk)#
#
aicm.temp <- c(aicm.bm.temp, aicm.trend.temp)#
names(aicm.temp) <- c("bm", "trend")#
#
AkaikeWeights(aicm.temp)#
#
###########################################################################################
####################GET THE ACTUAL ANCESTRAL STATE RECONSTRUCTIONS#########################
###########################################################################################
#
##remove the burn-in period for the node states as well#
#
trend.precip.nodes.burned <- trend.precip.nodes.ini[-(1:100), ]#
#
trend.temp.nodes.burned <- trend.temp.nodes.ini[-(1:100), ]#
#
##find the average of each node across all generations, and set the names to be in accord with REML.bioX$ace#
#
trend.precip.nodes <- apply(trend.precip.nodes.burned, 2, mean)#
#
names(trend.precip.nodes) <- names(REML.bio1$ace)#
#
trend.temp.nodes <- apply(trend.temp.nodes.burned, 2, mean)#
#
names(trend.temp.nodes) <- names(REML.bio1$ace)#
#
##calculate the model-weighted mean and 95% highest probability density for the root state for both precip and temp#
#
precip.weights <- density(c(bm.precip.res.burned$root, trend.precip.res.burned$root), weights=c(rep(AkaikeWeights(aicm.precip)["bm",3], length(bm.precip.res.burned$root)), rep(AkaikeWeights(aicm.precip)["trend",3], length(trend.precip.res.burned$root))))#
#
precip.hdr <- hdr.den(c(bm.precip.res.burned$root, trend.precip.res.burned$root), den=precip.weights)#
#
temp.weights <- density(c(bm.temp.res.burned$root, trend.temp.res.burned$root), weights=c(rep(AkaikeWeights(aicm.temp)["bm",3], length(bm.temp.res.burned$root)), rep(AkaikeWeights(aicm.temp)["trend",3], length(trend.temp.res.burned$root))))#
#
temp.hdr <- hdr.den(c(bm.temp.res.burned$root, trend.temp.res.burned$root), den=temp.weights)#
#
##you can could also calculate the weighted mean as below. the values are from Tracer:#
##precip.mean <- weighted.mean(c(3.0155,3.0964), c(AkaikeWeights(aicm.precip)["bm",3], AkaikeWeights(aicm.precip)["trend",3]))#
#
###########################################################################################
####################PLOT THE ANCESTRAL STATE RECONSTRUCTIONS########################
###########################################################################################
#
##there was some old semi-functioning Rich Glor style categorical coloring here. removed. #
##in old versions of script. the following is better, since it's continuous#
#
##first for bio1. i have played with a million color scales here. this is the best so far.#
##set the plot to be the size of a page. plot the ladderized form of the tree, with the #
##"most recent" taxa at the top. Note that this re-arranges the internal structure of the#
##tree but not the order of the tip labels. this means your original way of adding the points#
##on would also fail, so you will need to re-order the tip points according to the new#
##underlying phylogeny#
#
quartz(width=8.5, height=11)#
#
temp <- ladderize(meliphagidae2, right=FALSE)#
#
plot(temp, show.node.label=FALSE, label.offset=0, cex=0.8, show.tip.label=FALSE)#
#
##now figure out the new order of the ladderized tree#
#
orderizer <- temp$edge[,2][temp$edge[,2]<=length(temp$tip.label)]#
#
##the position of the tip labels, when the tree has been made ultrametric as above#
##is actually quite simple. the x coordinates begin at 1--the branch tip--and #
##increase from there, not by very much. the y coordinate refers to the tips.#
##want to plot the position of the node label to be relative to the value of the#
##trait. begin by standardizing the the trait#
#
bio1std <- (bio1niche - min(bio1niche))/(max(bio1niche)-min(bio1niche))#
#
##then multiply the std variable by the range between the max and min desired x#
##coord and add it to the min (you want to be adding a percentage of the range to#
##the min such that if the standardized variable = 1, the new position is the max#
##and if std = 0, the new position is the desired min)#
#
bio1std <- (1.072-1.015)*bio1std+1.015#
#
##and sort the points by the orderizer. note there is no call to order() here#
#
bio1std <- bio1std[orderizer]#
#
##this is a very complicated line with respect to the plotrix coloring. in particular, #
##difficult to decipher what the three arguments (r,g,b) mean. the way it works is if you #
##want it to go from just blue (0,0,1) to cyan (0,1,1) you code it c(0,0),c(0,1),c(1,1) #
##and if you wanted it to go from cyan to blue to cyan it would be c(0,0,0),c(1,0,1),c(1,1,1), etc. #
##COMPLICATED! the first place in each argument refers to color 1, the second place color 2, etc.#
##NOTE also the call to bio1niche[orderizer]->this is necessary to get the colors right#
##NOTE the cex=1.6 command. realized after a few submissions to various journals that I had#
##room for larger squares in the figure. this is the size that stacks them up edge to edge on#
##an 8.5 by 11 figure. i also made the node label size a little larger here too.#
#
points(x=bio1std, y=1:length(meliphagidae2$tip.label), pch=22, bg=color.scale(bio1niche[orderizer],c(0,0,1,1),c(1,1,0.5,0),c(1,1,0,0)), cex=1.6, lwd=1)#
#
nodelabels(pch=21, bg=color.scale(REML.bio1$ace,c(0,0,1,1),c(1,1,0.5,0),c(1,1,0,0)), cex=1.6, frame="none")#
#
##then for bio12. this is the best color scale I've come up with so far for precipitation.#
##each step below is explained in detail just above#
#
quartz(width=8.5, height=11)#
#
plot(temp, show.node.label=FALSE, label.offset=0, cex=0.8, show.tip.label=FALSE)#
#
bio12std <- (bio12niche - min(bio12niche))/(max(bio12niche)-min(bio12niche))#
#
bio12std <- (1.072-1.015)*bio12std+1.015#
#
bio12std <- bio12std[orderizer]#
#
points(x=bio12std, y=1:length(meliphagidae2$tip.label), pch=22, bg=color.scale(bio12niche[orderizer],c(1,1,0),c(0,1,1),c(0,0)), cex=1.6, lwd=1)#
#
nodelabels(pch=21, bg=color.scale(REML.bio12$ace,c(1,1,0),c(0,1,1),c(0,0)), cex=1.6, frame="none")#
#
###########################################################################################
####################PLOT THE fitContinuousMCMC ANCESTRAL STATE RECONSTRUCTIONS#############
###########################################################################################
#
##Try plotting the same type of figures with the ancestral states as reconstructed #
##with a trend. Follows same outline as code above, though never bothered to change color#
##scale to the most recent form#
#
quartz(width=8.5, height=11)#
#
plot(meliphagidae2, show.node.label=FALSE, label.offset=0, cex=0.8, show.tip.label=FALSE)#
#
bio1std <- (bio1niche - min(bio1niche))/(max(bio1niche)-min(bio1niche))#
#
bio1std <- (1.072-1.015)*bio1std+1.015#
#
points(x=bio1std, y=1:length(meliphagidae2$tip.label), pch=22, bg=color.scale(bio1niche,c(0,0,0,1,1),c(0,1,1,1,0),c(1,1,0,0,0)), cex=1, lwd=1)#
#
nodelabels(pch=21, bg=color.scale(trend.temp.nodes,c(0,0,0,1,1),c(0,1,1,1,0),c(1,1,0,0,0)), cex=1.2, frame="none")#
#
##move on and do bio12#
#
quartz(width=8.5, height=11)#
#
plot(meliphagidae2, show.node.label=FALSE, label.offset=0, cex=0.8, show.tip.label=FALSE)#
#
bio12std <- (bio12niche - min(bio12niche))/(max(bio12niche)-min(bio12niche))#
#
bio12std <- (1.072-1.015)*bio12std+1.015#
#
points(x=bio12std, y=1:length(meliphagidae2$tip.label), pch=22, bg=color.scale(bio12niche,c(1,1,0,0,0),c(0,1,1,1,0),c(0,0,0,1,1)), cex=1, lwd=1)#
#
nodelabels(pch=21, bg=color.scale(trend.precip.nodes,c(1,1,0,0,0),c(0,1,1,1,0),c(0,0,0,1,1)), cex=1.2, frame="none")#
#
###########################################################################################
####################DEFINE ALL THE FUNCTIONS TO FIGURE OUT WHICH###########################
####################SITES HAVE SIGNIFICANT PHYLOGENETIC COMMUNITY STRUCTURE################
###########################################################################################
#
##i used to simulate the null expectations by random draws from the entire phylogeny. the #
##code for how to properly deal with the resulting data is in previous versions of this file#
##here, i will randomize the input matrix with various null models, then save the results #
##as a data frame with first column equal to richness, second column equal to MPD#
#
##first define a function that will be used to find the species richness of each row (i.e. community)#
#
lengthNonZeros <- function(input.vector)#
{#
	nonZeros <- input.vector[input.vector != 0]#
	return(length(nonZeros))#
}#
#
##then define a function that will use this function and the modified.mpd function to generate one block (iteration) of the desired data frame#
#
oneIteration <- function(orig.matrix, phy.dists, abundance.method)#
{#
	oneBlock <- matrix(nrow = dim(orig.matrix)[1], ncol = 2)#
	oneBlock[,1] <- apply(orig.matrix, 1, lengthNonZeros)#
	oneBlock[,2] <- modified.mpd(orig.matrix, phy.dists, abundance.method)#
	return(oneBlock)#
}#
#
##define a function that uses the function oneIteration and the picante function randomizeMatrix to generate null expectations after randomization#
#
null.exp <- function(orig.matrix, null.method, phy.dists, abundance.method)#
{#
	randomMatrix <- matrix(nrow = dim(orig.matrix)[1], ncol = 2)#
	randomMatrix <- randomizeMatrix(orig.matrix, null.method)#
	results <- oneIteration(randomMatrix, phy.dists, abundance.method)#
	return(results)#
}#
#
##put all of these functions into an iterator function#
#
iterator <- function(orig.matrix, null.method, phy.dists, abundance.method, iterations)#
{#
	final.results <- matrix(nrow = iterations * dim(orig.matrix)[1], ncol = 2)#
	for (i in 1:iterations)#
	{	#
		final.results[(i * dim(orig.matrix)[1] - dim(orig.matrix)[1] + 1):(i * dim(orig.matrix)[1]), ] <- null.exp(orig.matrix, null.method, phy.dists, abundance.method)#
	}#
	final.results <- as.data.frame(final.results)#
	names(final.results) <- c("richness","metric")#
	return(final.results)#
}#
#
##discovered that the iterator function bogs down the memory very quickly (e.g. at > 1000 iterations)#
##want to write a function that will write the results to a csv file outside of R at each iteration, then clear the memory#
#
null.csv <- function(orig.matrix, null.method, phy.dists, abundance.method, iterations, file.name)#
{#
	for (i in 1:iterations)#
	{#
		temp.results <- null.exp(orig.matrix, null.method, phy.dists, abundance.method)#
		if(i == 1)#
		{#
			write.table(temp.results, file=file.name, append=FALSE, row.names=FALSE, sep=",")#
		}#
		else if(i/iterations == 0.2)#
		{#
			print("20% complete")#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
		else if(i/iterations == 0.5)#
		{#
			print("50% complete")#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
		else#
		{#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
	}#
	print("File saved to working directory")#
}#
#
##also, in case you need to run more iterations at a given richness, e.g. a low richness that isn't being sampled well with the frequency null, write a function that will subset each randomized matrix to only those richnesses you want#
#
null.exp.selected <- function(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses)#
{#
	randomMatrix <- matrix(nrow = dim(orig.matrix)[1], ncol = 2)#
	randomMatrix <- randomizeMatrix(orig.matrix, null.method)#
	results <- oneIteration(randomMatrix, phy.dists, abundance.method)#
	results <- matrix(results[results[,1] %in% accepted.richnesses, ], ncol=2)#
	return(results)#
}#
#
##and the iterator version of that. can't define the matrix beforehand because you don't know how often the pertinent richnesses will appear#
#
iterator.selected <- function(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses, iterations)#
{#
	final.results <- c()#
	for (i in 1:iterations)#
	{	#
		final.results <- rbind(final.results, null.exp.selected(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses))#
	}#
	final.results <- as.data.frame(final.results)#
	names(final.results) <- c("richness","metric")#
	return(final.results)#
}#
#
##make a version that will write straight to csv#
#
null.csv.selected <- function(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses, iterations, file.name)#
{#
	for (i in 1:iterations)#
	{#
		temp.results <- null.exp.selected(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses)#
		if(i == 1)#
		{#
			write.table(temp.results, file=file.name, append=FALSE, row.names=FALSE, sep=",")#
		}#
		else if(i/iterations == 0.2)#
		{#
			print("20% complete")#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
		else if(i/iterations == 0.5)#
		{#
			print("50% complete")#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
		else#
		{#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
	}#
	print("File saved to working directory")#
}#
#
specific.csv <- function(orig.matrix, null.method, phy.dists, abundance.method, desired.iterations, max.iterations, file.name)#
{#
	temp <- oneIteration(orig.matrix, phy.dists, abundance.method)#
	max.rich <- max(temp[,1])#
	min.rich <- min(temp[,1])#
	rich.seq <- min.rich:max.rich#
	details.table <- matrix(nrow=length(rich.seq), ncol=1, dimnames=list(rich.seq))#
	details.table[,1] <- 0#
	temp.results <- null.exp.selected(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses=rich.seq)#
	write.table(temp.results, file=file.name, append=FALSE, row.names=FALSE, col.names=c("richness","metric"), sep=",")#
	details.table[,1][row.names(details.table) %in% count(temp.results[,1])$x] <- count(temp.results[,1])$freq#
	for (i in 1:max.iterations)#
	{#
		rich.seq <- row.names(details.table)[details.table[,1] < desired.iterations]#
		temp.results <- null.exp.selected(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses=rich.seq)#
		write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		details.table[,1][row.names(details.table) %in% count(temp.results[,1])$x] <- details.table[,1][row.names(details.table) %in% count(temp.results[,1])$x] + count(temp.results[,1])$freq#
		if(length(rich.seq) == 0)#
		{#
			break()#
		}#
	}#
	print("File saved to working directory")#
	return(details.table)#
}#
#
##you need to call either iterator(), null.csv(), or specific.csv here to generate your nulls (or any of the selected versions of those) or load in a file (e.g. richness_sim.csv)#
#
##define a function to calculate the mean and 95% confidence intervals of the results from the iterator function#
#
con.intervals <- function(null.output)#
{#
	confidence <- ddply(null.output, "richness", summarise, iterations=length(metric), average=mean(metric), upper=quantile(metric, 0.975, na.rm=TRUE), lower=quantile(metric, 0.025, na.rm=TRUE))#
	return(confidence)#
}#
#
##in the end I ran about 100,000 iterations of the null.csv for each of the four options (non-abundance weighted frequency and richness and interspecific abundance-weighted frequency and richness), then ran 1,000,000 million iterations of the specific.csv for the frequency of both, trying to find 100 samples for every richness. also bound in a few additional searches i did with the null.csv.selected for these higher and lower richnesses for both frequency nulls.#
##then ran the function con.intervals on the concatenated results (note i used some sqldf commands to load these huge files in, see file titled something to do with large table load)#
##load in the for confidence intervals#
#
###########################################################################################
####################LOAD IN THE SUMMARIZED RESULTS AND DO SIG TESTING######################
###########################################################################################
#
##this first comes from 10^6 iterations for richnesses 4-30 (drawing species at random for the range of richnesses desired), then 10,000 iterations for richness 31-34 (assembled via the richness swaps)#
noabund.rich <- read.csv("richness_noabund_intervals.csv")#
#
##see above for where this comes from#
noabund.freq <- read.csv("frequency_noabund_intervals.csv")#
#
##this comes from 210,000 iterations of the richness null#
inter.rich <- read.csv("richness_interspecific_intervals.csv")#
#
##see above for where this comes from#
inter.freq <- read.csv("frequency_interspecific_intervals.csv")#
#
##the frequency null simulations sampled richnesses that aren't in the observed data, no reason to keep them#
#
noabund.freq <- noabund.freq[-(1:2),]#
#
inter.freq <- inter.freq[-c(1:2,34:35),]#
#
##now let's try to actually do significance testing.#
##merge in all the expectations. this will combine the expected nulls with the observed scores based on the corresponding richness of the null and the observed scores. need to do a bit of getting the names right for the merging and getting rid of iterations columns#
#
names(noabund.rich) <- c("richness","av.noabund.rich","up.noabund.rich","lo.noabund.rich")#
#
results <- merge(results.occ.onehund, noabund.rich, sort=FALSE)#
#
noabund.freq$iterations <- NULL#
#
names(noabund.freq) <- c("richness","av.noabund.freq","up.noabund.freq","lo.noabund.freq")#
#
results <- merge(results, noabund.freq, sort=FALSE, by="richness")#
#
inter.rich$iterations <- NULL#
#
names(inter.rich) <- c("richness","av.inter.rich","up.inter.rich","lo.inter.rich")#
#
results <- merge(results, inter.rich, sort=FALSE, by="richness")#
#
inter.freq$iterations <- NULL#
#
names(inter.freq) <- c("richness","av.inter.freq","up.inter.freq","lo.inter.freq")#
#
results <- merge(results, inter.freq, sort=FALSE, by="richness")#
#
##write a function to test for the actual significance of observed points against the null expectations. it will take the results table, and the name of the column of observed scores and the columns of the upper and lower confidence intervals against which you want to compare those observed scores, and return a vector of 0s, 1s and 2s, where 0s are not significant, 1s are clustered, and 2s are overdispersed#
#
sig.test <- function(results.table, observed, upper.CI, lower.CI)#
{#
	overdispersed <- results.table[,observed] > results.table[,upper.CI]#
	overdispersed[overdispersed==TRUE] <- 2#
	clustered <- results.table[,observed] < results.table[,lower.CI]#
	clustered[overdispersed==TRUE] <- 1#
	significance <- overdispersed + clustered#
	return(significance)#
}#
#
##use that function to test the significance of both abundance and non-abundance weighted versions for both richness and frequency nulls#
#
sig.noabund.rich <- sig.test(results, "noabund.MPD", "up.noabund.rich", "lo.noabund.rich")#
#
sig.noabund.freq <- sig.test(results, "noabund.MPD", "up.noabund.freq", "lo.noabund.freq")#
#
sig.inter.rich <- sig.test(results, "inter.MPD", "up.inter.rich", "lo.inter.rich")#
#
sig.inter.freq <- sig.test(results, "inter.MPD", "up.inter.freq", "lo.inter.freq")#
#
##bind those results back in#
#
results <- cbind(results, sig.noabund.rich, sig.noabund.freq, sig.inter.rich, sig.inter.freq)#
#
##MAT and MAP (bio1 & bio12) are not in correct units in this file#
#
results$bio1mean <- results$bio1mean/10#
#
results$bio12mean <- log10(results$bio12mean)#
#
###########################################################################################
####################PLOT THE MPD RESULTS COLOR-CODED BY SIGNIFICANCE#######################
###########################################################################################
#
##plot the non abundance weighted results against bio12.#
##make points that don't differ from any null model black. you didn't use these figures in#
##the MS, but this code is useful anyhow.#
#
plot(results$noabund.MPD[results$sig.noabund.rich==0 & results$sig.noabund.freq==0]~results$bio12mean[results$sig.noabund.rich==0 & results$sig.noabund.freq==0], pch=20, xlim=c(2.1,3.4), ylim=c(0.25,0.65), xlab=expression(Log[10]~" Precipitation (mm/yr)"), ylab="Mean Pairwise Phylogenetic Distance")#
#
##add points that are only clustered based on richness model as orange#
#
points(results$noabund.MPD[results$sig.noabund.rich==1 & results$sig.noabund.freq==0]~results$bio12mean[results$sig.noabund.rich==1 & results$sig.noabund.freq==0], pch=20, col="orange", cex=1.2)#
#
##there are no points that are clustered based only on frequency model#
##add points that are clustered based on both models as red#
#
points(results$noabund.MPD[results$sig.noabund.rich==1 & results$sig.noabund.freq==1]~results$bio12mean[results$sig.noabund.rich==1 & results$sig.noabund.freq==1], pch=20, col="red", cex=1.2)#
#
##add points that are only overdispersed based on frequency model as blue#
#
points(results$noabund.MPD[results$sig.noabund.rich==0 & results$sig.noabund.freq==2]~results$bio12mean[results$sig.noabund.rich==0 & results$sig.noabund.freq==2], pch=20, col="blue", cex=1.2)#
#
##there are no points that are overdispersed based only on richness model#
##add points that are overdispersed based on both models as purple#
#
points(results$noabund.MPD[results$sig.noabund.rich==2 & results$sig.noabund.freq==2]~results$bio12mean[results$sig.noabund.rich==2 & results$sig.noabund.freq==2], pch=20, col="purple", cex=1.2)#
#
##DO THE SAME FOR abundance-weighted MPD#
#
plot(results$inter.MPD[results$sig.inter.rich==0 & results$sig.inter.freq==0]~results$bio12mean[results$sig.inter.rich==0 & results$sig.inter.freq==0], pch=20, xlim=c(2.1,3.4), ylim=c(0.25,0.65), xlab=expression(Log[10]~" Precipitation (mm/yr)"), ylab="Mean Pairwise Phylogenetic Distance")#
#
##add points that are only clustered based on richness model as orange#
#
points(results$inter.MPD[results$sig.inter.rich==1 & results$sig.inter.freq==0]~results$bio12mean[results$sig.inter.rich==1 & results$sig.inter.freq==0], pch=20, col="orange", cex=1.2)#
#
##there are no points that are clustered based only on frequency model#
##add points that are clustered based on both models as red#
#
points(results$inter.MPD[results$sig.inter.rich==1 & results$sig.inter.freq==1]~results$bio12mean[results$sig.inter.rich==1 & results$sig.inter.freq==1], pch=20, col="red", cex=1.2)#
#
##there are no overdispersed points with the interspecific metric#
#
##make a color-scaled plot, where non-significant points range between yellow and #
##cyan, and are scaled based on their position between the upper and lower CIs, and #
##significant points get orange or red if they differ beyond one or two null models for #
##clustering, or blue or purple if they differ for overdispersion. could bother to do this#
##for both the frequency and richness nulls, then average, but that's more work than it's#
##worth. just arbitrarily choose frequency#
#
noabund.scaler <- (results$noabund.MPD[results$sig.noabund.rich==0 & results$sig.noabund.freq==0] - results$lo.noabund.freq[results$sig.noabund.rich==0 & results$sig.noabund.freq==0])/(results$up.noabund.freq[results$sig.noabund.rich==0 & results$sig.noabund.freq==0] - results$lo.noabund.freq[results$sig.noabund.rich==0 & results$sig.noabund.freq==0])#
#
plot(results$noabund.MPD[results$sig.noabund.rich==0 & results$sig.noabund.freq==0]~results$bio12mean[results$sig.noabund.rich==0 & results$sig.noabund.freq==0], pch=20, xlim=c(2.1,3.4), ylim=c(0.28,0.58), xlab=expression(Log[10]~" precipitation (mm/yr)"), ylab="Non-abundance-weighted mean pairwise distance", cex.lab=1.4, cex.axis=1.4, col=color.scale(noabund.scaler, c(1,0,0),c(0.75,1,0.75),c(0,0,1)))#
#
##add points that are only clustered based on richness model as orange#
#
points(results$noabund.MPD[results$sig.noabund.rich==1 & results$sig.noabund.freq==0]~results$bio12mean[results$sig.noabund.rich==1 & results$sig.noabund.freq==0], pch=20, col="orange", cex=1.4)#
#
##there are no points that are clustered based only on frequency model#
##add points that are clustered based on both models as red#
#
points(results$noabund.MPD[results$sig.noabund.rich==1 & results$sig.noabund.freq==1]~results$bio12mean[results$sig.noabund.rich==1 & results$sig.noabund.freq==1], pch=20, col="red", cex=1.4)#
#
##add points that are only overdispersed based on frequency model as blue#
#
points(results$noabund.MPD[results$sig.noabund.rich==0 & results$sig.noabund.freq==2]~results$bio12mean[results$sig.noabund.rich==0 & results$sig.noabund.freq==2], pch=20, col="blue", cex=1.4)#
#
##there are no points that are overdispersed based only on richness model#
##add points that are overdispersed based on both models as purple#
#
points(results$noabund.MPD[results$sig.noabund.rich==2 & results$sig.noabund.freq==2]~results$bio12mean[results$sig.noabund.rich==2 & results$sig.noabund.freq==2], pch=20, col="purple", cex=1.4)#
#
##add in the best-fit OLS line#
#
intercept <- lm(results$noabund.MPD~results$bio12mean)$coefficients[1]#
#
slope <- lm(results$noabund.MPD~results$bio12mean)$coefficients[2]#
#
segments(x0=min(results$bio12mean), y0=min(results$bio12mean)*slope+intercept, x1=max(results$bio12mean), y1=max(results$bio12mean)*slope+intercept)#
#
##add in the mode and 95% HPD ancestral states at root from the Bayesian MCMC method#
#
abline(v = precip.hdr$mode, lty=2)#
#
abline(v = precip.hdr$hdr["95%",1], lty=3)#
#
abline(v = precip.hdr$hdr["95%",2], lty=3)#
#
##and try the same color-scaled plot for abundance-weighted#
#
inter.scaler <- (results$inter.MPD[results$sig.inter.rich==0 & results$sig.inter.freq==0] - results$lo.inter.freq[results$sig.inter.rich==0 & results$sig.inter.freq==0])/(results$up.inter.freq[results$sig.inter.rich==0 & results$sig.inter.freq==0] - results$lo.inter.freq[results$sig.inter.rich==0 & results$sig.inter.freq==0])#
#
plot(results$inter.MPD[results$sig.inter.rich==0 & results$sig.inter.freq==0]~results$bio12mean[results$sig.inter.rich==0 & results$sig.inter.freq==0], pch=20, xlim=c(2.1,3.4), ylim=c(0.28,0.58), xlab=expression(Log[10]~" precipitation (mm/yr)"), ylab="Interspecific abundance-weighted mean pairwise distance", cex.lab=1.4, cex.axis=1.4, col=color.scale(inter.scaler, c(1,0,0),c(0.75,1,0.75),c(0,0,1)))#
#
##add points that are only clustered based on richness model as orange#
#
points(results$inter.MPD[results$sig.inter.rich==1 & results$sig.inter.freq==0]~results$bio12mean[results$sig.inter.rich==1 & results$sig.inter.freq==0], pch=20, col="orange", cex=1.4)#
#
##there are no points that are clustered based only on frequency model#
##add points that are clustered based on both models as red#
#
points(results$inter.MPD[results$sig.inter.rich==1 & results$sig.inter.freq==1]~results$bio12mean[results$sig.inter.rich==1 & results$sig.inter.freq==1], pch=20, col="red", cex=1.4)#
#
##add points that are only overdispersed based on frequency model as blue#
#
points(results$inter.MPD[results$sig.inter.rich==0 & results$sig.inter.freq==2]~results$bio12mean[results$sig.inter.rich==0 & results$sig.inter.freq==2], pch=20, col="blue", cex=1.4)#
#
##there are no points that are overdispersed based only on richness model#
##add points that are overdispersed based on both models as purple#
#
points(results$inter.MPD[results$sig.inter.rich==2 & results$sig.inter.freq==2]~results$bio12mean[results$sig.inter.rich==2 & results$sig.inter.freq==2], pch=20, col="purple", cex=1.4)#
#
##add in the best-fit OLS line#
#
intercept <- lm(results$inter.MPD~results$bio12mean)$coefficients[1]#
#
slope <- lm(results$inter.MPD~results$bio12mean)$coefficients[2]#
#
segments(x0=min(results$bio12mean), y0=min(results$bio12mean)*slope+intercept, x1=max(results$bio12mean), y1=max(results$bio12mean)*slope+intercept)#
#
##add in the ancestral state#
#
abline(v = precip.hdr$mode, lty=2)#
#
abline(v = precip.hdr$hdr["95%",1], lty=3)#
#
abline(v = precip.hdr$hdr["95%",2], lty=3)#
#
##plot non-abundance-weighted MPD against MAT#
#
plot(results$noabund.MPD[results$sig.noabund.rich==0 & results$sig.noabund.freq==0]~results$bio1mean[results$sig.noabund.rich==0 & results$sig.noabund.freq==0], pch=20, xlim=c(8,29), ylim=c(0.28,0.58), xlab=expression("Mean annual temperature"~"("~degree~C~")"), ylab="Non-abundance-weighted mean pairwise distance", cex.lab=1.4, cex.axis=1.4, col=color.scale(noabund.scaler, c(1,0,0),c(0.75,1,0.75),c(0,0,1)))#
#
##add points that are only clustered based on richness model as orange#
#
points(results$noabund.MPD[results$sig.noabund.rich==1 & results$sig.noabund.freq==0]~results$bio1mean[results$sig.noabund.rich==1 & results$sig.noabund.freq==0], pch=20, col="orange", cex=1.4)#
#
##there are no points that are clustered based only on frequency model#
##add points that are clustered based on both models as red#
#
points(results$noabund.MPD[results$sig.noabund.rich==1 & results$sig.noabund.freq==1]~results$bio1mean[results$sig.noabund.rich==1 & results$sig.noabund.freq==1], pch=20, col="red", cex=1.4)#
#
##add points that are only overdispersed based on frequency model as blue#
#
points(results$noabund.MPD[results$sig.noabund.rich==0 & results$sig.noabund.freq==2]~results$bio1mean[results$sig.noabund.rich==0 & results$sig.noabund.freq==2], pch=20, col="blue", cex=1.4)#
#
##there are no points that are overdispersed based only on richness model#
##add points that are overdispersed based on both models as purple#
#
points(results$noabund.MPD[results$sig.noabund.rich==2 & results$sig.noabund.freq==2]~results$bio1mean[results$sig.noabund.rich==2 & results$sig.noabund.freq==2], pch=20, col="purple", cex=1.4)#
#
##add in the ancestral state#
#
abline(v = temp.hdr$mode, lty=2)#
#
abline(v = temp.hdr$hdr["95%",1], lty=3)#
#
abline(v = temp.hdr$hdr["95%",2], lty=3)#
#
##plot abundance-weighted MPD against MAT#
#
plot(results$inter.MPD[results$sig.inter.rich==0 & results$sig.inter.freq==0]~results$bio1mean[results$sig.inter.rich==0 & results$sig.inter.freq==0], pch=20, xlim=c(8,29), ylim=c(0.28,0.58), xlab=expression("Mean annual temperature"~"("~degree~C~")"), ylab="Interspecific abundance-weighted mean pairwise distance", cex.lab=1.4, cex.axis=1.4, col=color.scale(inter.scaler, c(1,0,0),c(0.75,1,0.75),c(0,0,1)))#
#
##add points that are only clustered based on richness model as orange#
#
points(results$inter.MPD[results$sig.inter.rich==1 & results$sig.inter.freq==0]~results$bio1mean[results$sig.inter.rich==1 & results$sig.inter.freq==0], pch=20, col="orange", cex=1.4)#
#
##there are no points that are clustered based only on frequency model#
##add points that are clustered based on both models as red#
#
points(results$inter.MPD[results$sig.inter.rich==1 & results$sig.inter.freq==1]~results$bio1mean[results$sig.inter.rich==1 & results$sig.inter.freq==1], pch=20, col="red", cex=1.4)#
#
##add points that are only overdispersed based on frequency model as blue#
#
points(results$inter.MPD[results$sig.inter.rich==0 & results$sig.inter.freq==2]~results$bio1mean[results$sig.inter.rich==0 & results$sig.inter.freq==2], pch=20, col="blue", cex=1.4)#
#
##there are no points that are overdispersed based only on richness model#
##add points that are overdispersed based on both models as purple#
#
points(results$inter.MPD[results$sig.inter.rich==2 & results$sig.inter.freq==2]~results$bio1mean[results$sig.inter.rich==2 & results$sig.inter.freq==2], pch=20, col="purple", cex=1.4)#
#
##add in the ancestral state#
#
abline(v = temp.hdr$mode, lty=2)#
#
abline(v = temp.hdr$hdr["95%",1], lty=3)#
#
abline(v = temp.hdr$hdr["95%",2], lty=3)#
#
###########################################################################################
####################PLOT THE MPD RESULTS COLOR-CODED BY SIGNIFICANCE#######################
###########################################################################################
#
##get a sense of where the points sit in the space of the confidence intervals as a function of richness. see notes above for colors, etc. until i add the CIs, all I'm doing is changing the xaxis to be species richness instead of a climate variable#
#
plot(results$noabund.MPD[results$sig.noabund.rich==0 & results$sig.noabund.freq==0]~results$richness[results$sig.noabund.rich==0 & results$sig.noabund.freq==0], pch=20, xlim=c(4,34), ylim=c(0.28,0.63), xlab="Species richness", ylab="Non-abundance-weighted mean pairwise distance", col=color.scale(noabund.scaler, c(1,0,0),c(0.75,1,0.75),c(0,0,1)))#
#
points(results$noabund.MPD[results$sig.noabund.rich==1 & results$sig.noabund.freq==0]~results$richness[results$sig.noabund.rich==1 & results$sig.noabund.freq==0], pch=20, col="orange", cex=1.4)#
#
points(results$noabund.MPD[results$sig.noabund.rich==1 & results$sig.noabund.freq==1]~results$richness[results$sig.noabund.rich==1 & results$sig.noabund.freq==1], pch=20, col="red", cex=1.4)#
#
points(results$noabund.MPD[results$sig.noabund.rich==0 & results$sig.noabund.freq==2]~results$richness[results$sig.noabund.rich==0 & results$sig.noabund.freq==2], pch=20, col="blue", cex=1.4)#
#
points(results$noabund.MPD[results$sig.noabund.rich==2 & results$sig.noabund.freq==2]~results$richness[results$sig.noabund.rich==2 & results$sig.noabund.freq==2], pch=20, col="purple", cex=1.4)#
#
##add in the CIs#
#
points(results$up.noabund.rich~results$richness, col="gray", cex=0.8)#
#
points(results$lo.noabund.rich~results$richness, col="gray", cex=0.8)#
#
points(results$up.noabund.freq~results$richness, col="gray40", cex=0.8)#
#
points(results$lo.noabund.freq~results$richness, col="gray40", cex=0.8)#
##move on to interspecific MPD null expectations#
#
plot(results$inter.MPD[results$sig.inter.rich==0 & results$sig.inter.freq==0]~results$richness[results$sig.inter.rich==0 & results$sig.inter.freq==0], pch=20, xlim=c(4,34), ylim=c(0.25,0.65), xlab="Species richness", ylab="Non-abundance-weighted mean pairwise distance", col=color.scale(inter.scaler, c(1,0,0),c(0.75,1,0.75),c(0,0,1)))#
#
points(results$inter.MPD[results$sig.inter.rich==1 & results$sig.inter.freq==0]~results$richness[results$sig.inter.rich==1 & results$sig.inter.freq==0], pch=20, col="orange", cex=1.4)#
#
points(results$inter.MPD[results$sig.inter.rich==1 & results$sig.inter.freq==1]~results$richness[results$sig.inter.rich==1 & results$sig.inter.freq==1], pch=20, col="red", cex=1.4)#
#
points(results$inter.MPD[results$sig.inter.rich==0 & results$sig.inter.freq==2]~results$richness[results$sig.inter.rich==0 & results$sig.inter.freq==2], pch=20, col="blue", cex=1.4)#
#
points(results$inter.MPD[results$sig.inter.rich==2 & results$sig.inter.freq==2]~results$richness[results$sig.inter.rich==2 & results$sig.inter.freq==2], pch=20, col="purple", cex=1.4)#
#
##add in the CIs#
#
points(results$up.inter.rich~results$richness, col="gray", cex=0.8)#
#
points(results$lo.inter.rich~results$richness, col="gray", cex=0.8)#
#
points(results$up.inter.freq~results$richness, col="gray40", cex=0.8)#
#
points(results$lo.inter.freq~results$richness, col="gray40", cex=0.8)#
#
###########################################################################################
####################DEFINE AND USE THE PHYLOCLIMATESPACE FUNCTION#######################
###########################################################################################
#
##the function requires an ape-style-phylogeny and two prepared data frames. one with #
##column 1 as trait 1, column 2 as trait 2, row names as species names.#
##other as same, except that row names are node names (these could come from a function #
##like ace in ape). columns have to be in same order in species.niches and node.niches #
##files. the ability to plot available climate space (BEFORE plotting the #
##phyloclimatespace, so the latter is plotted on top of that) is offered. for that,#
##a simple dataframe with the first column the values of climate available along the #
##x-axis, and the second column those along the y. jitter is available, x.label and #
##y.label are necessary to specify. x.limits and y.limits can#
##be manipulated but do not have to be.#
#
##prepare the tables#
#
species.niches <- cbind(bio1niche, bio12niche)#
#
node.niches <- cbind(REML.bio1$ace, REML.bio12$ace)#
#
climate.points <- data.frame(biomeans.occ.fifty$bio1mean/10, log10(biomeans.occ.fifty$bio12mean))#
#
##define the function. NOTE THERE IS A SLIGHT MODIFICATION OF THIS FUNCTION FROM THE OFFICIAL#
##VERSION! this modification returns an internal data frame called segments.to.plot, which#
##you then use for the radial plot below#
#
phyloclimatespace <- function(ape.phylo, species.niches, node.niches, climate.points, jitter.level=0, x.label, y.label, x.limits, y.limits)#
{#
	require(ape)#
	require(phylobase)#
	require(plotrix)#
	##convert to phylobase phylo. the suppress warnings command is because if one makes a tree ultrametric it can come with some unexpected parameters that phylobase doesn't know how to deal with. just ignores them and all is fine, but no reason to print warnings.	#
	phylobase.phylo <- suppressWarnings(as(ape.phylo,"phylo4"))#
#
	##allow people to jitter the final results so if species have the exact same traits the tips can be distinguished. jitter will be normally set to zero#
	species.niches <- jitter(species.niches, factor=jitter.level)#
	node.niches <- jitter(node.niches, factor=jitter.level)#
	##add the internal node values onto the end of a vector of the species values for each trait#
	temp.trait1 <- c(species.niches[,1], node.niches[,1])#
	temp.trait2 <- c(species.niches[,2], node.niches[,2])#
#
	##combine those two vectors alonge with a column for the node names#
	lookup.table <- data.frame(1:length(temp.trait1), temp.trait1, temp.trait2)#
	row.names(lookup.table) <- NULL#
	names(lookup.table) <- c("node","col1","col2")#
#
	##make a new data table that has one row less than the current phylo. take the row out for the root edge. it just goes to node "0", which isn't in either species or node niches. do not use the label, edge length or the node type columns, and add in four new columns: x0, y0, x1, y1; to be used with drawing segments to connect the nodes. x = col1, y = col2. note that nodes 1-75 refer to the 75 taxa in this phylogeny. we will fill these new columns using the lookup table created above#
	segments.to.plot <- data.frame(phylobase.phylo@edge)[-1,]#
#
	##merge segments.to.plot with the lookup table. note that the by.x & by.y arguments refer not to columns and row but to first dataframe (x) and second (y)#
	segments.to.plot <- merge(segments.to.plot, lookup.table, by.x="ancestor", by.y="node")#
	names(segments.to.plot)[3:4] = c("x0","y0")#
#
	segments.to.plot <- merge(segments.to.plot, lookup.table, by.x="descendant", by.y="node")#
	names(segments.to.plot)[5:6] = c("x1","y1")#
#
	##it ends up switching descendants and ancestors here so that the former is the first column. we actually want ancestors as the first column#
	segments.to.plot <- data.frame(segments.to.plot$ancestor, segments.to.plot$descendant, segments.to.plot$x0, segments.to.plot$y0, segments.to.plot$x1, segments.to.plot$y1)#
	names(segments.to.plot) <- c("ancestor","descendant","x0","y0","x1","y1")#
	##will now try and color the branches by how deep they are in the phylogeny. for every node, will derive its distance from the root. will look at the distribution of these distances and break into 5 categories (blue, cyan, green, yellow, red). whether or not one uses an ultrametric tree here has a big influence on results#
#
	all.dist <- dist.nodes(ape.phylo)#
#
	##get the distances between the interior nodes and the root AND the tips and the root#
	root.dist <- all.dist[length(meliphagidae$tip.label)+1, ]#
#
	##use quantile to determine where breaks are. call tips "red" and divide the internal nodes four categories#
#
	to.break <- root.dist[(length(meliphagidae$tip.label)+1):length(root.dist)]#
#
	one <- quantile(to.break, 0.25)#
	two <- quantile(to.break, 0.50)#
	three <- quantile(to.break, 0.75)#
	four <- quantile(to.break, 1)#
#
	##make an empty character vector for use in coloring branches and fill based on distance of respective node to root. i am confused about how there can be anything greater than four here, but there are a few. will see what happens#
	branch.color <- character(length(root.dist))#
	names(branch.color) <- names(root.dist)#
	branch.color[root.dist >= 0 & root.dist < one] <- "blue"#
	branch.color[root.dist >= one & root.dist < two] <- "cyan"#
	branch.color[root.dist >= two & root.dist < three] <- "green"#
	branch.color[root.dist >= three & root.dist <= four] <- "yellow"#
	branch.color[root.dist > four] <- "red"#
#
	##bind the character vector colors back into the segments to plot dataframe, first by ancestor, then by descendent#
	temp <- as.data.frame(branch.color)#
	temp <- cbind(temp, 1:length(root.dist))#
	names(temp)[2]="num"#
	segments.to.plot <- merge(segments.to.plot, temp, by.x="ancestor", by.y="num")#
	names(segments.to.plot)[7]="from"#
	segments.to.plot <- merge(segments.to.plot, temp, by.x="descendant", by.y="num")#
	names(segments.to.plot)[8]="to"#
#
	##again, need to switch the columns of ancestors and descendants back.#
	segments.to.plot <- data.frame(segments.to.plot$ancestor, segments.to.plot$descendant, segments.to.plot$x0, segments.to.plot$y0, segments.to.plot$x1, segments.to.plot$y1, segments.to.plot$from, segments.to.plot$to)#
	names(segments.to.plot) <- c("ancestor","descendant","x0","y0","x1","y1","from","to")#
#
	##need to coerce these to characters for it to plot right#
	segments.to.plot$from <- as.character(segments.to.plot$from)#
	segments.to.plot$to <- as.character(segments.to.plot$to)#
#
	##add six new columns here. The first three will specify in R,G,B space the color from the "from" column, the second are for the "to" column#
#
	for(i in 1:dim(segments.to.plot)[1])#
	{#
		if(segments.to.plot$from[i] == "blue")#
		{#
			segments.to.plot$from.r[i] = 0#
			segments.to.plot$from.g[i] = 0#
			segments.to.plot$from.b[i] = 1#
		}#
		else if(segments.to.plot$from[i] == "cyan")#
		{#
			segments.to.plot$from.r[i] = 0#
			segments.to.plot$from.g[i] = 1#
			segments.to.plot$from.b[i] = 1#
		}#
		else if(segments.to.plot$from[i] == "green")#
		{#
			segments.to.plot$from.r[i] = 0#
			segments.to.plot$from.g[i] = 1#
			segments.to.plot$from.b[i] = 0#
		}#
		else if(segments.to.plot$from[i] == "yellow")#
		{#
			segments.to.plot$from.r[i] = 1#
			segments.to.plot$from.g[i] = 1#
			segments.to.plot$from.b[i] = 0#
		}#
		else if(segments.to.plot$from[i] == "red")#
		{#
			segments.to.plot$from.r[i] = 1#
			segments.to.plot$from.g[i] = 0#
			segments.to.plot$from.b[i] = 0#
		}#
	}#
#
	for(i in 1:dim(segments.to.plot)[1])#
	{#
		if(segments.to.plot$to[i] == "blue")#
		{#
			segments.to.plot$to.r[i] = 0#
			segments.to.plot$to.g[i] = 0#
			segments.to.plot$to.b[i] = 1#
		}#
		else if(segments.to.plot$to[i] == "cyan")#
		{#
			segments.to.plot$to.r[i] = 0#
			segments.to.plot$to.g[i] = 1#
			segments.to.plot$to.b[i] = 1#
		}#
		else if(segments.to.plot$to[i] == "green")#
		{#
			segments.to.plot$to.r[i] = 0#
			segments.to.plot$to.g[i] = 1#
			segments.to.plot$to.b[i] = 0#
		}#
		else if(segments.to.plot$to[i] == "yellow")#
		{#
			segments.to.plot$to.r[i] = 1#
			segments.to.plot$to.g[i] = 1#
			segments.to.plot$to.b[i] = 0#
		}#
		else if(segments.to.plot$to[i] == "red")#
		{#
			segments.to.plot$to.r[i] = 1#
			segments.to.plot$to.g[i] = 0#
			segments.to.plot$to.b[i] = 0#
		}#
	}#
#
	##set up an empty plot. if x and y limits aren't given, just let it figure out the appropriate limits#
	if(missing(x.limits) & missing(y.limits))#
	{#
		plot(lookup.table$col2~lookup.table$col1, xlab=x.label, ylab=y.label, type="n")#
	}#
#
	else if(missing(x.limits) | missing(y.limits))#
	{#
		warning("Need to specify either both x & y limits or no limits at all")#
	}#
	else#
	{#
		plot(lookup.table$col2~lookup.table$col1, xlab=x.label, ylab=y.label, type="n", xlim=x.limits, ylim=y.limits)#
	}#
#
	if(missing(climate.points))#
	{#
		print("No climate points supplied")#
	}#
	else#
	{#
		points(climate.points, pch=20, cex=0.6, col="gray80")#
	}#
#
	##this nested for loop breaks each line segment into 99 smaller segments, and basically figures out how to color scale the entire segment, then plots them as lines#
	for(i in 1:dim(segments.to.plot)[1])#
	{#
		breaks = 99#
		x <- c()#
		y <- c()#
		temp.x <- c()#
		temp.y <- c()#
		for(j in 1:breaks)#
		{#
			temp.x[j] <- (segments.to.plot[i,5]-segments.to.plot[i,3])/breaks*j+segments.to.plot[i,3]#
			x <- c(segments.to.plot[i,3],temp.x)#
			temp.y[j] <- (segments.to.plot[i,6]-segments.to.plot[i,4])/breaks*j+segments.to.plot[i,4]#
			y <- c(segments.to.plot[i,4],temp.y)#
		}#
		xydist <- sqrt(x^2+y^2)#
		##this is necessary because when the distances decrease it flips the scale away from what you'd expect#
		if(xydist[1] > xydist[breaks+1])#
		{#
			xydist <- (-1)*xydist#
		}#
		##the way this works is if you want it to go from just blue (0,0,1) to cyan (0,1,1) you code it c(0,0),c(0,1),c(1,1) and if you wanted it to go from cyan to blue to cyan it would be c(0,0,0),c(1,0,1),c(1,1,1), etc. the first place in each argument refers to color 1, the second place color 2, etc.#
#
		color.scale.lines(x,y,c(segments.to.plot$from.r[i],segments.to.plot$to.r[i]),c(segments.to.plot$from.g[i],segments.to.plot$to.g[i]),c(segments.to.plot$from.b[i],segments.to.plot$to.b[i]),colvar=xydist,lwd=2)#
	}#
#
	points(lookup.table[1:length(meliphagidae$tip.label), ]$col2~lookup.table[1:length(meliphagidae$tip.label), ]$col1, pch=20, col="red")#
#
	return(segments.to.plot)#
#
}#
#
##you created an option to jitter the points in the function, which is useful for quick #
##visualization, but for the final figure, it'd be better to systematically change the #
##problem species. push around these points slightly and systematically#
#
##change Lichenostomus flavicollis#
species.niches[65,2] <- 3.09#
#
##change Melithreptus validirostris#
species.niches[64,2] = 3.11#
#
##change Melithreptus affinis#
species.niches[58,2] = 3.08#
#
##change Meliphaga lewinii#
species.niches[31,2] = 3#
#
##there is room to improve some additional species' points, but this is a pretty good #
##start. call phyloclimatespace function. use nice axis labels, and space things out nicely#
#
scaled <- phyloclimatespace(meliphagidae2, species.niches=species.niches, node.niches=node.niches, climate.points=climate.points, x.label=expression("Mean annual temperature"~"("~degree~C~")"), y.label=expression(Log[10]~" precipitation (mm/yr)"), x.limits=c(9,27.5), y.limits=c(2.2,3.2))#
#
##call the phyloclimatespace function on the node niches calculated with the trend models#
#
trend.nodes <- cbind(trend.temp.nodes,trend.precip.nodes)#
#
phyloclimatespace(meliphagidae2, species.niches=species.niches, node.niches=trend.nodes, climate.points=climate.points, x.label=expression("Mean annual temperature"~"("~degree~C~")"), y.label=expression(Log[10]~" precipitation (mm/yr)"), x.limits=c(9,27.5), y.limits=c(2.2,3.2))#
#
###########################################################################################
####################MAKE THE RADIAL PLOT#######################
###########################################################################################
#
##looking at this figure, it appears that at higher precipitation, more of the vectors are#
##going left and right, while at lower precip, more of the vectors are going down. #
##want to make a radial plot of angle as a function of precipitation#
##however, a problem arises when trying to calculate the angle of these vectors, as the #
##scales are not commensurate (though they appear so in the figure). need to scale x0,x1,y0,y1#
##made a slight modification to phyloclimatespace function from the real version #
##(in that version there is no return statement) to have it return segments to plot#
##use the function "scale", with argument scale set to TRUE, and center to FALSE. Center, #
##if it equaled true, would center a column by subtracting the mean and scales by dividing#
##by the standard deviation first prep the data frame and derive the midpoint (BEFORE ACTUALLY SCALING!)#
#
scaled <- data.frame(scaled$ancestor, scaled$descendant, scaled$x0, scaled$y0, scaled$x1, scaled$y1)#
names(scaled) <- c("ancestor","descendant","x0","y0","x1","y1")#
#
##now derive the midpoint (in terms of precipitation) of each vector in the figure#
#
scaled$midpoint <- (scaled$y1-scaled$y0)/2+scaled$y0#
#
scaled$x0 <- scale(scaled$x0, center=FALSE, scale=TRUE)#
scaled$y0 <- scale(scaled$y0, center=FALSE, scale=TRUE)#
scaled$x1 <- scale(scaled$x1, center=FALSE, scale=TRUE)#
scaled$y1 <- scale(scaled$y1, center=FALSE, scale=TRUE)#
#
##now create a new vector and bind it back into the "scaled" data frame. this vector is #
##formed from a long logical statement describing how to calculate the angle of every #
##vector depending on which quadrant it is headed towards (and also for horizontal or #
##vertical lines)#
#
for(i in 1:dim(scaled)[1])#
{#
	if(scaled$x0[i] < scaled$x1[i] & scaled$y0[i] < scaled$y1[i])#
	{#
		scaled$w[i] <- abs(scaled$x1[i]-scaled$x0[i])#
		scaled$h[i] <- abs(scaled$y1[i]-scaled$y0[i])#
		scaled$l[i] <- sqrt(scaled$w[i]^2+scaled$h[i]^2)#
		scaled$quad[i] <- "one"#
		scaled$answer[i] <- asin(scaled$w[i]/scaled$l[i])#
	}#
	else if(scaled$x0[i] < scaled$x1[i] & scaled$y0[i] > scaled$y1[i])#
	{#
		scaled$w[i] <- abs(scaled$x1[i]-scaled$x0[i])#
		scaled$h[i] <- abs(scaled$y1[i]-scaled$y0[i])#
		scaled$l[i] <- sqrt(scaled$w[i]^2+scaled$h[i]^2)#
		scaled$quad[i] <- "two"#
		scaled$answer[i] <- asin(scaled$h[i]/scaled$l[i])+pi/2#
	}#
	else if(scaled$x0[i] > scaled$x1[i] & scaled$y0[i] > scaled$y1[i])#
	{#
		scaled$w[i] <- abs(scaled$x1[i]-scaled$x0[i])#
		scaled$h[i] <- abs(scaled$y1[i]-scaled$y0[i])#
		scaled$l[i] <- sqrt(scaled$w[i]^2+scaled$h[i]^2)#
		scaled$quad[i] <- "three"#
		scaled$answer[i] <- asin(scaled$w[i]/scaled$l[i])+pi#
	}#
	else if(scaled$x0[i] > scaled$x1[i] & scaled$y0[i] < scaled$y1[i])#
	{#
		scaled$w[i] <- abs(scaled$x1[i]-scaled$x0[i])#
		scaled$h[i] <- abs(scaled$y1[i]-scaled$y0[i])#
		scaled$l[i] <- sqrt(scaled$w[i]^2+scaled$h[i]^2)#
		scaled$quad[i] <- "four"#
		scaled$answer[i] <- asin(scaled$h[i]/scaled$l[i])+pi*3/2#
	}#
	else if(scaled$x0[i] == scaled$x1[i] & scaled$y0[i] < scaled$y1[i])#
	{#
		scaled$answer[i] <- 0#
	}#
	else if(scaled$x0[i] == scaled$x1[i] & scaled$y0[i] > scaled$y1[i])#
	{#
		scaled$answer[i] <- pi#
	}#
	else if(scaled$y0[i] == scaled$y1[i] & scaled$x0[i] < scaled$x1[i])#
	{#
		scaled$answer[i] <- pi/2#
	}#
	else if(scaled$y0[i] == scaled$y1[i] & scaled$x0[i] > scaled$x1[i])#
	{#
		scaled$answer[i] <- pi*3/2#
	}#
}#
#
##Reverse the precipitation axis. Plotrix does not seem to do that well. So, have to do it manually.#
#
reversed <- scaled$midpoint*-1#
#
par(cex.lab=1.5)#
#
par(cex.axis=1.5)#
#
radial.plot(lengths=reversed, radial.pos=scaled$answer, labels=c(expression("0"~degree),expression("41"~degree),expression("81"~degree),expression("121"~degree),expression("162"~degree),expression("202"~degree),expression("243"~degree),expression("284"~degree),expression("324"~degree)), start=pi/2, rp.type="s", clockwise=TRUE, show.grid.labels=3, grid.col="black", grid.unit="log mm/yr", point.symbols=20, point.col=color.scale(scaled$midpoint,c(1,1,0),c(0,0,0),c(0,1,1)), cex=7, radial.lim=c(-3.4,-2.4), radial.labels=c(3.2,3,2.8,2.6,2.4))#
#
##IMPORTANT TO RUN: these commands reset the graphical parameters#
#
par(cex.lab=1)#
#
par(cex.axis=1)#
#
###########################################################################################
####################PLOT SPECIES RICHNESS AS FUNCTION OF CLIMATE#######################
###########################################################################################
#
##plot species richness as a function of MAP#
#
plot(results$richness~results$bio12mean, pch=20, xlab=expression(Log[10]~" precipitation (mm/yr)"), ylab="Species richness", xlim=c(2.1,3.4), cex.axis=1.4, cex.lab=1.4, cex=1.3)#
#
##add an OLS line#
#
intercept <- lm(results$richness~results$bio12mean)$coefficients[1]#
slope <- lm(results$richness~results$bio12mean)$coefficients[2]#
#
segments(x0=min(results$bio12mean), y0=min(results$bio12mean)*slope+intercept, x1=max(results$bio12mean), y1=max(results$bio12mean)*slope+intercept)#
#
##plot richness as a function of MAT#
#
plot(results$richness~results$bio1mean, pch=20, xlab=expression("Mean annual temperature"~"("~degree~C~")"), ylab="Species richness", xlim=c(8,29), cex.axis=1.4, cex.lab=1.4, cex=1.3)#
#
intercept <- lm(results$richness~results$bio1mean)$coefficients[1]#
slope <- lm(results$richness~results$bio1mean)$coefficients[2]#
#
segments(x0=min(results$bio1mean), y0=min(results$bio1mean)*slope+intercept, x1=max(results$bio1mean), y1=max(results$bio1mean)*slope+intercept)#
#
###########################################################################################
####################CALCULATE RANGE SIZE, PLOT AS FUNCTION OF CLIMATE AND###################
####################DEFINE A FUNCTION TO CALCULATE PROPORTION OF OCCUPIED CLIMATE SPACE####
###########################################################################################
#
##derive a crude estimate of geographic range size by summing, for each species, the number of 100x100 km grid cells it occurs in. relate this value to the mean annual precipitation regime experienced by that taxon#
#
##the 2 argument below specifies to sum by column#
#
range.size <- apply(cdm.occ.onehund, 2, lengthNonZeros)#
#
##sort it into phylogenetic order#
#
range.size <- sort(range.size)[meliphagidae$tip.label]#
#
##combine this with the species.niches data.frame#
#
species.niches <- cbind(species.niches, range.size)#
#
##write a function to find the proportion of available climate space occupied by each sp#
##this function takes a dataframe that is a phylocom style community data matrix (with#
##plot as first column, abundance as second, and species as third) that has the climatic#
##data tacked on as additional columns. a column needs to be called "species" & another#
##"id". this can be run either using a species' min and max climate extremes, or with #
##something like it's 90% distribution. just switch quantile to min/max below if desired#
#
rangeOccupied <- function(biomeansDF, specific.biomean, phylogeny)#
{#
	available <- numeric(length(phylogeny$tip.label))#
	occupied <- numeric(length(phylogeny$tip.label))#
	quotient <- numeric(length(phylogeny$tip.label))#
	spMin <- numeric(length(phylogeny$tip.label))#
	spMax <- numeric(length(phylogeny$tip.label))#
	results <- data.frame(spMin, spMax, available, occupied, quotient)#
	for(i in 1:length(phylogeny$tip.label))#
	{#
		species <- phylogeny$tip.label[i]#
		results$spMin[i] <- quantile(biomeansDF[,specific.biomean][biomeansDF$species==species], 0.05, na.rm=TRUE)#
		results$spMax[i] <- quantile(biomeansDF[,specific.biomean][biomeansDF$species==species], 0.95, na.rm=TRUE)#
		results$available[i] <- length(unique(biomeansDF[,"id"][biomeansDF[,specific.biomean] >= results$spMin[i] & biomeansDF[,specific.biomean] <= results$spMax[i]]))#
		results$occupied[i] <- length(biomeansDF[,specific.biomean][biomeansDF$species==species])#
		results$quotient[i] <- results$occupied[i]/results$available[i]#
	}#
	return(results)#
}#
#
##call the function for MAP#
ranges.MAP <- rangeOccupied(combo.onehund, "bio12mean", meliphagidae)#
#
##add row names#
#
row.names(ranges.MAP) <- meliphagidae$tip.label#
#
##re-define the species niches matrix as a data frame with these new data. and rename new column#
##also, multiply quotient by 100 so it is in units of "percent"#
#
species.niches <- data.frame(species.niches, ranges.MAP$quotient)#
#
names(species.niches)[4]="quotient.MAP"#
#
species.niches$quotient.MAP <- species.niches$quotient.MAP*100#
#
##call the function for MAT and do all the same stuff#
#
ranges.MAT <- rangeOccupied(combo.onehund, "bio1mean", meliphagidae)#
#
row.names(ranges.MAT) <- meliphagidae$tip.label#
#
species.niches <- cbind(species.niches, ranges.MAT$quotient)#
#
names(species.niches)[5]="quotient.MAT"#
#
species.niches$quotient.MAT <- species.niches$quotient.MAT*100#
#
##plot range size as a function of MAP and add an OLS line#
#
plot(species.niches[,3]~species.niches[,2], xlab=expression(Log[10]~" precipitation (mm/yr)"), ylab="Range size (sum of occurrences)", xlim=c(2.1,3.4), pch=20, cex.axis=1.4, cex.lab=1.4, cex=1.3)#
#
intercept <- lm(species.niches[,3]~species.niches[,2])$coefficients[1]#
slope <- lm(species.niches[,3]~species.niches[,2])$coefficients[2]#
#
segments(x0=min(species.niches[,2]), y0=min(species.niches[,2])*slope+intercept, x1=max(species.niches[,2]), y1=max(species.niches[,2])*slope+intercept)#
#
##plot range as a function of MAT, no need for OLS line, not significant#
#
plot(species.niches[,3]~species.niches[,1], xlab=expression("Mean annual temperature"~"("~degree~C~")"), ylab="Range size (sum of occurrences)", xlim=c(8,29), pch=20, cex.axis=1.4, cex.lab=1.4, cex=1.3)#
#
##plot the percent of occupied grid cells with respect to MAP as a function of the mean MAP niche of a species#
#
plot(species.niches$quotient.MAP~species.niches$bio12niche, xlab=expression(Log[10]~" precipitation (mm/yr)"), ylab="Percent of available precipitation space occupied", pch=20, cex.axis=1.4, cex.lab=1.4, cex=1.3)#
#
intercept <- lm(species.niches$quotient.MAP~species.niches$bio12niche)$coefficients[1]#
slope <- lm(species.niches$quotient.MAP~species.niches$bio12niche)$coefficients[2]#
#
segments(x0=min(species.niches$bio12niche), y0=min(species.niches$bio12niche)*slope+intercept, x1=max(species.niches$bio12niche), y1=max(species.niches$bio12niche)*slope+intercept)#
#
##plot the percent of occupied grid cells with respect to MAT as a function of the mean MAP#
#
plot(species.niches$quotient.MAT~species.niches$bio12niche, xlab=expression(Log[10]~" precipitation (mm/yr)"), ylab="Percent of available temperature space occupied", pch=20, cex.axis=1.4, cex.lab=1.4, cex=1.3)#
#
intercept <- lm(species.niches$quotient.MAT~species.niches$bio12niche)$coefficients[1]#
slope <- lm(species.niches$quotient.MAT~species.niches$bio12niche)$coefficients[2]#
#
segments(x0=min(species.niches$bio12niche), y0=min(species.niches$bio12niche)*slope+intercept, x1=max(species.niches$bio12niche), y1=max(species.niches$bio12niche)*slope+intercept)#
#
##plot the percent of occupied grid cells with respect to MAP as a function of the mean MAT niche of a species#
#
plot(species.niches$quotient.MAP~species.niches$bio1niche, xlab=expression("Mean annual temperature"~"("~degree~C~")"), ylab="Percent of available precipitation space occupied", pch=20, cex.axis=1.4, cex.lab=1.4, cex=1.3)#
#
##no reason for an OLS line, not significant#
#
##plot the percent of occupied grid cells with respect to MAT as a function of the mean MAT niche of a species#
#
plot(species.niches$quotient.MAT~species.niches$bio1niche, xlab=expression("Mean annual temperature"~"("~degree~C~")"), ylab="Percent of available temperature space occupied", pch=20, cex.axis=1.4, cex.lab=1.4, cex=1.3)#
#
intercept <- lm(species.niches$quotient.MAT~species.niches$bio1niche)$coefficients[1]#
slope <- lm(species.niches$quotient.MAT~species.niches$bio1niche)$coefficients[2]#
#
segments(x0=min(species.niches$bio1niche), y0=min(species.niches$bio1niche)*slope+intercept, x1=max(species.niches$bio1niche), y1=max(species.niches$bio1niche)*slope+intercept)#
#
###########################################################################################
####################FIND THE PHYLOGENETIC SIGNAL OF MAT AND MAP###################
###########################################################################################
#
##define your K-calc function#
#
myKcalc <- function(trait.vector, phylogeny, reps)#
{#
	observed.K <- Kcalc(trait.vector, phylogeny, checkdata=TRUE)#
	tipsh <- replicate(reps, Kcalc(sample(trait.vector), phylogeny, checkdata=FALSE))#
	mean.tipsh <- mean(tipsh)#
	sd.tipsh <- sd(tipsh)#
	z.tipsh <- (observed.K - mean.tipsh)/sd.tipsh#
	p.tipsh <- (reps + 2 - rank(c(observed.K, tipsh))[1])/(reps+1)#
	results <- data.frame(observed.K, mean.randomized.K = mean.tipsh, z.score = z.tipsh, p.score = p.tipsh)#
	return(results)#
}#
#
##calculate K. note that you are doing this on your ultrametric tree. results are even more significant if you use your ultrametric tree#
##THESE ARE CURRENTLY HASHED OUT BECAUSE I'M MOVING TO PAGEL'S LAMBDA INSTEAD#
#
##MAP.signal <- myKcalc(species.niches[,2], meliphagidae, 1000)#
#
##and for MAT#
#
##MAT.signal <- myKcalc(species.niches[,1], meliphagidae, 1000)#
#
MAP.lambda <- phylosig(meliphagidae, bio12niche, method="lambda", test=TRUE, nsim=10000)#
#
MAT.lambda <- phylosig(meliphagidae, bio1niche, method="lambda", test=TRUE, nsim=10000)#
#
##to incorporate measurement error in these niches, try following. the starting values don't really matter#
##though some will cause problems in terms of convergence of optim()#
##using meliphagidae2 has effect of increasing lambda above 1 for bio12!#
#
MAT.SE.lambda <- phylosig(meliphagidae, bio1niche, method="lambda", test=TRUE, nsim=1000000, start=c(1,0), se=bio1STDniche)#
#
MAP.SE.lambda <- phylosig(meliphagidae, bio12niche, method="lambda", test=TRUE, nsim=1000000, start=c(1,0), se=bio12STDniche)#
#
##now fit brownian motion evolution models sensu O'Meara et al (2006). First not incorporating SE#
#
##you need to run this first line of code sensu: http://blog.phytools.org/2012/11/testing-for-pagels-10.html#
#
meliphagidae$mapped.edge <- matrix(meliphagidae$edge.length, nrow(meliphagidae$edge), 1, dimnames=list(NULL,"1"))#
#
##then fit models#
#
MAT.bm.logL <- brownie.lite(meliphagidae, x=bio1niche)$logL1#
#
MAP.bm.logL <- brownie.lite(meliphagidae, x=bio12niche)$logL1#
#
##now including SE#
#
MAT.SE.bm.logL <- brownie.lite(meliphagidae, x=bio1niche, se=bio1STDniche)$logL1#
#
MAP.SE.bm.logL <- brownie.lite(meliphagidae, x=bio12niche, se=bio12STDniche)$logL1#
#
##now conduct likelihood ratio tests comparing these observed lambda scores to Brownian motion evolution#
#
LR.MAT <- -2 * (MAT.bm.logL - MAT.lambda$logL)#
P.MAT <- pchisq(LR.MAT, df=1, lower.tail=F)#
#
LR.MAP <- -2 * (MAP.bm.logL - MAP.lambda$logL)#
P.MAP <- pchisq(LR.MAP, df=1, lower.tail=F)#
#
##now incorporating SE#
#
LR.SE.MAT <- -2 * (MAT.SE.bm.logL - MAT.SE.lambda$logL)#
P.SE.MAT <- pchisq(LR.SE.MAT, df=1, lower.tail=F)#
#
LR.SE.MAP <- -2 * (MAP.SE.bm.logL - MAP.SE.lambda$logL)#
P.SE.MAP <- pchisq(LR.SE.MAP, df=1, lower.tail=F)
install()
library(devtools)
library(phytools)
fastAnc
phylomorphospace
library(picante)
sample2matrix
example()
library(devtools)
load_all("ggplot2")dev_example("ggplot")
load_all(ggplot2)dev_example("ggplot")
library("ggplot2")
example("ggplot")
load_all("ggplot2")
load_all(ggplot2)
load_all("ggplot2")
package.skeleton(path=path)
path <- "/Users/eliotmiller/Desktop/phylospace"#
#
set_path(path)#
#
options(devtools.name="Eliot Miller")#
#
options(devtools.author="Eliot Miller <eliot.isaac@gmail.com> [aut, cre]")#
#
options(devtools.license="GPL-3")#
#
target_path <- "/Users/eliotmiller/Desktop/phylospace/phylospace"
package.skeleton(path=path)
?package.skeleton
package.skeleton(path=path, list="phylospace_1_2.R")
package.skeleton(name="anRpackage", code_files="phylospace_1_2.R")
package.skeleton(path=path, name="anRpackage", code_files="phylospace_1_2.R")
path
THE APPROPRIATE CITATION FOR THIS FUNCTION IS: Miller, E.T., A.E. Zanne, & R.E. #
##Ricklefs. 2013. Phylogenetic niche conservatism constrains Australian honeyeater#
##assemblages in stressful environments. Ecology Letters. doi: 10.1111/ele.12156#
#
#This function is very much still in beta version, please report bugs to me. Also let us know and <b> please cite our paper if you use this function </b>. The appropriate citation is at the top of the R script. The figures look best if the input tree is ultrametric, so consider using chronopl() in ape simply for visualization purposes if your tree is not ultrametric. Ancestral node states are not reconstructed within the function, and must be passed automatically. This can be done with the ace() function in ape, the fastAnc() function in phytools, fitContinuousMCMC() from Graham Slater, etc. The function can take a dataframe of available climate space, which it plots as dark gray points behind the phyloclimatespace. This might offer some interesting options for users to plot available morphological space, e.g., corresponding to some modeled physiological/mechanical limits. Because species' may have similar trait values, a quick and dirty jitter option is available, though this has the effect of shifting all
points, internal nodes included. Thus, for final figures, users may choose to slightly shift the points in question manually. X & Y limits can be modified, though they do not have to be. X & Y labels do need to be specified. Additional details in the script.#
#
##the function requires an ape phylogeny and two prepared data frames. one with #
##col 1 as trait 1, col 2 as trait 2, row names as species names, same order as phylogeny.#
##other as same, except that row names are node names, and node values need to be #
##calculated beforehand with any of a variety of functions, e.g. fastAnc() in phytools#
##or ace() in ape. columns have to be in same order in species.niches and node.niches #
##files. the ability to plot available climate space (BEFORE plotting the #
##phylospace, so the latter is plotted on top of that) is offered. for that,#
##a simple dataframe with the first column the values of climate available along the #
##x-axis, and the second column those along the y. jitter is available, x.label and #
##y.label are necessary to specify. x.limits and y.limits can#
##be manipulated but do not have to be. this version of the function now depends on a #
##short function, quadrant(), that is in this file and also needs to be defined.#
##the cool new feature in this version of the function is the ability to plot subclades.#
##for that, you need to know what the node number is (from the entire phylogeny) to which#
##you want to plot down to. there are a variety of ways you could do this, including#
##simply plotting the whole tree with node labels set to true. alternatively, consider#
##the findMRCA function in phytools. you will get an ignorable error if you specify a #
##node to prune at that leaves only tips, with no subsequent internal nodes. also can now #
##plot the edges between the subset node and the root if so desired#
#
##version 1.2. This version will become the first package for distribution -- ELIOT MILLER#
#
##define quadrant function#
#
quadrant <- function(x0, x1, y0, y1)#
{#
	if(x0 < x1 & y0 < y1)#
	{#
		quad <- "quadrant1"#
	}#
	else if(x0 < x1 & y0 > y1)#
	{#
		quad <- "quadrant2"#
	}#
	else if(x0 > x1 & y0 > y1)#
	{#
		quad <- "quadrant3"#
	}#
	else if(x0 > x1 & y0 < y1)#
	{#
		quad <- "quadrant4"#
	}#
	else if(x0 == x1 & y0 < y1)#
	{#
		quad <- "straightUp"#
	}#
	else if(x0 == x1 & y0 > y1)#
	{#
		quad <- "straightDown"#
	}#
	else if(x0 < x1 & y0 == y1)#
	{#
		quad <- "straightRight"#
	}#
	else if(x0 > x1 & y0 == y1)#
	{#
		quad <- "straightLeft"#
	}#
	else if(x0 == x1 & y0 == y1)#
	{#
		quad <- "stationary"#
	}#
	return(quad)#
}#
#
phylospace <- function(ape.phylo, species.niches, node.niches, subset.node, subset.to.root=FALSE, jitter.level=0)#
{#
	require(ape)#
	require(phylobase)#
	require(plotrix)#
	##convert to phylobase phylo. the suppress warnings command is because if one makes a tree ultrametric it can come with some unexpected parameters that phylobase doesn't know how to deal with. just ignores them and all is fine, but no reason to print warnings.	#
	phylobase.phylo <- suppressWarnings(as(ape.phylo,"phylo4"))#
#
	##derive a vector of species' names to subset later#
	keep.species <- ape.phylo$tip.label#
#
	##allow people to jitter the final results so if species have the exact same traits the tips can be distinguished. jitter will be normally set to zero#
	species.niches <- cbind(jitter(species.niches[,1], factor=jitter.level), jitter(species.niches[,2], factor=jitter.level))#
	node.niches <- cbind(jitter(node.niches[,1], factor=jitter.level), jitter(node.niches[,2], factor=jitter.level))#
	##add the internal node values onto the end of a vector of the species values for each trait#
	temp.trait1 <- c(species.niches[,1], node.niches[,1])#
	temp.trait2 <- c(species.niches[,2], node.niches[,2])#
#
	##combine those two vectors alonge with a column for the node names#
	lookup.table <- data.frame(1:length(temp.trait1), temp.trait1, temp.trait2)#
	row.names(lookup.table) <- NULL#
	names(lookup.table) <- c("node","col1","col2")#
#
	##make a new data frame that details the node to node connections. do not use the label, edge length or the node type columns#
	segments.to.plot <- data.frame(phylobase.phylo@edge)#
	##the root edge connects to node "0", which isn't in either species or node niches. however, we still want to plot the root on there#
	##we would lose it on the merge command later because we merge on ancestor (i.e. 0) and lose the whole row#
	##so, basically make a fake little branch that just goes from root to root (remember there will always be one branch less than number of nodes in a fully dichotomous tree)#
	segments.to.plot$ancestor[segments.to.plot$ancestor==0] <- length(ape.phylo$tip.label)+1#
#
	##merge segments.to.plot with the lookup table. note that the by.x & by.y arguments refer not to columns and row but to first dataframe (x) and second (y)#
	##add in four new columns: x0, y0, x1, y1; to be used with drawing segments to connect the nodes. x = col1, y = col2. we will fill these new columns using the lookup table created above#
	##first add in the x,y coordinates for the ancestor#
	segments.to.plot <- merge(segments.to.plot, lookup.table, by.x="ancestor", by.y="node")#
	names(segments.to.plot)[3:4] = c("x0","y0")#
#
	##now add in the x,y coordinates for the descendant#
	segments.to.plot <- merge(segments.to.plot, lookup.table, by.x="descendant", by.y="node")#
	names(segments.to.plot)[5:6] = c("x1","y1")#
	##color the branches by how deep they are in the phylogeny. for every node, will derive its distance from the root. will look at the distribution of these distances and break into 5 categories (blue, cyan, green, yellow, red). whether or not one uses an ultrametric tree here has a big influence on results#
#
	all.dist <- dist.nodes(ape.phylo)#
#
	##get the distances between the interior nodes and the root AND the tips and the root#
	root.dist <- all.dist[length(ape.phylo$tip.label)+1, ]#
#
	##use quantile to determine where breaks are. call tips "red" and divide the internal nodes four categories#
#
	to.break <- root.dist[(length(ape.phylo$tip.label)+1):length(root.dist)]#
#
	one <- quantile(to.break, 0.25)#
	two <- quantile(to.break, 0.50)#
	three <- quantile(to.break, 0.75)#
	four <- quantile(to.break, 1)#
#
	##make an empty character vector for use in coloring branches and fill based on distance of respective node to root. #
	node.color <- character(length(root.dist))#
	names(node.color) <- names(root.dist)#
	node.color[root.dist >= 0 & root.dist < one] <- "blue"#
	node.color[root.dist >= one & root.dist < two] <- "cyan"#
	node.color[root.dist >= two & root.dist < three] <- "green"#
	node.color[root.dist >= three & root.dist <= four] <- "yellow"#
	node.color[root.dist > four] <- "red"#
#
	##bind the character vector colors back into the segments to plot dataframe, first by ancestor, then by descendent#
	temp <- as.data.frame(node.color)#
	temp <- cbind(temp, 1:length(root.dist))#
	names(temp)[2]="num"#
	segments.to.plot <- merge(segments.to.plot, temp, by.x="ancestor", by.y="num")#
	names(segments.to.plot)[7]="from"#
	segments.to.plot <- merge(segments.to.plot, temp, by.x="descendant", by.y="num")#
	names(segments.to.plot)[8]="to"#
#
	##need to coerce these to characters for it to plot right#
	segments.to.plot$from <- as.character(segments.to.plot$from)#
	segments.to.plot$to <- as.character(segments.to.plot$to)#
#
	##add six new columns here. The first three will specify in R,G,B space the color from the "from" column, the second are for the "to" column#
#
	for(i in 1:dim(segments.to.plot)[1])#
	{#
		if(segments.to.plot$from[i] == "blue")#
		{#
			segments.to.plot$from.r[i] = 0#
			segments.to.plot$from.g[i] = 0#
			segments.to.plot$from.b[i] = 1#
		}#
		else if(segments.to.plot$from[i] == "cyan")#
		{#
			segments.to.plot$from.r[i] = 0#
			segments.to.plot$from.g[i] = 1#
			segments.to.plot$from.b[i] = 1#
		}#
		else if(segments.to.plot$from[i] == "green")#
		{#
			segments.to.plot$from.r[i] = 0#
			segments.to.plot$from.g[i] = 1#
			segments.to.plot$from.b[i] = 0#
		}#
		else if(segments.to.plot$from[i] == "yellow")#
		{#
			segments.to.plot$from.r[i] = 1#
			segments.to.plot$from.g[i] = 1#
			segments.to.plot$from.b[i] = 0#
		}#
		else if(segments.to.plot$from[i] == "red")#
		{#
			segments.to.plot$from.r[i] = 1#
			segments.to.plot$from.g[i] = 0#
			segments.to.plot$from.b[i] = 0#
		}#
	}#
#
	for(i in 1:dim(segments.to.plot)[1])#
	{#
		if(segments.to.plot$to[i] == "blue")#
		{#
			segments.to.plot$to.r[i] = 0#
			segments.to.plot$to.g[i] = 0#
			segments.to.plot$to.b[i] = 1#
		}#
		else if(segments.to.plot$to[i] == "cyan")#
		{#
			segments.to.plot$to.r[i] = 0#
			segments.to.plot$to.g[i] = 1#
			segments.to.plot$to.b[i] = 1#
		}#
		else if(segments.to.plot$to[i] == "green")#
		{#
			segments.to.plot$to.r[i] = 0#
			segments.to.plot$to.g[i] = 1#
			segments.to.plot$to.b[i] = 0#
		}#
		else if(segments.to.plot$to[i] == "yellow")#
		{#
			segments.to.plot$to.r[i] = 1#
			segments.to.plot$to.g[i] = 1#
			segments.to.plot$to.b[i] = 0#
		}#
		else if(segments.to.plot$to[i] == "red")#
		{#
			segments.to.plot$to.r[i] = 1#
			segments.to.plot$to.g[i] = 0#
			segments.to.plot$to.b[i] = 0#
		}#
	}#
#
	##if only a specific clade within the whole phylogeny is to be plotted, subset segments to plot accordingly#
	if(missing(subset.node))#
	{#
		subset.node <- "none"#
		print("Retaining entire phylogeny")#
	}#
	else if(!missing(subset.node) & subset.to.root==FALSE)#
	{#
		keep.branches <- descendants(phylobase.phylo, subset.node, type="all")#
		keep.species <- descendants(phylobase.phylo, subset.node, type="tips")#
		segments.to.plot <- segments.to.plot[segments.to.plot$descendant %in% keep.branches, ]#
	}#
	else#
	{#
		keep.branches <- descendants(phylobase.phylo, subset.node, type="all")#
		to.root <- ancestors(phylobase.phylo, subset.node, "ALL") ##calling it like this includes also the subset node#
		keep.branches <- c(rev(to.root), keep.branches)#
		keep.species <- descendants(phylobase.phylo, subset.node, type="tips")#
		segments.to.plot <- segments.to.plot[segments.to.plot$descendant %in% keep.branches, ]#
	}#
#
	##switch the order ancestor and descendant appear in data frame for ease of reading#
	segments.to.plot <- segments.to.plot[ , c("ancestor","descendant","x0","y0","x1","y1","from","to","from.r","from.g","from.b","to.r","to.g","to.b")]#
#
	##derive a vector of species' names based on whatever taxa are left to be plotted#
	name.vector <- phylobase.phylo@label[segments.to.plot$descendant][!is.na(phylobase.phylo@label[segments.to.plot$descendant])]#
#
	##derive a vector of node names based on whatever nodes are left to be plotted#
	node.vector <- segments.to.plot$descendant[segments.to.plot$descendant > length(ape.phylo$tip.label)]#
#
	output <- list(ape.phylo=ape.phylo, segments.to.plot=segments.to.plot, name.vector=name.vector, subset.node=subset.node, node.vector=node.vector)#
#
	class(output) <- "phylospace"#
#
	return(output)#
}#
#
plot.phylospace <- function(phylospace.object, climate.points, species.labels=FALSE, node.labels=FALSE, label.adjust=0, x.label, y.label, x.limits, y.limits)#
{#
	##derive the x,y locations of all points and nodes and their respective labels#
	slopes <- (phylospace.object$segments.to.plot[,6]-phylospace.object$segments.to.plot[,4])/(phylospace.object$segments.to.plot[,5]-phylospace.object$segments.to.plot[,3])#
	x.name.location <- numeric(length=dim(phylospace.object$segments.to.plot)[1])#
	y.name.location <- numeric(length=dim(phylospace.object$segments.to.plot)[1])#
	phylospace.object$segments.to.plot$quadrant <- mapply(quadrant, x0=phylospace.object$segments.to.plot$x0, x1=phylospace.object$segments.to.plot$x1, y0=phylospace.object$segments.to.plot$y0, y1=phylospace.object$segments.to.plot$y1)#
#
	##the general form of these logical statements follows x.location[quadrant in question] <- orig.x.location[quadrant in question] +/- (depending on quadrant) label.adjust/sqrt(1 + slope[quadrant in question]^2)#
	##and y.location[quadrant in question] <- orig.x.location[quadrant] +/- slope[quadrant]*label.adjust/sqrt(1+slope[quadrant]^2)#
	##quadrant 1#
	x.name.location[phylospace.object$segments.to.plot$quadrant == "quadrant1"] <- #
		phylospace.object$segments.to.plot[,5][phylospace.object$segments.to.plot$quadrant == "quadrant1"] + #
		label.adjust/sqrt(1 + slopes[phylospace.object$segments.to.plot$quadrant == "quadrant1"]^2)#
	y.name.location[phylospace.object$segments.to.plot$quadrant == "quadrant1"] <- #
		phylospace.object$segments.to.plot[,6][phylospace.object$segments.to.plot$quadrant == "quadrant1"] + #
		(slopes[phylospace.object$segments.to.plot$quadrant == "quadrant1"]*label.adjust)/sqrt(1 + slopes[phylospace.object$segments.to.plot$quadrant == "quadrant1"]^2)#
	##quadrant 2. slope is negative, hence the addition sign for the y-values#
	x.name.location[phylospace.object$segments.to.plot$quadrant == "quadrant2"] <- #
		phylospace.object$segments.to.plot[,5][phylospace.object$segments.to.plot$quadrant == "quadrant2"] + #
		label.adjust/sqrt(1 + slopes[phylospace.object$segments.to.plot$quadrant == "quadrant2"]^2)#
	y.name.location[phylospace.object$segments.to.plot$quadrant == "quadrant2"] <- #
		phylospace.object$segments.to.plot[,6][phylospace.object$segments.to.plot$quadrant == "quadrant2"] + #
		(slopes[phylospace.object$segments.to.plot$quadrant == "quadrant2"]*label.adjust)/sqrt(1 + slopes[phylospace.object$segments.to.plot$quadrant == "quadrant2"]^2)#
	##quadrant 3#
	x.name.location[phylospace.object$segments.to.plot$quadrant == "quadrant3"] <- #
		phylospace.object$segments.to.plot[,5][phylospace.object$segments.to.plot$quadrant == "quadrant3"] - #
		label.adjust/sqrt(1 + slopes[phylospace.object$segments.to.plot$quadrant == "quadrant3"]^2)#
	y.name.location[phylospace.object$segments.to.plot$quadrant == "quadrant3"] <- #
		phylospace.object$segments.to.plot[,6][phylospace.object$segments.to.plot$quadrant == "quadrant3"] - #
		(slopes[phylospace.object$segments.to.plot$quadrant == "quadrant3"]*label.adjust)/sqrt(1 + slopes[phylospace.object$segments.to.plot$quadrant == "quadrant3"]^2)#
	##quadrant 4. slope is negative, hence the subtraction sign for the y-values#
	x.name.location[phylospace.object$segments.to.plot$quadrant == "quadrant4"] <- #
		phylospace.object$segments.to.plot[,5][phylospace.object$segments.to.plot$quadrant == "quadrant4"] - #
		label.adjust/sqrt(1 + slopes[phylospace.object$segments.to.plot$quadrant == "quadrant4"]^2)#
	y.name.location[phylospace.object$segments.to.plot$quadrant == "quadrant4"] <- #
		phylospace.object$segments.to.plot[,6][phylospace.object$segments.to.plot$quadrant == "quadrant4"] - #
		(slopes[phylospace.object$segments.to.plot$quadrant == "quadrant4"]*label.adjust)/sqrt(1 + slopes[phylospace.object$segments.to.plot$quadrant == "quadrant4"]^2)#
#
	#straight up line#
	x.name.location[phylospace.object$segments.to.plot$quadrant == "straightUp"] <- #
		phylospace.object$segments.to.plot[,5][phylospace.object$segments.to.plot$quadrant == "straightUp"]#
	y.name.location[phylospace.object$segments.to.plot$quadrant == "straightUp"] <- #
		phylospace.object$segments.to.plot[,6][phylospace.object$segments.to.plot$quadrant == "straightUp"] + #
		(slopes[phylospace.object$segments.to.plot$quadrant == "straightUp"]*label.adjust)/sqrt(1 + slopes[phylospace.object$segments.to.plot$quadrant == "straightUp"]^2)#
	#straight down line#
	x.name.location[phylospace.object$segments.to.plot$quadrant == "straightDown"] <- #
		phylospace.object$segments.to.plot[,5][phylospace.object$segments.to.plot$quadrant == "straightDown"]#
	y.name.location[phylospace.object$segments.to.plot$quadrant == "straightDown"] <- #
		phylospace.object$segments.to.plot[,6][phylospace.object$segments.to.plot$quadrant == "straightDown"] - #
		(slopes[phylospace.object$segments.to.plot$quadrant == "straightDown"]*label.adjust)/sqrt(1 + slopes[phylospace.object$segments.to.plot$quadrant == "straightDown"]^2)#
#
	#straight right line#
	x.name.location[phylospace.object$segments.to.plot$quadrant == "straightRight"] <- #
		phylospace.object$segments.to.plot[,5][phylospace.object$segments.to.plot$quadrant == "straightRight"] + #
		label.adjust/sqrt(1 + slopes[phylospace.object$segments.to.plot$quadrant == "straightRight"]^2)#
	y.name.location[phylospace.object$segments.to.plot$quadrant == "straightRight"] <- #
		phylospace.object$segments.to.plot[,6][phylospace.object$segments.to.plot$quadrant == "straightRight"]#
	#straight left line#
	x.name.location[phylospace.object$segments.to.plot$quadrant == "straightRight"] <- #
		phylospace.object$segments.to.plot[,5][phylospace.object$segments.to.plot$quadrant == "straightRight"] - #
		label.adjust/sqrt(1 + slopes[phylospace.object$segments.to.plot$quadrant == "straightRight"]^2)#
	y.name.location[phylospace.object$segments.to.plot$quadrant == "straightRight"] <- #
		phylospace.object$segments.to.plot[,6][phylospace.object$segments.to.plot$quadrant == "straightRight"]#
#
	##for the root edge#
	x.name.location[phylospace.object$segments.to.plot$quadrant == "stationary"] <- #
		phylospace.object$segments.to.plot[,5][phylospace.object$segments.to.plot$quadrant == "stationary"]#
	y.name.location[phylospace.object$segments.to.plot$quadrant == "stationary"] <- #
		phylospace.object$segments.to.plot[,6][phylospace.object$segments.to.plot$quadrant == "stationary"]#
#
	##set up an empty plot. if x and y limits aren't given, just let it figure out the appropriate limits#
	if(missing(x.limits) & missing(y.limits))#
	{#
		plot(lookup.table$col2~lookup.table$col1, xlab=x.label, ylab=y.label, type="n")#
	}#
#
	else if(missing(x.limits) | missing(y.limits))#
	{#
		warning("Need to specify either both x & y limits or no limits at all")#
	}#
	else#
	{#
		plot(lookup.table$col2~lookup.table$col1, xlab=x.label, ylab=y.label, type="n", xlim=x.limits, ylim=y.limits)#
	}#
#
	if(missing(climate.points))#
	{#
		print("No climate points supplied")#
	}#
	else#
	{#
		points(climate.points, pch=20, cex=0.6, col="gray80")#
	}#
#
	##this nested for loop breaks considers an imaginary line segment between either x0 and x1 or y0 and y1, #
	##breaks it into 99 new points, adds the initial x or y point to the start of that vector of #
	##new points, and does this for each row of the segments to plot. this is just to get the appropriate#
	##color scale between nodes. then it plots each line segment according to that color scale#
	##because we added in the fake branch that just goes from blue to blue, this seems to cause this to crash#
	##need to take that line out for this part#
#
	temp.segments.to.plot <- phylospace.object$segments.to.plot[phylospace.object$segments.to.plot$descendant!=length(phylospace.object$ape.phylo$tip.label)+1, ]#
#
	for(i in 1:dim(temp.segments.to.plot)[1])#
	{#
		breaks = 99#
		x <- c()#
		y <- c()#
		temp.x <- c()#
		temp.y <- c()#
		for(j in 1:breaks)#
		{#
			temp.x[j] <- (temp.segments.to.plot[i,5]-temp.segments.to.plot[i,3])/breaks*j+temp.segments.to.plot[i,3]#
			x <- c(temp.segments.to.plot[i,3],temp.x)#
			temp.y[j] <- (temp.segments.to.plot[i,6]-temp.segments.to.plot[i,4])/breaks*j+temp.segments.to.plot[i,4]#
			y <- c(temp.segments.to.plot[i,4],temp.y)#
		}#
		##calculate the euclidean distance between each successive x,y point#
		xydist <- sqrt(x^2+y^2)#
		##this is necessary because the color.scale lines has no way that i know of to tell it which direction the segment is "going"#
		##thus, when the segments are "going" towards quadrants III or IV, it flips the scale away from what you want#
		if(xydist[1] > xydist[breaks+1])#
		{#
			xydist <- (-1)*xydist#
		}#
		##the way this works is if you want it to go from just blue (0,0,1) to cyan (0,1,1) you code it c(0,0),c(0,1),c(1,1) and if you wanted it to go from cyan to blue to cyan it would be c(0,0,0),c(1,0,1),c(1,1,1), etc. the first place in each argument refers to color 1, the second place color 2, etc.#
#
		color.scale.lines(x,y,c(temp.segments.to.plot$from.r[i],temp.segments.to.plot$to.r[i]),c(temp.segments.to.plot$from.g[i],temp.segments.to.plot$to.g[i]),c(temp.segments.to.plot$from.b[i],temp.segments.to.plot$to.b[i]),colvar=xydist,lwd=2)#
	}#
#
	##add the species' points#
	if(phylospace.object$subset.node=="none")#
	{#
		points(lookup.table[1:length(phylospace.object$ape.phylo$tip.label), ]$col2~lookup.table[1:length(phylospace.object$ape.phylo$tip.label), ]$col1, pch=20, col="red")#
	}#
	else#
	{#
		points(lookup.table[lookup.table$node %in% keep.species, ]$col2~lookup.table[lookup.table$node %in% keep.species, ]$col1, pch=20, col="red")#
	}#
#
	##add text to the points, with offset equal to label.adjust argument. IMPORTANTLY, this will work best if x & y are on similar scales. need to revise this script so that it doesn'matter. to query graphical parameters after calling the blank plot: par("usr")#
	if(species.labels == TRUE & node.labels == FALSE)#
	{#
		text(x=x.name.location[1:length(phylospace.object$name.vector)], y=y.name.location[1:length(phylospace.object$name.vector)], labels=phylospace.object$name.vector, cex=0.7)#
	}#
#
	else if(species.labels == TRUE & node.labels == TRUE)#
	{#
		text(x=x.name.location[1:length(phylospace.object$name.vector)], y=y.name.location[1:length(phylospace.object$name.vector)], labels=phylospace.object$name.vector, cex=0.7)#
		text(x=x.name.location[(length(phylospace.object$name.vector)+1):(length(phylospace.object$name.vector)+length(phylospace.object$node.vector))], y=y.name.location[(length(phylospace.object$name.vector)+1):(length(phylospace.object$name.vector)+length(phylospace.object$node.vector))], labels=phylospace.object$node.vector, cex=0.7)#
	}#
	else if(species.labels == FALSE & node.labels == TRUE)#
	{#
		text(x=x.name.location[(length(phylospace.object$name.vector)+1):(length(phylospace.object$name.vector)+length(phylospace.object$node.vector))], y=y.name.location[(length(phylospace.object$name.vector)+1):(length(phylospace.object$name.vector)+length(phylospace.object$node.vector))], labels=phylospace.object$node.vector, cex=0.7)#
	}	#
}
package.skeleton()
dev_example(phylospace)
phylospace
dev_example("phylospace")
load_all("ggplot2")
library(devtools)#
has_devel()
library(devtools)#
#
library(roxygen2)#
#
##doing the above notes with xcode allowed the following to run successfully#
#
has_devel()#
#
##paste whatever you want to work with onto the desktop, into a folder called phylospace#
#
##define your path, BUT ALSO SET IT MANUALLY IN CASE#
path <- "/Users/eliotmiller/Desktop/phylospacer"#
#
set_path(path)#
#
##set some options#
#
options(devtools.desc.name="Eliot Miller")#
#
options(devtools.desc.author="Eliot Miller <eliot.isaac@gmail.com> [aut, cre]")#
#
options(devtools.desc.license="GPL-3")#
#
target_path <- "/Users/eliotmiller/Desktop/phylospacer/phylospacer"
load_all()
?load_all
load_all(target_path)
build(target_path)
build(target_path, vignettes=FALSE)
Sys.which("pdflatex")
data(iris)
dput(iris$Petal.Width)
?dput
library(devtools)#
#
install_github("phylospacer", username="eliotmiller")#
#
library(phylospacer)
?phylospace
library(ape)#
#
#simulate tree with birth-death process#
tree <- rbdtree(birth=0.1, death=0, Tmax=40)#
#
#prune the phylogeny down to 50 species#
tree <- drop.tip(tree, tip=51:length(tree$tip.label))#
#
#simulate trait evolution up tree with Brownian motion process#
trait1 <- rTraitCont(tree, model="BM")#
trait2 <- rTraitCont(tree, model="BM")#
#
#bind the traits together into a matrix#
species.niches <- cbind(trait1, trait2)#
#
#reconstruct ancestral states#
nodes.trait1 <- ace(trait1, tree, type="continuous", method="REML")#
nodes.trait2 <- ace(trait2, tree, type="continuous", method="REML")#
#
node.niches <- cbind(nodes.trait1$ace, nodes.trait2$ace)#
#
#simulate available climate space#
climate.points <- cbind(rnorm(500, mean=0, sd=1), rnorm(100, mean=0, sd=1))#
#
#calculate a phylospace object for the entire phylogeny#
entire <- phylospace(tree, species.niches=species.niches, node.niches=node.niches)#
#
#plot the entire phylospace, with species labels plotted and slightly offset from tips, and with available climate space in background#
plot(entire, species.labels=TRUE, climate.points=climate.points, label.adjust=0.05, lwd=2)
check()
colors
ca
1:100
rep(1, 50)
seq(from=0, to=1)
seq(from=0, to=1, by=0.5)
?seq
seq(from=0.01, to=0.99, length.out=49)
root.dist <- c(rep(1, 50), seq(from=0.01, to=0.99, length.out=49))
root.dist
to.break <- root.dist[51:99]
to.break
names(root.dist)
as.character(1:99)
names(root.dist) <- as.character(1:99)
root.dist
ca <- function(colors)#
{#
#
	root.dist <- c(rep(1, 50), seq(from=0.01, to=0.99, length.out=49))#
	names(root.dist) <- as.character(1:99)#
#
	to.break <- root.dist[51:99]#
#
	one <- quantile(to.break, 0.25)#
	two <- quantile(to.break, 0.50)#
	three <- quantile(to.break, 0.75)#
	four <- quantile(to.break, 1)#
#
	node.color <- character(length(root.dist))#
	names(node.color) <- names(root.dist)#
#
	if(missing(colors))#
	{#
		##make an empty character vector for use in coloring branches and fill based on distance of respective node to root. #
		node.color[root.dist >= 0 & root.dist < one] <- "blue"#
		node.color[root.dist >= one & root.dist < two] <- "cyan"#
		node.color[root.dist >= two & root.dist < three] <- "green"#
		node.color[root.dist >= three & root.dist <= four] <- "yellow"#
		node.color[root.dist > four] <- "red"#
	}#
	else#
	{#
		print("something")#
	}#
}
ca()
colors
missing(colors)
node.color
ca <- function(desired.colors)#
{#
#
	root.dist <- c(rep(1, 50), seq(from=0.01, to=0.99, length.out=49))#
	names(root.dist) <- as.character(1:99)#
#
	to.break <- root.dist[51:99]#
#
	one <- quantile(to.break, 0.25)#
	two <- quantile(to.break, 0.50)#
	three <- quantile(to.break, 0.75)#
	four <- quantile(to.break, 1)#
#
	node.color <- character(length(root.dist))#
	names(node.color) <- names(root.dist)#
#
	if(missing(desired.colors))#
	{#
		##make an empty character vector for use in coloring branches and fill based on distance of respective node to root. #
		node.color[root.dist >= 0 & root.dist < one] <- "blue"#
		node.color[root.dist >= one & root.dist < two] <- "cyan"#
		node.color[root.dist >= two & root.dist < three] <- "green"#
		node.color[root.dist >= three & root.dist <= four] <- "yellow"#
		node.color[root.dist > four] <- "red"#
	}#
	else#
	{#
		print("something")#
	}#
	return(node.color)#
}
ca()
ca <- function(desired.colors)#
{#
#
	root.dist <- c(rep(1, 50), seq(from=0.01, to=0.99, length.out=49))#
	names(root.dist) <- as.character(1:99)#
#
	to.break <- root.dist[51:99]#
#
	one <- quantile(to.break, 0.25)#
	two <- quantile(to.break, 0.50)#
	three <- quantile(to.break, 0.75)#
	four <- quantile(to.break, 1)#
#
	node.color <- character(length(root.dist))#
	names(node.color) <- names(root.dist)#
#
	if(missing(desired.colors))#
	{#
		##make an empty character vector for use in coloring branches and fill based on distance of respective node to root. #
		node.color[root.dist >= 0 & root.dist < one] <- "blue"#
		node.color[root.dist >= one & root.dist < two] <- "cyan"#
		node.color[root.dist >= two & root.dist < three] <- "green"#
		node.color[root.dist >= three & root.dist <= four] <- "yellow"#
		node.color[root.dist > four] <- "red"#
	}#
	else#
	{#
		node.color[root.dist >= 0 & root.dist < one] <- "color1"#
		node.color[root.dist >= one & root.dist < two] <- "color2"#
		node.color[root.dist >= two & root.dist < three] <- "color3"#
		node.color[root.dist >= three & root.dist <= four] <- "color4"#
		node.color[root.dist > four] <- "red"#
	}#
	return(node.color)#
}
ca()
ca(desired.colors=1)
ca <- function(desired.colors)#
{#
#
	root.dist <- c(rep(1, 50), seq(from=0.01, to=0.99, length.out=49))#
	names(root.dist) <- as.character(1:99)#
#
	to.break <- root.dist[51:99]#
#
	one <- quantile(to.break, 0.25)#
	two <- quantile(to.break, 0.50)#
	three <- quantile(to.break, 0.75)#
	four <- quantile(to.break, 1)#
#
	node.color <- character(length(root.dist))#
	names(node.color) <- names(root.dist)#
#
	if(missing(desired.colors))#
	{#
		##make an empty character vector for use in coloring branches and fill based on distance of respective node to root. #
		node.color[root.dist >= 0 & root.dist < one] <- "blue"#
		node.color[root.dist >= one & root.dist < two] <- "cyan"#
		node.color[root.dist >= two & root.dist < three] <- "green"#
		node.color[root.dist >= three & root.dist <= four] <- "yellow"#
		node.color[root.dist > four] <- "red"#
	}#
	else#
	{#
		node.color[root.dist >= 0 & root.dist < one] <- "color1"#
		node.color[root.dist >= one & root.dist < two] <- "color2"#
		node.color[root.dist >= two & root.dist < three] <- "color3"#
		node.color[root.dist >= three & root.dist <= four] <- "color4"#
		node.color[root.dist > four] <- "color5"#
	}#
	return(node.color)#
}
ca(desired.colors=1)
color
Colors
replacement.colors
test
test <- c((1,2,3),(4,5,6))
1,2,4
test <- c(c(1,2,3),c(4,5,6))
test
' Create a phylospace object.#
#'#
#' Given a phylo object, a data frame of species trait values, and another of#
#' reconstructed node values, returns a phylospace object.#
#'#
#' @param ape.phylo Phylo object#
#' @param species.niches Two column data frame (or matrix) with species names as row names  #
#' and exactly matching phylogeny. Columns as traits of interest.#
#' @param node.niches Two column data frame (or matrix) with node names as row names  #
#' and exactly matching phylogeny. Columns as traits of interest.#
#' @param subset.node Optional numeric value (possible character vector if nodes are so#
#' named?) specifying a node at which to subset the phylospace object.#
#' @param subset.to.root Logical argument used for when subset.node is specified. If TRUE,#
#' then all edges between the subset node and the root of the entire phylogeny will also#
#' be retained in the resulting phylospace object.#
#' @param jitter.level Optional numeric value to jitter both species and node values. #
#' Useful for when species' and/or nodes have very similar trait values.#
#' #
#' @details This function does not currently reconstruct ancestral states. These need to#
#' be calculated beforehand with any of a variety of functions, e.g. fastAnc() in phytools#
#' or ace() in ape. It is intended to take two data frames, with the species names of the#
#' species.niches frame exactly matching the phylogeny. Importantly, these need to be#
#' specified as the row names of the data frame, not as a separate column. Similarly, the#
#' reconstructed node names need to be the row names of the node.niches data frame. The#
#' subset.node must be a single number (or object) corresponding to a unique node in the  #
#' tree. There are a variety of ways you could find this, including simply plotting the #
#' node labels onto a tree. Alternatively, consider the findMRCA function in phytools. #
#' Because species may have similar trait values, a quick and dirty jitter option is #
#' available, though this has the effect of shifting all points, internal nodes included. #
#' Thus, users may choose to slightly shift the points in question manually.#
#' The function is still in development version, please report bugs to me. #
#'#
#' @return Returns a phylospace object, which is a list with five elements: the original#
#' phylo object; a data frame with 14 columns describing the colors and bounds of all line#
#' segments; a character vector of all species retained; the identity of the subset#
#' node, if there is one; a vector of all descendant nodes from the subset node, and#
#' including also all ancestors of the subset node if subset.to.root = TRUE#
#'#
#' @export#
#'#
#' @import ape phylobase plotrix#
#'#
#' @references Miller, E.T., A.E. Zanne, & R. E. Ricklefs. In press. Niche conservatism #
#' constrains Australian honeyeater assemblages in stressful environments. Ecology Letters. #
#'#
#' @examples#
#' library(ape)#
#'#
#' #simulate tree with birth-death process#
#' tree <- rbdtree(birth=0.1, death=0, Tmax=40)#
#'#
#' #prune the phylogeny down to 50 species#
#' tree <- drop.tip(tree, tip=51:length(tree$tip.label))#
#'#
#' #simulate trait evolution up tree with Brownian motion process#
#' trait1 <- rTraitCont(tree, model="BM")#
#' trait2 <- rTraitCont(tree, model="BM")#
#'#
#' #bind the traits together into a matrix#
#' species.niches <- cbind(trait1, trait2)#
#'#
#' #reconstruct ancestral states#
#' nodes.trait1 <- ace(trait1, tree, type="continuous", method="REML")#
#' nodes.trait2 <- ace(trait2, tree, type="continuous", method="REML")#
#'#
#' node.niches <- cbind(nodes.trait1$ace, nodes.trait2$ace)#
#'#
#' #simulate available climate space#
#' climate.points <- cbind(rnorm(500, mean=0, sd=1), rnorm(100, mean=0, sd=1))#
#'#
#' #calculate a phylospace object for the entire phylogeny#
#' entire <- phylospace(tree, species.niches=species.niches, node.niches=node.niches)#
#'#
#' #plot the entire phylospace, with species labels plotted and slightly offset from tips, and with available climate space in background#
#' plot(entire, species.labels=TRUE, climate.points=climate.points, label.adjust=0.05, lwd=2)#
#'#
#' #Example of how one could create a series of panels for an animation. Here we are retaining all branches from each subset node to the root#
#' cladeA <- phylospace(tree, species.niches=species.niches, node.niches=node.niches, subset.node=63, subset.to.root=TRUE)#
#' cladeB <- phylospace(tree, species.niches=species.niches, node.niches=node.niches, subset.node=75, subset.to.root=TRUE)#
#' cladeC <- phylospace(tree, species.niches=species.niches, node.niches=node.niches, subset.node=90, subset.to.root=TRUE)#
#'#
#' #These x & y limits can most likely be made more restrictive, depending on the simulated trait data. Keeping broad here, but modify if desired.#
#' #Save each plot before calling next.#
#' plot(phylospace.object=cladeA, species.labels=TRUE, label.adjust=0.1, x.label="Trait 1", y.label="Trait 2", x.limits=c(-2,2), y.limits=c(-2,2), lwd=2)#
#' plot(phylospace.object=cladeB, species.labels=TRUE, label.adjust=0.1, x.label="Trait 1", y.label="Trait 2", x.limits=c(-2,2), y.limits=c(-2,2), lwd=2)#
#' plot(phylospace.object=cladeC, species.labels=TRUE, label.adjust=0.1, x.label="Trait 1", y.label="Trait 2", x.limits=c(-2,2), y.limits=c(-2,2), lwd=2)#
#'#
#' #Example of how to quickly plot phylospace for a small clade without the edges to the root.#
#' plot(phylospace(tree, species.niches, node.niches, subset.node=85), lwd=2)#
#
phylospace <- function(ape.phylo, species.niches, node.niches, subset.node, subset.to.root=FALSE, jitter.level=0, replacement.colors)#
{	#
	##convert to phylobase phylo. the suppress warnings command is because if one makes a tree ultrametric it can come with some unexpected parameters that phylobase doesn't know how to deal with. just ignores them and all is fine, but no reason to print warnings.	#
	phylobase.phylo <- suppressWarnings(as(ape.phylo,"phylo4"))#
#
	##derive a vector of species' names to subset later#
	keep.species <- ape.phylo$tip.label#
#
	##allow people to jitter the final results so if species have the exact same traits the tips can be distinguished. jitter will be normally set to zero#
	species.niches <- cbind(jitter(species.niches[,1], factor=jitter.level), jitter(species.niches[,2], factor=jitter.level))#
	node.niches <- cbind(jitter(node.niches[,1], factor=jitter.level), jitter(node.niches[,2], factor=jitter.level))#
	##add the internal node values onto the end of a vector of the species values for each trait#
	temp.trait1 <- c(species.niches[,1], node.niches[,1])#
	temp.trait2 <- c(species.niches[,2], node.niches[,2])#
#
	##combine those two vectors alonge with a column for the node names#
	lookup.table <- data.frame(1:length(temp.trait1), temp.trait1, temp.trait2)#
	row.names(lookup.table) <- NULL#
	names(lookup.table) <- c("node","col1","col2")#
#
	##make a new data frame that details the node to node connections. do not use the label, edge length or the node type columns#
	segments.to.plot <- data.frame(phylobase.phylo@edge)#
	##the root edge connects to node "0", which isn't in either species or node niches. however, we still want to plot the root on there#
	##we would lose it on the merge command later because we merge on ancestor (i.e. 0) and lose the whole row#
	##so, basically make a fake little branch that just goes from root to root (remember there will always be one branch less than number of nodes in a fully dichotomous tree)#
	segments.to.plot$ancestor[segments.to.plot$ancestor==0] <- length(ape.phylo$tip.label)+1#
#
	##merge segments.to.plot with the lookup table. note that the by.x & by.y arguments refer not to columns and row but to first dataframe (x) and second (y)#
	##add in four new columns: x0, y0, x1, y1; to be used with drawing segments to connect the nodes. x = col1, y = col2. we will fill these new columns using the lookup table created above#
	##first add in the x,y coordinates for the ancestor#
	segments.to.plot <- merge(segments.to.plot, lookup.table, by.x="ancestor", by.y="node")#
	names(segments.to.plot)[3:4] = c("x0","y0")#
#
	##now add in the x,y coordinates for the descendant#
	segments.to.plot <- merge(segments.to.plot, lookup.table, by.x="descendant", by.y="node")#
	names(segments.to.plot)[5:6] = c("x1","y1")#
	##color the branches by how deep they are in the phylogeny. for every node, will derive its distance from the root. will look at the distribution of these distances and break into 5 categories (blue, cyan, green, yellow, red). whether or not one uses an ultrametric tree here has a big influence on results#
#
	all.dist <- dist.nodes(ape.phylo)#
#
	##get the distances between the interior nodes and the root AND the tips and the root#
	root.dist <- all.dist[length(ape.phylo$tip.label)+1, ]#
#
	##use quantile to determine where breaks are. call tips "red" and divide the internal nodes four categories#
#
	to.break <- root.dist[(length(ape.phylo$tip.label)+1):length(root.dist)]#
#
	one <- quantile(to.break, 0.25)#
	two <- quantile(to.break, 0.50)#
	three <- quantile(to.break, 0.75)#
	four <- quantile(to.break, 1)#
#
	##make an empty character vector for use in coloring branches and fill based on distance of respective node to root. #
	node.color <- character(length(root.dist))#
	names(node.color) <- names(root.dist)#
#
	if(missing(replacement.colors))#
	{#
		##make an empty character vector for use in coloring branches and fill based on distance of respective node to root. #
		node.color[root.dist >= 0 & root.dist < one] <- "blue"#
		node.color[root.dist >= one & root.dist < two] <- "cyan"#
		node.color[root.dist >= two & root.dist < three] <- "green"#
		node.color[root.dist >= three & root.dist <= four] <- "yellow"#
		node.color[root.dist > four] <- "red"#
	}#
	else#
	{#
		node.color[root.dist >= 0 & root.dist < one] <- "color1"#
		node.color[root.dist >= one & root.dist < two] <- "color2"#
		node.color[root.dist >= two & root.dist < three] <- "color3"#
		node.color[root.dist >= three & root.dist <= four] <- "color4"#
		node.color[root.dist > four] <- "color5"#
	}#
	##bind the character vector colors back into the segments to plot dataframe, first by ancestor, then by descendent#
	temp <- as.data.frame(node.color)#
	temp <- cbind(temp, 1:length(root.dist))#
	names(temp)[2]="num"#
	segments.to.plot <- merge(segments.to.plot, temp, by.x="ancestor", by.y="num")#
	names(segments.to.plot)[7]="from"#
	segments.to.plot <- merge(segments.to.plot, temp, by.x="descendant", by.y="num")#
	names(segments.to.plot)[8]="to"#
#
	##need to coerce these to characters for it to plot right#
	segments.to.plot$from <- as.character(segments.to.plot$from)#
	segments.to.plot$to <- as.character(segments.to.plot$to)#
#
	##add six new columns here. The first three will specify in R,G,B space the color from the "from" column, the second are for the "to" column#
#
	if(missing(replacement.colors))#
	{#
		for(i in 1:dim(segments.to.plot)[1])#
		{#
			if(segments.to.plot$from[i] == "blue")#
			{#
				segments.to.plot$from.r[i] = 0#
				segments.to.plot$from.g[i] = 0#
				segments.to.plot$from.b[i] = 1#
			}#
			else if(segments.to.plot$from[i] == "cyan")#
			{#
				segments.to.plot$from.r[i] = 0#
				segments.to.plot$from.g[i] = 1#
				segments.to.plot$from.b[i] = 1#
			}#
			else if(segments.to.plot$from[i] == "green")#
			{#
				segments.to.plot$from.r[i] = 0#
				segments.to.plot$from.g[i] = 1#
				segments.to.plot$from.b[i] = 0#
			}#
			else if(segments.to.plot$from[i] == "yellow")#
			{#
				segments.to.plot$from.r[i] = 1#
				segments.to.plot$from.g[i] = 1#
				segments.to.plot$from.b[i] = 0#
			}#
			else if(segments.to.plot$from[i] == "red")#
			{#
				segments.to.plot$from.r[i] = 1#
				segments.to.plot$from.g[i] = 0#
				segments.to.plot$from.b[i] = 0#
			}#
		}#
#
		for(i in 1:dim(segments.to.plot)[1])#
		{#
			if(segments.to.plot$to[i] == "blue")#
			{#
				segments.to.plot$to.r[i] = 0#
				segments.to.plot$to.g[i] = 0#
				segments.to.plot$to.b[i] = 1#
			}#
			else if(segments.to.plot$to[i] == "cyan")#
			{#
				segments.to.plot$to.r[i] = 0#
				segments.to.plot$to.g[i] = 1#
				segments.to.plot$to.b[i] = 1#
			}#
			else if(segments.to.plot$to[i] == "green")#
			{#
				segments.to.plot$to.r[i] = 0#
				segments.to.plot$to.g[i] = 1#
				segments.to.plot$to.b[i] = 0#
			}#
			else if(segments.to.plot$to[i] == "yellow")#
			{#
				segments.to.plot$to.r[i] = 1#
				segments.to.plot$to.g[i] = 1#
				segments.to.plot$to.b[i] = 0#
			}#
			else if(segments.to.plot$to[i] == "red")#
			{#
				segments.to.plot$to.r[i] = 1#
				segments.to.plot$to.g[i] = 0#
				segments.to.plot$to.b[i] = 0#
			}#
		}#
	}#
	else#
	{#
		for(i in 1:dim(segments.to.plot)[1])#
		{#
			if(segments.to.plot$from[i] == "color1")#
			{#
				segments.to.plot$from.r[i] = replacement.colors[1]#
				segments.to.plot$from.g[i] = replacement.colors[2]#
				segments.to.plot$from.b[i] = replacement.colors[3]#
			}#
			else if(segments.to.plot$from[i] == "color2")#
			{#
				segments.to.plot$from.r[i] = replacement.colors[4]#
				segments.to.plot$from.g[i] = replacement.colors[5]#
				segments.to.plot$from.b[i] = replacement.colors[6]#
			}#
			else if(segments.to.plot$from[i] == "color3")#
			{#
				segments.to.plot$from.r[i] = replacement.colors[7]#
				segments.to.plot$from.g[i] = replacement.colors[8]#
				segments.to.plot$from.b[i] = replacement.colors[9]#
			}#
			else if(segments.to.plot$from[i] == "color4")#
			{#
				segments.to.plot$from.r[i] = replacement.colors[10]#
				segments.to.plot$from.g[i] = replacement.colors[11]#
				segments.to.plot$from.b[i] = replacement.colors[12]#
			}#
			else if(segments.to.plot$from[i] == "color5")#
			{#
				segments.to.plot$from.r[i] = replacement.colors[13]#
				segments.to.plot$from.g[i] = replacement.colors[14]#
				segments.to.plot$from.b[i] = replacement.colors[15]#
			}#
		}#
#
		for(i in 1:dim(segments.to.plot)[1])#
		{#
			if(segments.to.plot$from[i] == "color1")#
			{#
				segments.to.plot$from.r[i] = replacement.colors[1]#
				segments.to.plot$from.g[i] = replacement.colors[2]#
				segments.to.plot$from.b[i] = replacement.colors[3]#
			}#
			else if(segments.to.plot$from[i] == "color2")#
			{#
				segments.to.plot$from.r[i] = replacement.colors[4]#
				segments.to.plot$from.g[i] = replacement.colors[5]#
				segments.to.plot$from.b[i] = replacement.colors[6]#
			}#
			else if(segments.to.plot$from[i] == "color3")#
			{#
				segments.to.plot$from.r[i] = replacement.colors[7]#
				segments.to.plot$from.g[i] = replacement.colors[8]#
				segments.to.plot$from.b[i] = replacement.colors[9]#
			}#
			else if(segments.to.plot$from[i] == "color4")#
			{#
				segments.to.plot$from.r[i] = replacement.colors[10]#
				segments.to.plot$from.g[i] = replacement.colors[11]#
				segments.to.plot$from.b[i] = replacement.colors[12]#
			}#
			else if(segments.to.plot$from[i] == "color5")#
			{#
				segments.to.plot$from.r[i] = replacement.colors[13]#
				segments.to.plot$from.g[i] = replacement.colors[14]#
				segments.to.plot$from.b[i] = replacement.colors[15]#
			}#
		}#
	}#
#
	##if only a specific clade within the whole phylogeny is to be plotted, subset segments to plot accordingly#
	if(missing(subset.node))#
	{#
		subset.node <- "none"#
		print("Retaining entire phylogeny")#
	}#
	else if(!missing(subset.node) & subset.to.root==FALSE)#
	{#
		keep.branches <- descendants(phylobase.phylo, subset.node, type="all")#
		keep.species <- descendants(phylobase.phylo, subset.node, type="tips")#
		segments.to.plot <- segments.to.plot[segments.to.plot$descendant %in% keep.branches, ]#
	}#
	else#
	{#
		keep.branches <- descendants(phylobase.phylo, subset.node, type="all")#
		to.root <- ancestors(phylobase.phylo, subset.node, "ALL") ##calling it like this includes also the subset node#
		keep.branches <- c(rev(to.root), keep.branches)#
		keep.species <- descendants(phylobase.phylo, subset.node, type="tips")#
		segments.to.plot <- segments.to.plot[segments.to.plot$descendant %in% keep.branches, ]#
	}#
#
	##switch the order ancestor and descendant appear in data frame for ease of reading#
	segments.to.plot <- segments.to.plot[ , c("ancestor","descendant","x0","y0","x1","y1","from","to","from.r","from.g","from.b","to.r","to.g","to.b")]#
#
	##derive a vector of species' names based on whatever taxa are left to be plotted#
	name.vector <- phylobase.phylo@label[segments.to.plot$descendant][!is.na(phylobase.phylo@label[segments.to.plot$descendant])]#
#
	##derive a vector of node names based on whatever nodes are left to be plotted#
	node.vector <- segments.to.plot$descendant[segments.to.plot$descendant > length(ape.phylo$tip.label)]#
#
	output <- list(ape.phylo=ape.phylo, segments.to.plot=segments.to.plot, name.vector=name.vector, subset.node=subset.node, node.vector=node.vector)#
#
	class(output) <- "phylospace"#
#
	return(output)#
}
library(devtools)#
install_github("phylospacer", username="eliotmiller")#
library(phylospacer)
?phylospace
library(phylospacer)
?phylospace
?plot.phylospace
phylospace
plot.phylospace
?plot.phylospace
plot.phylospace
plot_phylospace
library()
library(phylospacer)
quadrant
phylospacer::quadrant
phylospacer:::quadrant
phylomorphospace
library(phytools)
phylomorphospace
12*300
12*100
library(devtools)
install_github("phylospacer", username="eliotmiller")
library(phylospacer)
?phylospace
library(ape)
tree <- rbdtree(birth=0.1, death=0, Tmax=40)
plot(tree)
tree <- drop.tip(tree, tip=51:length(tree$tip.label))
plot(tree)
trait1 <- rTraitCont(tree, model="BM")#
trait2 <- rTraitCont(tree, model="BM")
trait1
trait2
species.niches <- cbind(trait1, trait2)
nodes.trait1 <- ace(trait1, tree, type="continuous", method="REML")#
nodes.trait2 <- ace(trait2, tree, type="continuous", method="REML")
node.niches <- cbind(nodes.trait1$ace, nodes.trait2$ace)#
#
#simulate available climate space#
climate.points <- cbind(rnorm(500, mean=0, sd=1), rnorm(100, mean=0, sd=1))#
#
#calculate a phylospace object for the entire phylogeny#
entire <- phylospace(tree, species.niches=species.niches, node.niches=node.niches)#
#
#plot the entire phylospace, with species labels plotted and slightly offset from tips, and with available climate space in background#
plot(entire, species.labels=TRUE, climate.points=climate.points, label.adjust=0.05, lwd=2)
entire <- phylospace(tree, species.niches=species.niches, node.niches=node.niches, replacement.colors=c(0,0.1,0,0,0.4,0,0,0.6,0,0,0.8,0,0,1,0))#
plot(entire, species.labels=TRUE, climate.points=climate.points, label.adjust=0.05, lwd=2)
black <- c(0,0,0)#
blue <- c(0,0,1)#
purple <- c(1,0,1)#
red <- c(1,0,0)#
orange <- c(1,0.5,0)#
entire <- phylospace(tree, species.niches=species.niches, node.niches=node.niches, replacement.colors=c(black, blue, purple, red, orange))#
plot(entire, species.labels=TRUE, climate.points=climate.points, label.adjust=0.05, lwd=2)
entire <- phylospace(tree, species.niches=species.niches, node.niches=node.niches, replacement.colors=c(0.95,0.95,0.95, 0.75,0.75,0.75, 0.5,0.5,0.5, 0.25,0.25,0.25, 0,0,0))#
plot(entire, species.labels=TRUE, climate.points=climate.points, label.adjust=0.05, lwd=2)
max_travel_rep <- 8#
	max_travel_att <- 4#
#
	max_dist_rep <- 20#
	nl_rep <- 2 #non-linearity#
	steepness <- 1#
	proportion_replaced <- 0#
	offset_rep <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,50,0.2)#
	plot(NULL,ylim=c(-max_travel_att,max_travel_rep),xlim=c(0,50),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel_rep*(1-(steepness/(steepness+exp(-x-offset_rep+((1-gd)^nl_rep*max_dist_rep)+1))))#
		lines(x,y)#
		text(1.2+((1-gd)^nl_rep*max_dist_rep)-offset_rep,0.5*max_travel_rep,gd,srt=-74)#
	}#
	min_dist_att <- 30#
	max_dist_att <- 50#
	nl_att <- 0.5 #non-linearity#
	steepness <- 1#
	proportion_replaced <- 0#
	offset_att <- 0  ## moves left or right in reverse direction#
#
	for (gd in seq(0,1,0.1)) {#
		y <- -max_travel_att*((steepness/(steepness+exp(-x-offset_att+min_dist_att+(gd^nl_att*(max_dist_att-min_dist_att))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl_att*(max_dist_att-min_dist_att))-offset_att+min_dist_att,-0.5*max_travel_att,gd,srt=-74)#
	}
quartz()
max_travel_rep <- 8#
	max_travel_att <- 4#
#
	max_dist_rep <- 20#
	nl_rep <- 2 #non-linearity#
	steepness <- 1#
	proportion_replaced <- 0#
	offset_rep <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,50,0.2)#
	plot(NULL,ylim=c(-max_travel_att,max_travel_rep),xlim=c(0,50),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel_rep*(1-(steepness/(steepness+exp(-x-offset_rep+((gd)^nl_rep*max_dist_rep)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl_rep*max_dist_rep)-offset_rep,0.5*max_travel_rep,gd,srt=-74)#
	}#
	min_dist_att <- 30#
	max_dist_att <- 50#
	nl_att <- 0.5 #non-linearity#
	steepness <- 1#
	proportion_replaced <- 0#
	offset_att <- 0  ## moves left or right in reverse direction#
#
	for (gd in seq(0,1,0.1)) {#
		y <- -max_travel_att*((steepness/(steepness+exp(-x-offset_att+min_dist_att+(gd^nl_att*(max_dist_att-min_dist_att))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl_att*(max_dist_att-min_dist_att))-offset_att+min_dist_att,-0.5*max_travel_att,gd,srt=-74)#
	}
max_travel_rep <- 8#
	max_travel_att <- 4#
#
	max_dist_rep <- 30#
	nl_rep <- 2 #non-linearity#
	steepness <- 1#
	proportion_replaced <- 0#
	offset_rep <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,50,0.2)#
	plot(NULL,ylim=c(-max_travel_att,max_travel_rep),xlim=c(0,50),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel_rep*(1-(steepness/(steepness+exp(-x-offset_rep+((gd)^nl_rep*max_dist_rep)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl_rep*max_dist_rep)-offset_rep,0.5*max_travel_rep,gd,srt=-74)#
	}#
	min_dist_att <- 30#
	max_dist_att <- 50#
	nl_att <- 0.5 #non-linearity#
	steepness <- 1#
	proportion_replaced <- 0#
	offset_att <- 0  ## moves left or right in reverse direction#
#
	for (gd in seq(0,1,0.1)) {#
		y <- -max_travel_att*((steepness/(steepness+exp(-x-offset_att+min_dist_att+(gd^nl_att*(max_dist_att-min_dist_att))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl_att*(max_dist_att-min_dist_att))-offset_att+min_dist_att,-0.5*max_travel_att,gd,srt=-74)#
	}
max_travel_rep <- 8#
	max_travel_att <- 4#
#
	max_dist_rep <- 30#
	nl_rep <- 2 #non-linearity#
	steepness <- 1#
	proportion_replaced <- 0#
	offset_rep <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,50,0.2)#
	plot(NULL,ylim=c(-max_travel_att,max_travel_rep),xlim=c(0,50),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel_rep*(1-(steepness/(steepness+exp(-x-offset_rep+((gd)^nl_rep*max_dist_rep)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl_rep*max_dist_rep)-offset_rep,0.5*max_travel_rep,gd,srt=-74)#
	}#
	min_dist_att <- 10#
	max_dist_att <- 50#
	nl_att <- 0.5 #non-linearity#
	steepness <- 1#
	proportion_replaced <- 0#
	offset_att <- 0  ## moves left or right in reverse direction#
#
	for (gd in seq(0,1,0.1)) {#
		y <- -max_travel_att*((steepness/(steepness+exp(-x-offset_att+min_dist_att+(gd^nl_att*(max_dist_att-min_dist_att))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl_att*(max_dist_att-min_dist_att))-offset_att+min_dist_att,-0.5*max_travel_att,gd,srt=-74)#
	}
max_travel_rep <- 8#
	max_travel_att <- 4#
#
	max_dist_rep <- 30#
	nl_rep <- 2 #non-linearity#
	steepness <- 1#
	proportion_replaced <- 0#
	offset_rep <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,50,0.2)#
	plot(NULL,ylim=c(-max_travel_att,max_travel_rep),xlim=c(0,50),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel_rep*(1-(steepness/(steepness+exp(-x-offset_rep+((gd)^nl_rep*max_dist_rep)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl_rep*max_dist_rep)-offset_rep,0.5*max_travel_rep,gd,srt=-74)#
	}#
	min_dist_att <- 10#
	max_dist_att <- 100#
	nl_att <- 0.5 #non-linearity#
	steepness <- 1#
	proportion_replaced <- 0#
	offset_att <- 0  ## moves left or right in reverse direction#
#
	for (gd in seq(0,1,0.1)) {#
		y <- -max_travel_att*((steepness/(steepness+exp(-x-offset_att+min_dist_att+(gd^nl_att*(max_dist_att-min_dist_att))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl_att*(max_dist_att-min_dist_att))-offset_att+min_dist_att,-0.5*max_travel_att,gd,srt=-74)#
	}
max_travel_rep <- 8#
	max_travel_att <- 4#
#
	max_dist_rep <- 30#
	nl_rep <- 2 #non-linearity#
	steepness <- 1#
	proportion_replaced <- 0#
	offset_rep <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,50,0.2)#
	plot(NULL,ylim=c(-max_travel_att,max_travel_rep),xlim=c(0,100),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel_rep*(1-(steepness/(steepness+exp(-x-offset_rep+((gd)^nl_rep*max_dist_rep)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl_rep*max_dist_rep)-offset_rep,0.5*max_travel_rep,gd,srt=-74)#
	}#
	min_dist_att <- 10#
	max_dist_att <- 100#
	nl_att <- 0.5 #non-linearity#
	steepness <- 1#
	proportion_replaced <- 0#
	offset_att <- 0  ## moves left or right in reverse direction#
#
	for (gd in seq(0,1,0.1)) {#
		y <- -max_travel_att*((steepness/(steepness+exp(-x-offset_att+min_dist_att+(gd^nl_att*(max_dist_att-min_dist_att))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl_att*(max_dist_att-min_dist_att))-offset_att+min_dist_att,-0.5*max_travel_att,gd,srt=-74)#
	}
max_travel_rep <- 8#
	max_travel_att <- 4#
#
	max_dist_rep <- 30#
	nl_rep <- 2 #non-linearity#
	steepness <- 1#
	proportion_replaced <- 0#
	offset_rep <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,50,0.2)#
	plot(NULL,ylim=c(-max_travel_att,max_travel_rep),xlim=c(0,50),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel_rep*(1-(steepness/(steepness+exp(-x-offset_rep+((gd)^nl_rep*max_dist_rep)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl_rep*max_dist_rep)-offset_rep,0.5*max_travel_rep,gd,srt=-74)#
	}#
	min_dist_att <- 10#
	max_dist_att <- 50#
	nl_att <- 0.5 #non-linearity#
	steepness <- 1#
	proportion_replaced <- 0#
	offset_att <- 0  ## moves left or right in reverse direction#
#
	for (gd in seq(0,1,0.1)) {#
		y <- -max_travel_att*((steepness/(steepness+exp(-x-offset_att+min_dist_att+(gd^nl_att*(max_dist_att-min_dist_att))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl_att*(max_dist_att-min_dist_att))-offset_att+min_dist_att,-0.5*max_travel_att,gd,srt=-74)#
	}
max_travel_rep <- 8#
	max_travel_att <- 4#
#
	max_dist_rep <- 30#
	nl_rep <- 2 #non-linearity#
	steepness <- 1#
	proportion_replaced <- 0#
	offset_rep <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,50,0.2)#
	plot(NULL,ylim=c(-max_travel_att,max_travel_rep),xlim=c(0,50),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel_rep*(1-(steepness/(steepness+exp(-x-offset_rep+((gd)^nl_rep*max_dist_rep)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl_rep*max_dist_rep)-offset_rep,0.5*max_travel_rep,gd,srt=-74)#
	}#
	min_dist_att <- 10#
	max_dist_att <- 60#
	nl_att <- 0.5 #non-linearity#
	steepness <- 1#
	proportion_replaced <- 0#
	offset_att <- 0  ## moves left or right in reverse direction#
#
	for (gd in seq(0,1,0.1)) {#
		y <- -max_travel_att*((steepness/(steepness+exp(-x-offset_att+min_dist_att+(gd^nl_att*(max_dist_att-min_dist_att))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl_att*(max_dist_att-min_dist_att))-offset_att+min_dist_att,-0.5*max_travel_att,gd,srt=-74)#
	}
library(geiger)
sim.bdtree(stop="taxa", n=17)
sim.bdtree(stop="taxa", n=17)->tree
plot(tree)
nodelabels()
6*24+2
max_travel_rep <- 8#
	max_travel_att <- 4#
#
	max_dist_rep <- 30#
	nl_rep <- 2 #non-linearity#
	steepness <- 1#
	proportion_replaced <- 0#
	offset_rep <- 2  ## moves left or right in reverse direction#
#
	x <- seq(0,50,0.2)#
	plot(NULL,ylim=c(-max_travel_att,max_travel_rep),xlim=c(0,50),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
	for (gd in seq(0,1,0.1)) {#
		y <- max_travel_rep*(1-(steepness/(steepness+exp(-x-offset_rep+((gd)^nl_rep*max_dist_rep)+1))))#
		lines(x,y)#
		text(1.2+((gd)^nl_rep*max_dist_rep)-offset_rep,0.5*max_travel_rep,gd,srt=-74)#
	}#
	min_dist_att <- 10#
	max_dist_att <- 60#
	nl_att <- 0.5 #non-linearity#
	steepness <- 1#
	proportion_replaced <- 0#
	offset_att <- 0  ## moves left or right in reverse direction#
#
	for (gd in seq(0,1,0.1)) {#
		y <- -max_travel_att*((steepness/(steepness+exp(-x-offset_att+min_dist_att+(gd^nl_att*(max_dist_att-min_dist_att))+1))))#
		lines(x,y)#
		text(1.2+(gd^nl_att*(max_dist_att-min_dist_att))-offset_att+min_dist_att,-0.5*max_travel_att,gd,srt=-74)#
	}
start libraries#
#
library(ape)#
library(colorRamps)#
library(geiger)#
library(plyr)#
library(picante)#
#
##write a function that will derive a phylogeny, and evolve two traits up it according to#
##Brownian motion#
#
phyloNtraits <- function(no.species)#
{#
	require(geiger)#
	require(ape)#
	tree <- sim.bdtree(b=0.1, d=0, stop="taxa", n=no.species)#
	trait1 <- rTraitCont(tree, model="BM")#
	trait2 <- rTraitCont(tree, model="BM")#
#
	traits <- cbind(trait1, trait2)#
#
	output <- list(tree, traits)#
#
	return(output)#
}#
#
##write a function that will take the second element of the output of the phyloNtraits#
##function, and the min and max arena arguments, and output a data frame of scaled traits#
##where min and max traits are min and max of arena#
#
scaler <- function(input.traits, min.arena, max.arena)#
{#
	std1 <- (input.traits[,1] - min(input.traits[,1]))/(max(input.traits[,1])-min(input.traits[,1]))#
	std2 <- (input.traits[,2] - min(input.traits[,2]))/(max(input.traits[,2])-min(input.traits[,2]))#
	output.trait1 <- (max.arena - min.arena) * std1 + min.arena#
	output.trait2 <- (max.arena - min.arena) * std2 + min.arena#
	output.traits <- cbind(output.trait1, output.trait2)#
	return(output.traits)#
}#
#
##this function should be sped up by removing for loops and inserting new mini functions#
##then applying them with mapply() or something like that. regardless, what it does is it#
##takes results of a phyloNtraits() and scaled(), and you tell it what you want the mean#
##log of individuals on the plot to be. you also have to give it two important parameters:#
##the length of the vector from which a species X & Y coordinates will drawn, and the sd#
##of that vector. it then returns a dataframe of species and their X Y coordinates#
#
locationSampler <- function(phyloNtraits.results, mean.log.individuals, scaled.results, length.parameter, sd.parameter)#
{#
	indivs.per.species <- rlnorm(n=length(phyloNtraits.results[[1]]$tip.label), mean.log.individuals, sdlog=1)#
	indivs.per.species[indivs.per.species < 0] <- 0#
#
	indivs.per.species <- round(indivs.per.species)#
#
	individuals <- c()#
#
	for(i in 1:length(indivs.per.species))#
	{#
		individuals <- append(individuals, rep(phyloNtraits.results[[1]]$tip.label[i], times=indivs.per.species[i]))#
	}#
	output <- data.frame(individuals)#
#
	X <- c()#
	Y <- c()#
	for(i in 1:length(individuals))#
	{#
		X.options <- rnorm(n=length.parameter, mean=scaled.results[row.names(scaled.results)==individuals[i], 1], sd=sd.parameter)#
		X[i] <- sample(X.options, size=1)#
#
		Y.options <- rnorm(n=length.parameter, mean=scaled.results[row.names(scaled.results)==individuals[i], 2], sd=sd.parameter)#
		Y[i] <- sample(Y.options, size=1)#
	}#
	output$X <- X#
	output$Y <- Y#
	return(output)#
}#
#
###########################################################################################
##########################DEFINE A BUNCH OF NECESSARY FUNCTIONS############################
###########################################################################################
#
##the following is just a modified version of the original picante mpd function.#
#
modified.mpd <- function (samp, dis, abundance.weighted = FALSE) #
{#
    N <- dim(samp)[1]#
    mpd <- numeric(N)#
    for (i in 1:N) {#
        sppInSample <- names(samp[i, samp[i, ] > 0])#
        if (length(sppInSample) > 1) {#
            sample.dis <- dis[sppInSample, sppInSample]#
            if (abundance.weighted == "interspecific") {#
                sample.weights <- t(as.matrix(samp[i, sppInSample, #
                  drop = FALSE])) %*% as.matrix(samp[i, sppInSample, #
                  drop = FALSE])#
	            diag(sample.weights) <- 0#
                mpd[i] <- weighted.mean(sample.dis, sample.weights)#
            }#
            else if (abundance.weighted == "intraspecific") {#
                sample.weights <- t(as.matrix(samp[i, sppInSample, #
                  drop = FALSE])) %*% as.matrix(samp[i, sppInSample, #
                  drop = FALSE])#
	            diag(sample.weights) <- diag(sample.weights) - sqrt(diag(sample.weights))#
                mpd[i] <- weighted.mean(sample.dis, sample.weights)#
            }#
            else if (abundance.weighted == "complete") {#
                sample.weights <- t(as.matrix(samp[i, sppInSample, #
                  drop = FALSE])) %*% as.matrix(samp[i, sppInSample, #
                  drop = FALSE])#
                mpd[i] <- weighted.mean(sample.dis, sample.weights)#
            }#
            else {#
                mpd[i] <- mean(sample.dis[lower.tri(sample.dis)])#
            }#
        }#
        else {#
            mpd[i] <- NA#
        }#
    }#
    mpd#
}#
#
##first define a function that will be used to find the species richness of each row #
##(i.e. community)#
#
lengthNonZeros <- function(input.vector)#
{#
	nonZeros <- input.vector[input.vector != 0]#
	return(length(nonZeros))#
}#
#
##then define a function that will use this function and the modified.mpd function to #
##generate one block (iteration) of the desired data frame#
#
oneIteration <- function(orig.matrix, phy.dists, abundance.method)#
{#
	oneBlock <- matrix(nrow = dim(orig.matrix)[1], ncol = 2)#
	oneBlock[,1] <- apply(orig.matrix, 1, lengthNonZeros)#
	oneBlock[,2] <- modified.mpd(orig.matrix, phy.dists, abundance.method)#
	return(oneBlock)#
}#
#
##define a function that uses the function oneIteration and the picante function #
##randomizeMatrix to generate null expectations after randomization#
#
null.exp <- function(orig.matrix, null.method, phy.dists, abundance.method)#
{#
	randomMatrix <- matrix(nrow = dim(orig.matrix)[1], ncol = 2)#
	randomMatrix <- randomizeMatrix(orig.matrix, null.method)#
	results <- oneIteration(randomMatrix, phy.dists, abundance.method)#
	return(results)#
}#
#
##put all of these functions into an iterator function#
#
iterator <- function(orig.matrix, null.method, phy.dists, abundance.method, iterations)#
{#
	final.results <- matrix(nrow = iterations * dim(orig.matrix)[1], ncol = 2)#
	for (i in 1:iterations)#
	{	#
		final.results[(i * dim(orig.matrix)[1] - dim(orig.matrix)[1] + 1):(i * dim(orig.matrix)[1]), ] <- null.exp(orig.matrix, null.method, phy.dists, abundance.method)#
	}#
	final.results <- as.data.frame(final.results)#
	names(final.results) <- c("richness","metric")#
	return(final.results)#
}#
#
##discovered that the iterator function bogs down the memory very quickly #
##(e.g. at > 1000 iterations). write a function that will write the results to a csv file #
##outside of R at each iteration#
#
null.csv <- function(orig.matrix, null.method, phy.dists, abundance.method, iterations, file.name)#
{#
	for (i in 1:iterations)#
	{#
		temp.results <- null.exp(orig.matrix, null.method, phy.dists, abundance.method)#
		if(i == 1)#
		{#
			write.table(temp.results, file=file.name, append=FALSE, row.names=FALSE, sep=",")#
		}#
		else if(i/iterations == 0.2)#
		{#
			print("20% complete")#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
		else if(i/iterations == 0.5)#
		{#
			print("50% complete")#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
		else#
		{#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
	}#
	print("File saved to working directory")#
}#
#
##also, in case you need to run more iterations at a given richness, e.g. a low richness #
##that isn't being sampled well with the frequency null, write a function that will subset#
##each randomized matrix to only those richnesses you want#
#
null.exp.selected <- function(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses)#
{#
	randomMatrix <- matrix(nrow = dim(orig.matrix)[1], ncol = 2)#
	randomMatrix <- randomizeMatrix(orig.matrix, null.method)#
	results <- oneIteration(randomMatrix, phy.dists, abundance.method)#
	results <- matrix(results[results[,1] %in% accepted.richnesses, ], ncol=2)#
	return(results)#
}#
#
##and the iterator version of that. can't define the matrix beforehand for memory saving #
##purposes because you don't know how often the pertinent richnesses will appear#
#
iterator.selected <- function(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses, iterations)#
{#
	final.results <- c()#
	for (i in 1:iterations)#
	{	#
		final.results <- rbind(final.results, null.exp.selected(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses))#
	}#
	final.results <- as.data.frame(final.results)#
	names(final.results) <- c("richness","metric")#
	return(final.results)#
}#
#
##make a version that will write straight to csv#
#
null.csv.selected <- function(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses, iterations, file.name)#
{#
	for (i in 1:iterations)#
	{#
		temp.results <- null.exp.selected(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses)#
		if(i == 1)#
		{#
			write.table(temp.results, file=file.name, append=FALSE, row.names=FALSE, sep=",")#
		}#
		else if(i/iterations == 0.2)#
		{#
			print("20% complete")#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
		else if(i/iterations == 0.5)#
		{#
			print("50% complete")#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
		else#
		{#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
	}#
	print("File saved to working directory")#
}#
#
specific.csv <- function(orig.matrix, null.method, phy.dists, abundance.method, desired.iterations, max.iterations, file.name)#
{#
	temp <- oneIteration(orig.matrix, phy.dists, abundance.method)#
	max.rich <- max(temp[,1])#
	min.rich <- min(temp[,1])#
	rich.seq <- min.rich:max.rich#
	details.table <- matrix(nrow=length(rich.seq), ncol=1, dimnames=list(rich.seq))#
	details.table[,1] <- 0#
	temp.results <- null.exp.selected(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses=rich.seq)#
	write.table(temp.results, file=file.name, append=FALSE, row.names=FALSE, col.names=c("richness","metric"), sep=",")#
	details.table[,1][row.names(details.table) %in% count(temp.results[,1])$x] <- count(temp.results[,1])$freq#
	for (i in 1:max.iterations)#
	{#
		rich.seq <- row.names(details.table)[details.table[,1] < desired.iterations]#
		temp.results <- null.exp.selected(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses=rich.seq)#
		write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		details.table[,1][row.names(details.table) %in% count(temp.results[,1])$x] <- details.table[,1][row.names(details.table) %in% count(temp.results[,1])$x] + count(temp.results[,1])$freq#
		if(length(rich.seq) == 0)#
		{#
			break()#
		}#
	}#
	print("File saved to working directory")#
	return(details.table)#
}#
#
##define a function to calculate the mean and 95% confidence intervals of the results from#
##the various iterator functions#
#
con.intervals <- function(null.output)#
{#
	confidence <- ddply(null.output, "richness", summarise, iterations=length(metric), average=mean(metric), upper=quantile(metric, 0.975, na.rm=TRUE), lower=quantile(metric, 0.025, na.rm=TRUE))#
	return(confidence)#
}#
#
###########################################################################################
########################################BEGIN EXAMPLES#####################################
###########################################################################################
#
temp <- phyloNtraits(50)#
#
scaled <- scaler(temp[[2]], 0, 300)#
#
inds <- locationSampler(temp, mean.log.individuals=4, scaled, length.parameter=5000, sd.parameter=50)#
#
##set number of quadrats#
#
n_quadrats <- 15#
#
##set quadrat size#
#
quadrat_size <-50 ##note that for the repulsion run we only used size=30 here!#
#
# Set the arena size, make sure this matches with the simulation's arena size#
x_min <- 0#
x_max <- 300#
y_min <- 0#
y_max <- 300#
#
##define a genetic distance matrix#
#
phydistmatrix <- cophenetic(temp[[1]])#
#
##define a color for each species#
#
cols <- blue2green2red(nrow(phydistmatrix))#
#
##plot the arena. don't close the window#
#
plot(inds$X, inds$Y, pch=20, cex=0.5, xlim=c(0,x_max), ylim=c(0,y_max), col=cols[inds$individuals])
run_simulation <- function(n_default_inds, n_species, n_rounds, x_min, x_max, y_min, y_max, min_dist, max_dist_rep, max_dist_att, min_dist_att, nl_rep, nl_att, max_travel_rep, max_travel_att, steepness, proportion_replaced, offset_rep, offset_att, n_nodes, attract_species = FALSE, plotit=FALSE) {#
#
	library(ape)#
	library(geiger)#
	output <- list()#
#
	####  RUN FROM HERE - NOTHING MORE TO DO#
#
	#tree<-rcoal(n_species) # make tree with n_species#
	tree<-sim.bdtree(b=0.1,d=0,stop="taxa",n=n_species)#
	output[[1]] <- tree#
	rstree<-transform(tree,"depth",1) # rescale tree to have root to tip distance of 1.#
#
	# Assign abundances to species in tree#
	ab<-rlnorm(n_species,2,1)#
	# rescale abundances to be out of n_inds individuals in total#
	abpercent<-ab/sum(ab)*100#
	abdata<-round(abpercent/100*n_default_inds)#
	# replace species that have zero abundance with 1.#
	zeroes<-which(abdata==0)#
	abdata[zeroes]<-1#
#
	regional.community<-data.frame(species=tree$tip.label,abundance=abdata)#
	output[[2]] <- regional.community#
	# branch lengths between pairs of species#
	phydistmatrix<-sqrt(cophenetic(rstree)/2)#
	#### RANDOMLY PLACE INDS IN THE ARENA#
#
	n_inds <- sum(regional.community[,2])#
#
	inds <- data.frame(SPECIES=rep("",n_inds),X=rep(0,n_inds),Y=rep(0,n_inds))#
	inds$SPECIES <- rep(regional.community[,1],regional.community[,2])#
	inds$X <- sample(c((x_max):(x_max)),n_inds, replace=T)#
	inds$Y <- sample(c((y_max):(y_max)),n_inds, replace=T)#
	inds$X2 <- inds$X#
	inds$Y2 <- inds$Y#
	inds$REPULSE <- 0#
	inds$SPECIES_NUM <- rep(c(1:nrow(phydistmatrix)),regional.community[,2])#
#
	#### FUNCTION TO DEFINE ANGLE AND DISTANCE#
#
	dir_dist <- function(xy2,xy1) {#
		distance <- sqrt((xy1[1]-xy2[1])^2 + (xy1[2]-xy2[2])^2)#
#
		angle <- atan2((c(xy1[2]-xy2[2])),(c(xy1[1]-xy2[1]))) * 180 / pi#
		if (angle <0) angle <- 360+angle#
		angle <- angle-180#
		if (angle <0) angle <- 360+angle#
		return(c(distance,angle))#
	}#
#
	#### FUNCTION TO CALCULATE REPULSION / ATTRACTION#
#
	repulse <- function(gd, distance, max_dist, nl, steepness) {#
		if (attract_species) {#
			repulsion <- max_travel_rep*(1-(steepness/(steepness+exp(-distance-offset_rep+((gd)^nl*max_dist)+1))))#
		} else {	#
			repulsion <- max_travel_rep*(1-(steepness/(steepness+exp(-distance-offset_rep+((1-gd)^nl*max_dist)+1))))#
		}#
		return(repulsion)#
	}#
#
	attract <- function(gd, distance, max_dist, min_dist, nl, steepness) {#
		if (attract_species) {#
			attraction <- -max_travel_att*((steepness/(steepness+exp(-distance-offset_att+min_dist+((gd)^nl*(max_dist-min_dist))+1))))#
		} else {#
			attraction <- -max_travel_att*((steepness/(steepness+exp(-distance-offset_att+min_dist+((1-gd)^nl*(max_dist-min_dist))+1))))#
		}#
		return(attraction)#
	}#
#
	#### FUNCTION TO CALCULATE NEWX AND NEWY#
#
	travel <- function(inputs) {  # inputs <- x, y, angle, repulsion#
		xy <- inputs[c(1,2)]#
		angle <- inputs[3]#
		repulsion <- inputs[4]#
		if (angle < 180) {#
			angle <- angle * pi / 180#
			newx <- xy[1]-repulsion*cos(angle)#
			newy <- xy[2]-repulsion*sin(angle)#
		} else {#
			angle <- angle - 180#
			angle <- angle * pi / 180#
			newx <- xy[1]+repulsion*cos(angle)#
			newy <- xy[2]+repulsion*sin(angle)#
		}#
		return(c(newx,newy))#
#
	}	#
#
	#### FUNCTION TO ROUND TO +- MAX TRAVEL#
#
	round_travel <- function(distance,max_travel) {#
		if (distance < 0) #
			return(max(distance,-max_travel))#
		else#
			return(min(distance,max_travel))#
	}#
	#####  FUNCTION TO RETURN i TOP VALUES#
	max_n <- function(i,X) { #
		n <- length(unique(X))#
		which(X == sort(unique(X),partial=n-i)[n-i])#
	}#
#
	if (plotit) {#
		library(colorRamps)#
		cols <- blue2green2red(nrow(phydistmatrix))#
	}#
#
	#### GIVE EACH INDIVIDUAL A CHANCE TO RELOCATE#
	if (plotit == TRUE) print(plot(inds$X,inds$Y,pch=20,cex=0.5, xlim=c(0,x_max),ylim=c(0,y_max), col=cols[inds$SPECIES_NUM]))#
	for (zz in c(1:n_rounds)) {#
#
		for (yy in sample(c(1:nrow(inds)),nrow(inds),replace=FALSE)) {#
			xy2 <- as.matrix(inds[yy,c(2,3)])#
			# Put point in center of arena to avoid boundary issues#
			xy <- xy2#
			xy[1] <- xy2[1]+(0.5*x_max-xy2[1])#
			xy[2] <- xy2[2]+(0.5*y_max-xy2[2])#
			inds$X2 <- inds$X+(0.5*x_max-xy2[1])#
			inds$Y2 <- inds$Y+(0.5*y_max-xy2[2])#
			inds$X2[inds$X2 > x_max] <- inds$X2[inds$X2 > x_max]-x_max#
			inds$Y2[inds$Y2 > y_max] <- inds$Y2[inds$Y2 > y_max]-y_max#
			inds$X2[inds$X2 < 0] <- inds$X2[inds$X2 < 0]+x_max#
			inds$Y2[inds$Y2 < 0] <- inds$Y2[inds$Y2 < 0]+y_max#
			# identify individuals within distance#
			distances <- sqrt((inds$X2[yy]-inds$X2[-yy])^2 + (inds$Y2[yy]-inds$Y2[-yy])^2)#
#
			locals <- inds[-yy,][c(1:length(distances)) %in% sapply(c(0:(n_nodes-1)),max_n,-distances) & distances < max(max_dist_att,max_dist_rep) ,]#
			if (nrow(locals) > 0) {#
				# calculate angles, distances and repulsions#
				distances <- t(apply(as.matrix(locals[,c(4,5)]),1,dir_dist,xy))#
				repulsions <- repulse(phydistmatrix[inds$SPECIES_NUM[yy],locals$SPECIES_NUM],distances[,1],rep(max_dist_rep,nrow(locals)),rep(nl_rep,nrow(locals)),rep(steepness,nrow(locals)))#
				attractions <- attract(phydistmatrix[inds$SPECIES_NUM[yy],locals$SPECIES_NUM],distances[,1],rep(max_dist_att,nrow(locals)),rep(min_dist_att,nrow(locals)),rep(nl_att,nrow(locals)),rep(steepness,nrow(locals)))#
				repulsions <- repulsions + attractions#
				#reps <- sapply(c(0:min(5,nrow(locals))),max_n,repulsions)#
				reps <- c(1:length(repulsions))#
				# calculate new xs and ys#
				inputs <- cbind(rep(xy[1],length(reps)),rep(xy[2],length(reps)),distances[reps,2],repulsions[reps])#
				travels_rep <- t(apply(inputs,1,travel))#
				x_travel_rep <- round_travel(sum(travels_rep[,1] - (0.5*x_max)), max_travel_rep)#
				y_travel_rep <- round_travel(sum(travels_rep[,2] - (0.5*y_max)), max_travel_rep)#
				inds$X[yy] <- inds$X[yy] + sum(x_travel_rep)#
				inds$Y[yy] <- inds$Y[yy] + sum(y_travel_rep)#
				inds$X2[yy] <- inds$X2[yy] + sum(x_travel_rep)#
				inds$Y2[yy] <- inds$Y2[yy] + sum(y_travel_rep)#
				if (inds$X[yy] < 0) #
					inds$X[yy] <- x_max+(sum(x_travel_rep))-xy2[1]#
				if (inds$X[yy] > x_max)#
					inds$X[yy] <- inds$X[yy]-x_max#
				if (inds$Y[yy] < 0) #
					inds$Y[yy] <- y_max+(sum(y_travel_rep))-xy2[2]#
				if (inds$Y[yy] > y_max)#
					inds$Y[yy] <- inds$Y[yy]-y_max#
			} #
		}#
		if (plotit) print(plot(inds$X,inds$Y,pch=20,cex=0.5, xlim=c(0,x_max),ylim=c(0,y_max), col=cols[inds$SPECIES_NUM]))#
	}#
	output[[3]] <- inds#
	return(output)#
}
CURVE PARAMETERS & PLOT#
#
n_nodes <- 10  ## Number of nodes to use in calculations (pics n strongest influence)#
#
max_travel_rep <- 10#
max_travel_att <- 5#
#
max_dist_rep <- 75#
nl_rep <- 5 #non-linearity#
steepness <- 1#
proportion_replaced <- 0#
offset_rep <- 2  ## moves left or right in reverse direction#
#
x <- seq(0,50,0.2)#
plot(NULL,ylim=c(-max_travel_att,max_travel_rep),xlim=c(0,50),xlab="Distance",ylab="Repulsion",xaxs="i",yaxs="i")#
for (gd in seq(0,1,0.1)) {#
	y <- max_travel_rep*(1-(steepness/(steepness+exp(-x-offset_rep+((1-gd)^nl_rep*max_dist_rep)+1))))#
	lines(x,y)#
	text(1.2+((1-gd)^nl_rep*max_dist_rep)-offset_rep,0.5*max_travel_rep,gd,srt=-74)#
}#
min_dist_att <- 20#
max_dist_att <- 70#
nl_att <- 5 #non-linearity#
steepness <- 1#
proportion_replaced <- 0#
offset_att <- 2  ## moves left or right in reverse direction#
#
for (gd in seq(0,1,0.1)) {#
	y <- -max_travel_att*((steepness/(steepness+exp(-x-offset_att+min_dist_att+((1-gd)^nl_att*(max_dist_att-min_dist_att))+1))))#
	lines(x,y)#
	text(1.2+((1-gd)^nl_att*(max_dist_att-min_dist_att))-offset_att+min_dist_att,-0.5*max_travel_att,gd,srt=-74)#
}#
# SIMULATION PARAMETERS#
#
n_rounds <- 10#
#
x_min <- 0#
x_max <- 400#
y_min <- 0#
y_max <- 400#
#
n_default_inds <- 500#
#
n_species <- 20
run_simulation(n_default_inds, n_species, n_rounds, x_min, x_max, y_min, y_max, min_dist, max_dist_rep, max_dist_att, min_dist_att, nl_rep, nl_att, max_travel_rep, max_travel_att, steepness, proportion_replaced, offset_rep, offset_att, n_nodes, attract_species = T, plotit=T)
library(ape)#
library(colorRamps)#
library(geiger)#
library(plyr)#
library(picante)#
#
##write a function that will derive a phylogeny, and evolve two traits up it according to#
##Brownian motion#
#
phyloNtraits <- function(no.species)#
{#
	require(geiger)#
	require(ape)#
	tree <- sim.bdtree(b=0.1, d=0, stop="taxa", n=no.species)#
	trait1 <- rTraitCont(tree, model="BM")#
	trait2 <- rTraitCont(tree, model="BM")#
#
	traits <- cbind(trait1, trait2)#
#
	output <- list(tree, traits)#
#
	return(output)#
}
write a function that will take the second element of the output of the phyloNtraits#
##function, and the min and max arena arguments, and output a data frame of scaled traits#
##where min and max traits are min and max of arena#
#
scaler <- function(input.traits, min.arena, max.arena)#
{#
	std1 <- (input.traits[,1] - min(input.traits[,1]))/(max(input.traits[,1])-min(input.traits[,1]))#
	std2 <- (input.traits[,2] - min(input.traits[,2]))/(max(input.traits[,2])-min(input.traits[,2]))#
	output.trait1 <- (max.arena - min.arena) * std1 + min.arena#
	output.trait2 <- (max.arena - min.arena) * std2 + min.arena#
	output.traits <- cbind(output.trait1, output.trait2)#
	return(output.traits)#
}#
#
##this function should be sped up by removing for loops and inserting new mini functions#
##then applying them with mapply() or something like that. regardless, what it does is it#
##takes results of a phyloNtraits() and scaled(), and you tell it what you want the mean#
##log of individuals on the plot to be. you also have to give it two important parameters:#
##the length of the vector from which a species X & Y coordinates will drawn, and the sd#
##of that vector. it then returns a dataframe of species and their X Y coordinates#
#
locationSampler <- function(phyloNtraits.results, mean.log.individuals, scaled.results, length.parameter, sd.parameter)#
{#
	indivs.per.species <- rlnorm(n=length(phyloNtraits.results[[1]]$tip.label), mean.log.individuals, sdlog=1)#
	indivs.per.species[indivs.per.species < 0] <- 0#
#
	indivs.per.species <- round(indivs.per.species)#
#
	individuals <- c()#
#
	for(i in 1:length(indivs.per.species))#
	{#
		individuals <- append(individuals, rep(phyloNtraits.results[[1]]$tip.label[i], times=indivs.per.species[i]))#
	}#
	output <- data.frame(individuals)#
#
	X <- c()#
	Y <- c()#
	for(i in 1:length(individuals))#
	{#
		X.options <- rnorm(n=length.parameter, mean=scaled.results[row.names(scaled.results)==individuals[i], 1], sd=sd.parameter)#
		X[i] <- sample(X.options, size=1)#
#
		Y.options <- rnorm(n=length.parameter, mean=scaled.results[row.names(scaled.results)==individuals[i], 2], sd=sd.parameter)#
		Y[i] <- sample(Y.options, size=1)#
	}#
	output$X <- X#
	output$Y <- Y#
	return(output)#
}#
#
###########################################################################################
##########################DEFINE A BUNCH OF NECESSARY FUNCTIONS############################
###########################################################################################
#
##the following is just a modified version of the original picante mpd function.#
#
modified.mpd <- function (samp, dis, abundance.weighted = FALSE) #
{#
    N <- dim(samp)[1]#
    mpd <- numeric(N)#
    for (i in 1:N) {#
        sppInSample <- names(samp[i, samp[i, ] > 0])#
        if (length(sppInSample) > 1) {#
            sample.dis <- dis[sppInSample, sppInSample]#
            if (abundance.weighted == "interspecific") {#
                sample.weights <- t(as.matrix(samp[i, sppInSample, #
                  drop = FALSE])) %*% as.matrix(samp[i, sppInSample, #
                  drop = FALSE])#
	            diag(sample.weights) <- 0#
                mpd[i] <- weighted.mean(sample.dis, sample.weights)#
            }#
            else if (abundance.weighted == "intraspecific") {#
                sample.weights <- t(as.matrix(samp[i, sppInSample, #
                  drop = FALSE])) %*% as.matrix(samp[i, sppInSample, #
                  drop = FALSE])#
	            diag(sample.weights) <- diag(sample.weights) - sqrt(diag(sample.weights))#
                mpd[i] <- weighted.mean(sample.dis, sample.weights)#
            }#
            else if (abundance.weighted == "complete") {#
                sample.weights <- t(as.matrix(samp[i, sppInSample, #
                  drop = FALSE])) %*% as.matrix(samp[i, sppInSample, #
                  drop = FALSE])#
                mpd[i] <- weighted.mean(sample.dis, sample.weights)#
            }#
            else {#
                mpd[i] <- mean(sample.dis[lower.tri(sample.dis)])#
            }#
        }#
        else {#
            mpd[i] <- NA#
        }#
    }#
    mpd#
}#
#
##first define a function that will be used to find the species richness of each row #
##(i.e. community)#
#
lengthNonZeros <- function(input.vector)#
{#
	nonZeros <- input.vector[input.vector != 0]#
	return(length(nonZeros))#
}#
#
##then define a function that will use this function and the modified.mpd function to #
##generate one block (iteration) of the desired data frame#
#
oneIteration <- function(orig.matrix, phy.dists, abundance.method)#
{#
	oneBlock <- matrix(nrow = dim(orig.matrix)[1], ncol = 2)#
	oneBlock[,1] <- apply(orig.matrix, 1, lengthNonZeros)#
	oneBlock[,2] <- modified.mpd(orig.matrix, phy.dists, abundance.method)#
	return(oneBlock)#
}#
#
##define a function that uses the function oneIteration and the picante function #
##randomizeMatrix to generate null expectations after randomization#
#
null.exp <- function(orig.matrix, null.method, phy.dists, abundance.method)#
{#
	randomMatrix <- matrix(nrow = dim(orig.matrix)[1], ncol = 2)#
	randomMatrix <- randomizeMatrix(orig.matrix, null.method)#
	results <- oneIteration(randomMatrix, phy.dists, abundance.method)#
	return(results)#
}#
#
##put all of these functions into an iterator function#
#
iterator <- function(orig.matrix, null.method, phy.dists, abundance.method, iterations)#
{#
	final.results <- matrix(nrow = iterations * dim(orig.matrix)[1], ncol = 2)#
	for (i in 1:iterations)#
	{	#
		final.results[(i * dim(orig.matrix)[1] - dim(orig.matrix)[1] + 1):(i * dim(orig.matrix)[1]), ] <- null.exp(orig.matrix, null.method, phy.dists, abundance.method)#
	}#
	final.results <- as.data.frame(final.results)#
	names(final.results) <- c("richness","metric")#
	return(final.results)#
}#
#
##discovered that the iterator function bogs down the memory very quickly #
##(e.g. at > 1000 iterations). write a function that will write the results to a csv file #
##outside of R at each iteration#
#
null.csv <- function(orig.matrix, null.method, phy.dists, abundance.method, iterations, file.name)#
{#
	for (i in 1:iterations)#
	{#
		temp.results <- null.exp(orig.matrix, null.method, phy.dists, abundance.method)#
		if(i == 1)#
		{#
			write.table(temp.results, file=file.name, append=FALSE, row.names=FALSE, sep=",")#
		}#
		else if(i/iterations == 0.2)#
		{#
			print("20% complete")#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
		else if(i/iterations == 0.5)#
		{#
			print("50% complete")#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
		else#
		{#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
	}#
	print("File saved to working directory")#
}#
#
##also, in case you need to run more iterations at a given richness, e.g. a low richness #
##that isn't being sampled well with the frequency null, write a function that will subset#
##each randomized matrix to only those richnesses you want#
#
null.exp.selected <- function(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses)#
{#
	randomMatrix <- matrix(nrow = dim(orig.matrix)[1], ncol = 2)#
	randomMatrix <- randomizeMatrix(orig.matrix, null.method)#
	results <- oneIteration(randomMatrix, phy.dists, abundance.method)#
	results <- matrix(results[results[,1] %in% accepted.richnesses, ], ncol=2)#
	return(results)#
}#
#
##and the iterator version of that. can't define the matrix beforehand for memory saving #
##purposes because you don't know how often the pertinent richnesses will appear#
#
iterator.selected <- function(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses, iterations)#
{#
	final.results <- c()#
	for (i in 1:iterations)#
	{	#
		final.results <- rbind(final.results, null.exp.selected(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses))#
	}#
	final.results <- as.data.frame(final.results)#
	names(final.results) <- c("richness","metric")#
	return(final.results)#
}#
#
##make a version that will write straight to csv#
#
null.csv.selected <- function(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses, iterations, file.name)#
{#
	for (i in 1:iterations)#
	{#
		temp.results <- null.exp.selected(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses)#
		if(i == 1)#
		{#
			write.table(temp.results, file=file.name, append=FALSE, row.names=FALSE, sep=",")#
		}#
		else if(i/iterations == 0.2)#
		{#
			print("20% complete")#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
		else if(i/iterations == 0.5)#
		{#
			print("50% complete")#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
		else#
		{#
			write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		}#
	}#
	print("File saved to working directory")#
}#
#
specific.csv <- function(orig.matrix, null.method, phy.dists, abundance.method, desired.iterations, max.iterations, file.name)#
{#
	temp <- oneIteration(orig.matrix, phy.dists, abundance.method)#
	max.rich <- max(temp[,1])#
	min.rich <- min(temp[,1])#
	rich.seq <- min.rich:max.rich#
	details.table <- matrix(nrow=length(rich.seq), ncol=1, dimnames=list(rich.seq))#
	details.table[,1] <- 0#
	temp.results <- null.exp.selected(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses=rich.seq)#
	write.table(temp.results, file=file.name, append=FALSE, row.names=FALSE, col.names=c("richness","metric"), sep=",")#
	details.table[,1][row.names(details.table) %in% count(temp.results[,1])$x] <- count(temp.results[,1])$freq#
	for (i in 1:max.iterations)#
	{#
		rich.seq <- row.names(details.table)[details.table[,1] < desired.iterations]#
		temp.results <- null.exp.selected(orig.matrix, null.method, phy.dists, abundance.method, accepted.richnesses=rich.seq)#
		write.table(temp.results, file=file.name, append=TRUE, col.names=FALSE, row.names=FALSE, sep=",")#
		details.table[,1][row.names(details.table) %in% count(temp.results[,1])$x] <- details.table[,1][row.names(details.table) %in% count(temp.results[,1])$x] + count(temp.results[,1])$freq#
		if(length(rich.seq) == 0)#
		{#
			break()#
		}#
	}#
	print("File saved to working directory")#
	return(details.table)#
}#
#
##define a function to calculate the mean and 95% confidence intervals of the results from#
##the various iterator functions#
#
con.intervals <- function(null.output)#
{#
	confidence <- ddply(null.output, "richness", summarise, iterations=length(metric), average=mean(metric), upper=quantile(metric, 0.975, na.rm=TRUE), lower=quantile(metric, 0.025, na.rm=TRUE))#
	return(confidence)#
}
temp <- phyloNtraits(50)
temp
scaled <- scaler(temp[[2]], 0, 300)
scaled
inds <- locationSampler(temp, mean.log.individuals=4, scaled, length.parameter=5000, sd.parameter=50)
head(inds)
n_quadrats <- 15#
#
##set quadrat size#
#
quadrat_size <-50 ##note that for the repulsion run we only used size=30 here!#
#
# Set the arena size, make sure this matches with the simulation's arena size#
x_min <- 0#
x_max <- 300#
y_min <- 0#
y_max <- 300#
#
##define a genetic distance matrix#
#
phydistmatrix <- cophenetic(temp[[1]])#
#
##define a color for each species#
#
cols <- blue2green2red(nrow(phydistmatrix))#
#
##plot the arena. don't close the window#
#
plot(inds$X, inds$Y, pch=20, cex=0.5, xlim=c(0,x_max), ylim=c(0,y_max), col=cols[inds$individuals])
quadrat_bounds <- matrix(0,nrow=n_quadrats,ncol=4)#
colnames(quadrat_bounds) <- c("X1","X2","Y1","Y2")#
#
##run this for loop with the arena plot still active#
#
for (i in c(1:n_quadrats)) {#
#
	repeat {#
	OK <- TRUE#
	quadrat_bounds[i,1] <- sample(c(0:(x_max-quadrat_size)),1)#
	quadrat_bounds[i,2] <- quadrat_bounds[i,1] + quadrat_size#
	quadrat_bounds[i,3] <- sample(c(0:(y_max-quadrat_size)),1)#
	quadrat_bounds[i,4] <- quadrat_bounds[i,3] + quadrat_size#
	if (i > 1) {#
	for (j in c(1:(i-1))) {#
		if (any(#
			quadrat_bounds[i,1] %in% c(quadrat_bounds[j,1]:quadrat_bounds[j,2]) & quadrat_bounds[i,3] %in% c(quadrat_bounds[j,3]:quadrat_bounds[j,4]),#
			quadrat_bounds[i,2] %in% c(quadrat_bounds[j,1]:quadrat_bounds[j,2]) & quadrat_bounds[i,3] %in% c(quadrat_bounds[j,3]:quadrat_bounds[j,4]),#
			quadrat_bounds[i,1] %in% c(quadrat_bounds[j,1]:quadrat_bounds[j,2]) & quadrat_bounds[i,4] %in% c(quadrat_bounds[j,3]:quadrat_bounds[j,4]),#
			quadrat_bounds[i,2] %in% c(quadrat_bounds[j,1]:quadrat_bounds[j,2]) & quadrat_bounds[i,4] %in% c(quadrat_bounds[j,3]:quadrat_bounds[j,4])#
			)) {#
			OK <- FALSE#
		}#
	}#
	}#
	if (OK == TRUE) {#
		break;#
	}#
	}#
	# Plot quadrats#
	polygon(c(quadrat_bounds[i,1],quadrat_bounds[i,2],quadrat_bounds[i,2],quadrat_bounds[i,1]),c(quadrat_bounds[i,3],quadrat_bounds[i,3],quadrat_bounds[i,4],quadrat_bounds[i,4]))#
#
}#
#
#####  RECORD WHATS IN QUADRATS, RETURNING A DATA FRAME#
#
species <- unique(inds$individuals)#
com.results <- matrix(0, ncol=n_quadrats, nrow=length(species))#
rownames(com.results) <- species#
#
for (i in c(1:n_quadrats)) {#
#
	in_quadrat <- inds$individuals[inds$X >= quadrat_bounds[i,1] & inds$X <= quadrat_bounds[i,2] & inds$Y >= quadrat_bounds[i,3] & inds$Y <= quadrat_bounds[i,4]]#
#
	for (j in c(1:length(species))) {#
		com.results[j,i] <- sum(in_quadrat == species[j])#
	}#
#
}#
#
##transpose the results into picante format#
#
cdm <- t(com.results)
null.csv(cdm, "richness", phydistmatrix, "FALSE", 100, "cluster_rich_noAbund.csv")#
#
null.csv(cdm, "richness", phydistmatrix, "interspecific", 100, "cluster_rich_inter.csv")#
#
null.csv(cdm, "richness", phydistmatrix, "intraspecific", 100, "cluster_rich_intra.csv")#
#
null.csv(cdm, "richness", phydistmatrix, "complete", 100, "cluster_rich_complete.csv")#
#
##read the simulations in #
#
noAbund.simulations <- read.csv("cluster_rich_noAbund.csv")#
#
inter.simulations <- read.csv("cluster_rich_inter.csv")#
#
intra.simulations <- read.csv("cluster_rich_intra.csv")#
#
complete.simulations <- read.csv("cluster_rich_complete.csv")#
#
##assign names necessary for con.intervals() to work right below#
#
names(noAbund.simulations) <- c("richness","metric")#
#
names(inter.simulations) <- c("richness","metric")#
#
names(intra.simulations) <- c("richness","metric")#
#
names(complete.simulations) <- c("richness","metric")#
#
##run the con intervals function on it#
#
noAbundCIs <- con.intervals(noAbund.simulations)#
#
interCIs <- con.intervals(inter.simulations)#
#
intraCIs <- con.intervals(intra.simulations)#
#
completeCIs <- con.intervals(complete.simulations)#
#
##calculate non-abundance weighted, interspecific and complete MPDs#
#
noAbundMPD <- modified.mpd(cdm, phydistmatrix, "FALSE")#
#
interMPD <- modified.mpd(cdm, phydistmatrix, "interspecific")#
#
intraMPD <- modified.mpd(cdm, phydistmatrix, "intraspecific")#
#
completeMPD <- modified.mpd(cdm, phydistmatrix, "complete")#
#
##calculate richness of each quadrat#
#
richness <- apply(cdm, 1, lengthNonZeros)#
#
##try plotting on the empirical results. here for noAbund#
#
plot(noAbundCIs$upper~noAbundCIs$richness, xlab="Richness", ylab="NAW MPD", ylim=c(min(noAbundCIs$lower, noAbundMPD),max(noAbundCIs$upper, noAbundMPD)))#
#
points(noAbundCIs$lower~noAbundCIs$richness)#
#
points(noAbundMPD~richness, pch=20, cex=2)
temp <- phyloNtraits(50)#
#
scaled <- scaler(temp[[2]], 0, 300)#
#
inds <- locationSampler(temp, mean.log.individuals=4, scaled, length.parameter=5000, sd.parameter=50)#
#
##set number of quadrats#
#
n_quadrats <- 15#
#
##set quadrat size#
#
quadrat_size <-50 ##note that for the repulsion run we only used size=30 here!#
#
# Set the arena size, make sure this matches with the simulation's arena size#
x_min <- 0#
x_max <- 300#
y_min <- 0#
y_max <- 300#
#
##define a genetic distance matrix#
#
phydistmatrix <- cophenetic(temp[[1]])#
#
##define a color for each species#
#
cols <- blue2green2red(nrow(phydistmatrix))#
#
##plot the arena. don't close the window#
#
plot(inds$X, inds$Y, pch=20, cex=0.5, xlim=c(0,x_max), ylim=c(0,y_max), col=cols[inds$individuals])
temp <- phyloNtraits(50)#
#
scaled <- scaler(temp[[2]], 0, 300)#
#
inds <- locationSampler(temp, mean.log.individuals=3, scaled, length.parameter=5000, sd.parameter=50)#
#
##set number of quadrats#
#
n_quadrats <- 15#
#
##set quadrat size#
#
quadrat_size <-50 ##note that for the repulsion run we only used size=30 here!#
#
# Set the arena size, make sure this matches with the simulation's arena size#
x_min <- 0#
x_max <- 300#
y_min <- 0#
y_max <- 300#
#
##define a genetic distance matrix#
#
phydistmatrix <- cophenetic(temp[[1]])#
#
##define a color for each species#
#
cols <- blue2green2red(nrow(phydistmatrix))#
#
##plot the arena. don't close the window#
#
plot(inds$X, inds$Y, pch=20, cex=0.5, xlim=c(0,x_max), ylim=c(0,y_max), col=cols[inds$individuals])
temp <- phyloNtraits(50)#
#
scaled <- scaler(temp[[2]], 0, 300)#
#
inds <- locationSampler(temp, mean.log.individuals=3, scaled, length.parameter=10000, sd.parameter=50)#
#
##set number of quadrats#
#
n_quadrats <- 15#
#
##set quadrat size#
#
quadrat_size <-50 ##note that for the repulsion run we only used size=30 here!#
#
# Set the arena size, make sure this matches with the simulation's arena size#
x_min <- 0#
x_max <- 300#
y_min <- 0#
y_max <- 300#
#
##define a genetic distance matrix#
#
phydistmatrix <- cophenetic(temp[[1]])#
#
##define a color for each species#
#
cols <- blue2green2red(nrow(phydistmatrix))#
#
##plot the arena. don't close the window#
#
plot(inds$X, inds$Y, pch=20, cex=0.5, xlim=c(0,x_max), ylim=c(0,y_max), col=cols[inds$individuals])
temp <- phyloNtraits(50)#
#
scaled <- scaler(temp[[2]], 0, 300)#
#
inds <- locationSampler(temp, mean.log.individuals=3, scaled, length.parameter=10000, sd.parameter=5)#
#
##set number of quadrats#
#
n_quadrats <- 15#
#
##set quadrat size#
#
quadrat_size <-50 ##note that for the repulsion run we only used size=30 here!#
#
# Set the arena size, make sure this matches with the simulation's arena size#
x_min <- 0#
x_max <- 300#
y_min <- 0#
y_max <- 300#
#
##define a genetic distance matrix#
#
phydistmatrix <- cophenetic(temp[[1]])#
#
##define a color for each species#
#
cols <- blue2green2red(nrow(phydistmatrix))#
#
##plot the arena. don't close the window#
#
plot(inds$X, inds$Y, pch=20, cex=0.5, xlim=c(0,x_max), ylim=c(0,y_max), col=cols[inds$individuals])
temp <- phyloNtraits(50)#
#
scaled <- scaler(temp[[2]], 0, 300)#
#
inds <- locationSampler(temp, mean.log.individuals=4, scaled, length.parameter=5000, sd.parameter=50)#
#
##set number of quadrats#
#
n_quadrats <- 15#
#
##set quadrat size#
#
quadrat_size <-50 ##note that for the repulsion run we only used size=30 here!#
#
# Set the arena size, make sure this matches with the simulation's arena size#
x_min <- 0#
x_max <- 300#
y_min <- 0#
y_max <- 300#
#
##define a genetic distance matrix#
#
phydistmatrix <- cophenetic(temp[[1]])#
#
##define a color for each species#
#
cols <- blue2green2red(nrow(phydistmatrix))#
#
##plot the arena. don't close the window#
#
plot(inds$X, inds$Y, pch=20, cex=0.5, xlim=c(0,x_max), ylim=c(0,y_max), col=cols[inds$individuals])
plot(interCIs$upper~interCIs$richness, xlab="Richness", ylab="Inter MPD", ylim=c(min(interCIs$lower, interMPD),max(interCIs$upper, interMPD)))#
#
points(interCIs$lower~interCIs$richness)#
#
points(interMPD~richness, pch=20, cex=2)#
#
##here for intraspecific
plot(intraCIs$upper~intraCIs$richness, xlab="Richness", ylab="Intra MPD", ylim=c(min(intraCIs$lower, intraMPD),max(intraCIs$upper, intraMPD)))#
#
points(intraCIs$lower~intraCIs$richness)#
#
points(intraMPD~richness, pch=20, cex=2)
plot(completeCIs$upper~completeCIs$richness, xlab="Richness", ylab="Complete MPD", ylim=c(min(completeCIs$lower, completeMPD),max(completeCIs$upper, completeMPD)))#
#
points(completeCIs$lower~completeCIs$richness)#
#
points(completeMPD~richness, pch=20, cex=2)
library(devtools)#
install_github("ecoPDcorr", username="eliotmiller")#
library(ecoPDcorr)
load_all()
